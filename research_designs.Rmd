# Data and Research Designs

In the previous chapter (\@ref(role-of-statistics-in-the-research-process)) we have provided an overview of the research process in psychology and related disciplines. The goal of this overview was to show that statistics is just one part of the full research endeavour and usually not the end goal. We also highlighted that an answer to our research questions requires not only the results from the statistical analysis, but the context in which this result was generated. More specifically, we argued that the most important part of the research process is usually the operationalisation of the research question: What are our measures? What is the task participants have to do? What is our study design? The goal of this chapter is to provide us with the necessary conceptual knowledge and the right terminology to answer these questions for our research.

## Empirical Evidence and Data

In this book we are concerned with *empirical research*. What this means is that we are generally not interested in research questions for which an answer or proof can be found purely through thinking hard, such as in mathematics or philosophy. Instead, we are only interested in research question for which the evidence comes in the form of observations or experiences, *empirical evidence* for short. As we have discussed in the previous chapter, that does not mean that our theories cannot include unobservable entities such as mental states (e.g., fear, enjoyment, attention). However, if our theories include such unobservable entities, these must be causally responsible for something that is observable (e.g., behaviour). This way, we can still test the theories (e.g., if our theory predicts that fear should lead to aggression, but we can induce fear without it leading to aggression, we learn that our theory must be wrong).

The fact that we are interested in empirical research means that the ultimate arbiter of whether or not we should believe in a theory is empirical evidence. It does not matter how elegant or intuitive a theory is. If the observed behaviour of people disagrees with a theory, it is wrong. It also means that theories that are so vague that there is no possible empirical evidence that would disprove them are not part of the empirical sciences (i.e., they are not empirical theories). This criterion is also known as [*falsifiability*](https://en.wikipedia.org/wiki/Falsifiability) and was introduced by the philosopher Karl Popper in the 1930s. For example, there is a never ending discussed of whether Freudian psychoanalysis is in principle falsifiable or not. Whereas Karl Popper was very strong in his belief that it is not (which would render psychoanalysis non-scientific), proponents of Freudian psychoanalysis naturally see this rather differently.[^research_designs-1]

[^research_designs-1]: I think it is fair to say that nowadays most researchers believe that many parts of Freudian psychoanalysis are not falsifiable. Consequently, psychoanalysis is not considered an empirical theory and therefore largely no part of (scientific) psychology (it is of course a part of the history of psychology). For a somewhat recent discussion see: [@grunbaumFreudianPsychoanalyticTheory1986]

The empirical evidence comes in at least two different types, *anecdotes* and *data*. Whereas an anecdote typically refer to a single person, data usually contains information about multiple persons. However, anecdotes and data differ on more dimensions than just the number of observations, as summarised in the following aphorism: The plural of anecdote is not data.

Anecdotes are unsystematic observation, typically in the form of stories (e.g., "the friend of a friend"), that somehow address our research questions. The problem with anecdotes is that they are generally difficult to verify and to investigate further. This makes it usually impossible to rule out possible alternative explanations (as we have seen in the previous chapter, one of the main criteria for deciding whether some observation provides evidence for a theoretical position is whether we can rule out plausible alternative explanations). Consequently, for mature sciences anecdotes should only play a minor evidentiary role.

Data are systematic observations that are collected for a specific purpose, such as answering a research question or bookkeeping. Data generally consists of *observations* on multiple *variables*. Each variable corresponds to a specific set of possible outcomes or states of affair, where each possible outcome corresponds to one value of the variable. An observation is the smallest unit of data corresponding to one set of values on at least one of the variables.

As an example of data, consider again the study by @walasekHowMakeLoss2015 discussed in the previous chapter (\@ref(role-of-statistics-in-the-research-process)). The task of participants was to accept or reject 50-50 lotteries (for an example, see \@ref(fig:lottery-example)) and each participant had to do this for 64 trials. Table \@ref(tab:walasek-data) below shows six observations each from two different participants from this study. Observations are shown in rows and variables are shown as columns. This tabular representation of the data with observations in rows and variables in columns is common and will be used throughout the book. The way the data is shown here is exactly the format in which the data was kindly provided by Lukasz Walasek (i.e., no variables added or removed). So presumably, this is exactly the format that he used to analyse the data (of course, this table omits several thousand observations, but the format of the data is the same for the not shown observations).

```{r walasek-data, echo=FALSE}
d1a <- readxl::read_xlsx("data_original/walasek_2015/Experiment1_Raw.xlsx") %>% 
  mutate(#subno = factor(paste0("e1a_", subno)),
         response = factor(response),  #levels = c("reject", "accept")
         #condition = round(condition, 2)
         ) %>% 
  # separate("condition", c("gain_c", "loss_c"), remove = FALSE) %>% 
  # mutate(gain_c = factor(gain_c), 
  #        loss_c = factor(loss_c, labels = c("20", "40"))) %>% 
  mutate(condition = factor(condition), 
         subno = as.character(subno))
tt1 <- d1a %>% 
  filter(subno %in% c(8)) %>% 
  slice(1:6)

tt2 <- d1a %>% 
  filter(subno %in% c(369)) %>% 
  slice(1:6)
ttb <- d1a %>% 
  slice(0) 

ttb[1, "subno"] <- "[...]"

op <- options()
options(knitr.kable.NA = '')
knitr::kable(bind_rows(tt1, ttb, tt2), booktabs = TRUE,
  caption = 'Selected observations of the data from Walasek & Stewart (2015, Exp. 1a). The "[...]" indicates that this is only part of the whole data and some observations are not shown.', )
options(op)
```

In total we can see six different variables in this data set. Let us discuss these in turn. The first variable, `subno` (we generally use a `monospace` font to refer to variable names as they appear in a data set), is the participant identifier or "subject number" (because actual individuals take part in research and not passive subjects, the term "participant" is now preferred to "subject"). This variable should be part of any data set to uniquely identify to which participant (or more generally *unit of observation*) a specific observation belongs. Here, we see that it only takes numbers. It is not uncommon to only use numbers for the participant identifier variable, but it can also be a combination of numbers and letters, or a (ideally anonymous) name.

The second and third variables, `loss` and `gain`, specify the possible outcomes of the lotteries for each trial. For example, the first observations shows a lottery in which the potential loss was \$6 and the potential gain was \$8. Based on these two columns, we can see that the observations are ordered by the combination of loss and gain. This means the order of observations in the data does not reflect the actual order of trials in which participants saw them (as this order was random). All values of the two variables are numbers with the lowest possible loss/gain being 6 and the largest possible loss/gain being 40, depending on the condition a participant is in.

Column four shows the `response` of the participant to the lottery, either `accept` or `reject`. The sixth variable, `resp`, is a numeric version of the response. Here, an accept decision is represented by a 1 and a reject decision by a 0. So these two variables carry the same information, but in different format that have different benefits. The `response` variable makes it easy to understand what participants response was (i.e., it is clear which value corresponds to which possible response, accept or reject, in the study). The `resp` variable makes it easy to perform calculation on the results given it uses a numerical code to represent the same information. For example, because reject is mapped onto 0 and accept is mapped onto 1, we could take the mean over all observations to get the overall acceptance rate across all gambles (the mean of the whole data is 0.38 which corresponds to an acceptance rate of 38%). However, if we only had the `resp` variable, we would additionally need the information what 0 and what 1 corresponds to.

Finally, variable five informs us in which `condition` each participant is in. Remember from the previous chapter that the experiment varied the range of gains and losses across participants resulting in four conditions in total: a condition with loss and gains ranging up to -\$20/+\$40, a -\$20/+\$20 condition, a -\$40/+\$40 condition, and a -\$40/+\$20. This information is here provided in form of a decimal number with the values before the decimal point referring to the range of gains and the values after the decimal to the range of losses without the trailing 0 (i.e., in the opposite order to how we have referred to the conditions so far). Thus, participant with `subno` 8 is in the -\$20/+\$20 condition and participant 369 in the -\$20/+\$40 condition (if we were showing a participant in the -\$40 loss condition, there lowest possible loss outcome would be 12).

The example from @walasekHowMakeLoss2015 hopefully clarifies the abstract definition of a variable that was provided above. For each variable, we have a set of possible outcomes that is defined by our research design. For example, for the participant identifier `subno`, this set encompasses all possible participants that can take part in the study. For `loss` and `gain`, this set contains all potential losses and potential gains that occur in the lotteries. For `response` there are the two possible outcomes, to accept or to reject a lottery. We then define values for each possible outcome. In the case of `subno` we assign a different number to every participant from which we collect data. For `loss` and `gain`, the values correspond to the magnitude of the potential loss and gain in US dollars (the currency that was used in the experiment). For `response`, we do not use a numeric code but use a word to represent the two outcomes.

There are a few things of note in the example data shown in Table \@ref(tab:walasek-data).

(1) Every observation in this data is complete; for each observations we have values on each variable and no missing data. Whereas this is common in experimental research, it is not always the case for other types of research. Whereas missing data is not something we will discuss in detail in this book, it is important to be aware that it can happen and to think about what to do in this case (sadly, there is no general solution).

(2) We have multiple observations per participant, 64 for to be precise. These 64 observations are given in different rows. We call this data format -- in which the data from each participant potentially spans multiple rows, one row per observation (i.e., 64 rows per participant in the present case) -- the *long format*. This long format contrasts with a *wide format* that is also commonly found in the social sciences. In the wide format, the data of one participant only spans a single row. In case a participant has multiple observations, these are given in different columns. For the procedures introduced in this book, we generally want the data to be in the long format.

(3) The variables differ in whether they contain no numbers (only `response`) or numbers (all other variables).

## Data Types

Let us discuss the last point from above in more detail. A common intuition is to think about numbers when thinking about data. As we have seen in the example data, this is not necessary. Data does not have to be numbers. The `response` variable shows that we can use other values, such as words or phrases, to represent values of variables. However, the conception of data primarily as numbers is also not completely false. For example, the statistical analyses introduced in this book need to represent all variables in terms of numbers. Fortunately for us, the tools we will be using will generally help us and convert non-numeric data into numeric data when necessary. This means we will use the type of data representation that makes it easiest to understand what the data stands for.

### Numerical Versus Categorical Variables

An important issue that arises when thinking about data as numbers is that numbers can mean different things. One possibility is that numbers represent *numerical information*; that is, they represent a measurement, magnitude, or count of something. However, we can also use number in a broader sense in which they only serve as a label (e.g., numbers on football jerseys or telephone numbers). In this case, numbers only represent *categorical information*; each observation falls into one of a set of mutually exclusive categories. The meaning of the numbers has important consequences of how we use them. If numbers do not represent numerical information most mathematical operations do not make sense. For example, it does not make much sense to calculate the average of two telephone numbers. Let us exemplify this with some variables from the example data.

Let us begin with the `loss`/`gain` variable pair (we can consider them together, because the type of information is the same, the only difference is whether the number refers to a potential loss or a potential gain). For these variables, the meaning of numbers corresponds to the common understanding of numbers as a magnitude of something. In particular, the magnitude of a potential loss and potential gain. We could understand these variables as *measuring* the magnitude of the potential loss and potential gain of a lottery. The larger the number the larger potential loss and gain. In fact, the number exactly represents the potential loss and potential gain (i.e., the measurement of the potential loss and gain is perfectly accurate). Because the numbers of the variables represent numeric information we can treat the variable as a numeric variable in a statistical analysis. More specifically, because performing mathematical operations, such as addition or calculating the average of the numbers, is meaningful for this variable we can treat it as a numerical variable. For example, we could calculate the average potential loss/gain for a participant and it would be useful information (i.e., we could interpret the average in a meaningful way, for example by comparing with the average loss/gain in a different condition).

As a second example, let us consider the `subno` variable. Here, the numbers do not really measure the magnitude of something. Participant number 16 is not twice participant 8. From just looking at the variable, we also do not know what it means. As described above, one just needs to assign numbers somehow to each participant. For example, one could assign number 1 to the first participants that participates in the experiment, number 2 to the second one that participates, and so forth. Alternatively, one could also assign number 1 to the first participant invited, number 2 to the second one invited, and so forth. Another possibility is to specify the maximum number of participant one can collect, say 500 participants, and then just assign a unique random number from 1 to 500 to every participant that participates (e.g., by drawing them from a pool of all numbers without replacement). Importantly, we do not need to know which of these procedures was used. The only reason we have the `subno` variables is so we know to which participant a particular observation belongs to. The numbers in `subno` only serve the purpose as a *label* identifying the particular participant. Instead of numbers, we could also use non-numeric labels, such as random strings of letters, as the participant variable. Consequently, it does not make much sense to perform any mathematical operation on the `subno` variable. For example, the average participant number does not provide any useful information.

For the purposes of this book, this distinction between these two data types is central: Can we treat a variable as a *numerical variable* or a *categorical variable*? The statistical methods introduced in the following chapters can only deal with these two types of variables (and categorical variables can generally also only serve the role of an explanatory variable and not as an outcome variable). So how can we identify whether a variable is numerical or categoerical?

Usually it is easy to identify categorical variables among the variables that have numbers. Whenever the numbers represent a label, a variable is usually a categorical variable. For example, in addition to the `subno` variable, the numbers in the `condition` variable only serve as a label to identify the condition. We cannot interpret the numbers of the `condition` variable shown in Table \@ref(tab:walasek-data) as actually representing a numerical value of either 20.2 or 40.2. Instead, each of the four possible values of the variable, 20.2, 20.4, 40.2 and 40.4, refers to one of their four conditions of the experiment, with loss and gains ranging up to either -\$20/+\$20, -\$40/+\$20, -\$20/+\$40, and -\$40/+\$40 (note again that the value after the decimal point is the range of the potential loss and the value before the decimal point the range of the potential gains). And non-numeric variables in which the values are labels, such as for the `response` variable, are also clearly categorical variables.

More difficult is the decision for the `resp` variable. Clearly, the two possible values of the response variable, the accept or reject decision, are response categories. However, when transforming it into a variable with numbers 1 and 0, we can perform meaningful mathematical operations on it. As discussed above, the average value of the variable can be interpret as the average accept proportion. More generally, any *binary categorical variable* (i.e., a categorical variable of two categories) can be seen as a special case where treating it as a numerical variable can in certain situations be meaningful. However, whether or not it is meaningful depends on the situation. In general it is best to explicitly treat a variable as categorical unless one is sure treating it as numerical is meaningful.

### Assumptions of Numerical Variables

What the case of the `resp` variable, the numerical representation of a binary categorical variable, shows is that the decision of whether something is a numerical or categorical variable can depend on the situation. To help with this decision, it is helpful to know what exactly is entailed by treating a variable as numerical. For the statistical methods used here, when we treat a variable as numerical we assume it represents *continuous numerical information*. What this means is that we assume that:

(1) A certain difference has the same meaning anywhere on the scale. For example, a difference of 1 unit of the variable means the same on whether we add it to 10 or 20. We can see that this holds for the `loss`/`gain` variable pair but we will later discuss examples where this is a questionable assumption. A corollary to this assumption is that calculating the average for our variable must be meaningful in itself. If we cannot interpret the average, a variable cannot be treated as numeric.

(2) Our variable can in principle take on any real-valued (i.e., decimal) number. That is, even though we might have only used *discrete values* for our variables, such as for the `loss`/`gain` variable pair only a subset of the whole numbers between 6 and 40 (see Table \@ref(tab:gainloss)), our statistical method assumes the in-between values are possible and in principle meaningful.

Let us consider a few example variables to see how well they fulfil the two assumptions for a numerical variable. For the `loss`/`gain` variable pair, the two assumptions are fully satisfied. However, the `loss`/`gain` variable pair is not actually an outcome that was measured in an experiment. Instead, this variable pair was part of the design of an experiment. So maybe it is not the most relevant variable for this question. The numerical outcome variable in this data set is `resp`. Clearly, `resp` does not fulfil the assumptions as it only has two discrete outcomes, the values 0 and 1. However, we can calculate and interpret the average (as average proportion accepted). We could also assume that a specific difference, say a 0.1 (or 10%) difference, means the same whether it happens at an acceptance rate of 50% or an acceptance rate of 85%.[^research_designs-2] So whereas the assumptions are violated they are also partially fulfilled. So whether we can interpret the results from an analysis depends on the exact context and circumstances. For example, if our statistical analysis would lead to results or predictions beyond the probability range of 0 to 1, this would be clearly problematic as the results would not be meaningful. In other words, we would have learned very little meaningful about our data from such a statistical analysis.

[^research_designs-2]: The assumption that a specific difference on the probability scale, say 0.1, has the same meaning across the whole probability range is everything but uncontroversial. In fact, most methods specifically for dealing with binary variables make the opposite assumption that a difference of 0.1 represents a larger effect if it occurs near the edges (say at 0.9 or 0.1) than when it occurs in the centre of the scale (i.e., near 0.5). However, these methods are beyond the scope of the current book. For introductions see @baguleySeriousStatsGuide2012 (Chapter. 17), @dixonModelsAccuracyRepeatedmeasures2008, or @jaegerCategoricalDataAnalysis2008.

A very popular variable in psychology and related sciences is subjective rating scales. For example, we have discussed the study of @mcgrawComparingGainsLosses2010 where participants in one condition where asked to rate the intensity of their emotional reaction to a potential loss or potential gain on a response scale ranging from 1 = "no Effect" to 5 = "Very Large Effect" (see Figure \@ref(fig:loss-feeling-scales), unipolar intensity scale). Does this variable represent a numerical variable? Clearly, a value of 5 represents an emotional reaction that is larger than a value of 1. What this means is that the variable does represent a magnitude, but does it fulfil the assumptions spelled out above? We can also take the average of the scale and interpret it in a meaningful way. Specifically, in the loss condition participants reported an on average stronger feeling with an average value of around 3.6 compared to the gain condition, where the average value was around 3.1. However, it is questionable whether a difference of 1 means the same everywhere across the scale. More specifically, is the difference between "No Effect" and "Small Effect" (i.e., the difference between 1 and 2) the same as the difference between "Moderate Effect" and "Substantial Effect" (i.e., the difference between 3 and 4)? Numerically it is, but whether this also holds psychologically is a question that is difficult to answer. Like most researchers @mcgrawComparingGainsLosses2010 have treated this variable as a numerical variable so have made this assumption (which is also implicit in the process of calculating the average). The validity of their conclusions rests to some degree on whether or not we believe making this assumption makes sense.

Let us generalise the conclusion of the previous paragraph and answer the question what it means that the two points above represent the *assumptions* for treating a variable as a numerical variable. Can we only treat a variable as a numeric variable in a statistical model if it perfectly meets the assumptions? In an ideal statistical world the answer would be yes, but the reality of data analysis always differs from the ideal. Many of the variables that we regularly encounter in our research (e.g., rating scales) violate the two assumptions to some degree and we still need to include them as numerical variable in our model (because treating them as categorical does not help us in answering our research questions). Whenever the assumptions are to some degree violated this can be interpreted as another instance of an epistemic gap (or as an instance of the first epistemic desk, Section \@ref(epistemic-gap-1-underdetermination-of-theory-by-data)). The fact that the assumptions are violated opens the possibility for an alternative explanation of the results that differs from our hypothesis. In other words, if the assumptions are perfectly met the evidence provided by our statistical analysis is stronger than when the assumptions are only partially met.

The problem is that once we have numbers and treat them as a numerical variable, the computer treats all the numbers the same way (i.e., assuming they are a continuous numerical variable), "the numbers don't remember where they came from" [@lordStatisticalTreatmentFootball1953][^research_designs-3]. Only we -- the researchers -- know where the numbers came from and need to take this into account when interpreting statistics. We can also interpret this insight in terms of the concepts introduced in the previous chapter. The numbers are part of the operationalisation; we establish a procedure that maps real world entities (above we have called these possible outcomes or states of affairs) onto values of the variables (which are in many cases numbers). The numbers that emerge from this procedure are related to our research question, but they are not identical with our research question. Any inference from the statistical results based on this numbers requires many auxiliary assumptions, one which is that we assume that numerical variables are continuous. And as we can never be sure if all the auxiliary assumptions are true, we have to be careful and humble with the conclusions we draw from our research.

[^research_designs-3]: This quote is taken from @lordStatisticalTreatmentFootball1953, a short and humorous paper addressing the question of what mathematical operations can be performed with categorical variables, in particular with football jersey numbers. The author, Frederic M. Lord, is one of the most important researchers in the history of psychometrics, the scientific field concerned with psychological measurement. And even though this quote encapsulates an important message, the fact that we have to distinguish the numbers and what they stand for when doing statistics, the overall message of his paper is not without problems. For a modern discussion and perspective see [@zandscholtenReanalysisLordStatistical2009].

### Measurement Scales
