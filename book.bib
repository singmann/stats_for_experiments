@Book{xie2015,
  title = {Dynamic Documents with {R} and knitr},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2015},
  edition = {2nd},
  note = {ISBN 978-1498716963},
  url = {http://yihui.org/knitr/},
}

@article{urry2021,
	title = {Don{\textquoteright}t Ditch the Laptop Just Yet: A Direct Replication of Mueller and Oppenheimer{\textquoteright}s (2014) Study 1 Plus Mini Meta-Analyses Across Similar Studies},
	author = {{Urry}, {Heather L.} and {Crittle}, {Chelsea S.} and {Floerke}, {Victoria A.} and {Leonard}, {Michael Z.} and {Perry}, {Clinton S.} and {Akdilek}, {Naz} and {Albert}, {Erica R.} and {Block}, {Avram J.} and {Bollinger}, {Caroline Ackerley} and {Bowers}, {Emily M.} and {Brody}, {Renee S.} and {Burk}, {Kelly C.} and {Burnstein}, {Ally} and {Chan}, {Allissa K.} and {Chan}, {Petrina C.} and {Chang}, {Lena J.} and {Chen}, {Emily} and {Chiarawongse}, {Chakrapand Paul} and {Chin}, {Gregory} and {Chin}, {Kathy} and {Cooper}, {Ben G.} and {Corneilson}, {Katherine Adele} and {Danielson}, {Amanda M.} and {Davis}, {Elizabeth S.} and {Devis}, {Ycar} and {Dong}, {Melissa} and {Dossett}, {Elizabeth K.} and {Dulchin}, {Nick} and {Duong}, {Vincent N.} and {Ewing}, {Ben} and {Fuller}, {Julia Mansfield} and {Gartman}, {Thomas E.} and {Goldberg}, {Chad R.} and {Greenfield}, {Jesse} and {Groh}, {Selena} and {Hamilton}, {Ross A.} and {Hodge}, {Will} and {Van Hong}, {Dylan} and {Insler}, {Joshua E.} and {Jahan}, {Aava B.} and {Jimbo}, {Jessica Paola} and {Kahn}, {Emma M.} and {Knight}, {Daniel} and {Konstantin}, {Grace E.} and {Kornick}, {Caitlin} and {Kramer}, {Zachary J.} and {Lauz√©}, {Meghan S.} and {Linnehan}, {Misha S.} and {Lombardi}, {Tommaso} and {Long}, {Hayley} and {Lotstein}, {Alec J.} and {Lyncee}, {Myrna-Nahisha A.} and {Lyons}, {Monica Gabriella} and {Maayan}, {Eli} and {May}, {Nicole Marie} and {McCall}, {Elizabeth C.} and {Montgomery-Walsh}, {Rhea Ann Charlotte} and {Morscher}, {Michael C.} and {Moser}, {Amelia D.} and {Mueller}, {Alexandra S.} and {Mujica}, {Christin A.} and {Na}, {Elim} and {Newman}, {Isabelle R.} and {O{\textquoteright}Brien}, {Meghan K.} and {Ochoa Castillo}, {Katherine Alexandra} and {Onipede}, {Zaenab Ayotola} and {Pace}, {Danielle A.} and {Park}, {Jasper H.} and {Perdikari}, {Angeliki} and {Perloff}, {Catherine E.} and {Perry}, {Rachel C.} and {Pillai}, {Akash A.} and {Rajpal}, {Avni} and {Ranalli}, {Emma} and {Schreier}, {Jillian E.} and {Shangguan}, {Justin R.} and {Silver}, {Micaela Jen} and {Spratt}, {Avery Glennon} and {Stein}, {Rachel E.} and {Steinhauer}, {Grant J.} and {Valera}, {Devon K.} and {Vervoordt}, {Samantha M.} and {Walton}, {Lena} and {Weinflash}, {Noah W.} and {Weinstock}, {Karen} and {Yuan}, {Jiaqi} and {Zarrella}, {Dominique T.} and {Zarrow}, {Jonah E.}},
	year = {2021},
	month = {02},
	date = {2021-02-04},
	journal = {Psychological Science},
	pages = {0956797620965541},
	doi = {10.1177/0956797620965541},
	url = {https://doi.org/10.1177/0956797620965541},
	note = {Publisher: SAGE Publications Inc},
	langid = {en}
}

@book{kline2015,
	title = {Principles and practice of structural equation modeling},
	author = {{Kline}, {Rex B}},
	year = {2015},
	date = {2015},
	publisher = {Guilford Press},
	langid = {English}
}

@book{lee2013,
	title = {Bayesian cognitive modeling: a practical course},
	author = {{Lee}, {Michael D.} and {Wagenmakers}, {Eric-Jan}},
	year = {2013},
	date = {2013},
	publisher = {Cambridge University Press},
	address = {Cambridge},
	langid = {English}
}

@book{lenth2021,
	title = {emmeans: Estimated Marginal Means, aka Least-Squares Means},
	author = {{Lenth}, {Russell}},
	year = {2021},
	date = {2021},
	url = {https://CRAN.R-project.org/package=emmeans},
	note = {R package version 1.1, https://CRAN.R-project.org/package=emmeans}
}

@book{wickham2017,
	title = {R for Data Science: Import, Tidy, Transform, Visualize, and Model Data},
	author = {{Wickham}, {Hadley} and {Grolemund}, {Garrett}},
	year = {2017},
	date = {2017},
	publisher = {O'Reilly},
	address = {Sebastopol  CA},
	langid = {English}
}

@article{meehl1978,
	title = {Theoretical Risks and Tabular Asterisks: Sir Karl, Sir Ronald, and the Slow Progress of Soft Psychology},
	author = {{Meehl}, {Paul E}},
	year = {1978},
	date = {1978},
	journal = {Journal of Consulting and Clinical Psychology},
	pages = {806--834},
	volume = {46},
	doi = {10.1037//0022-006X.46.4.806}
}

@article{cohen1994,
	title = {The earth is round (p < .05)},
	author = {{Cohen}, {Jacob}},
	year = {1994},
	date = {1994},
	journal = {American Psychologist},
	pages = {997--1003},
	volume = {49},
	number = {12},
	doi = {10.1037/0003-066X.49.12.997},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0003-066X.49.12.997}
}

@article{rozeboom1960,
	title = {The fallacy of the null-hypothesis significance test.},
	author = {{Rozeboom}, {William W.}},
	year = {1960},
	month = {09},
	date = {1960-09},
	journal = {Psychological Bulletin},
	pages = {416--428},
	volume = {57},
	number = {5},
	doi = {10.1037/h0042040},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0042040},
	langid = {en}
}

@article{nickerson2000,
	title = {Null hypothesis significance testing: a review of an old and continuing controversy.},
	author = {{Nickerson}, {Raymond S.}},
	year = {2000},
	date = {2000},
	journal = {Psychological methods},
	pages = {241},
	volume = {5},
	number = {2}
}

@article{wagenmakers2007,
	title = {A practical solution to the pervasive problems of p values},
	author = {{Wagenmakers}, {Eric-Jan}},
	year = {2007},
	month = {10},
	date = {2007-10},
	journal = {Psychonomic Bulletin \& Review},
	pages = {779--804},
	volume = {14},
	number = {5},
	doi = {10.3758/BF03194105},
	url = {http://www.springerlink.com/content/7403110087u84w72/}
}


@book{howellStatisticalMethodsPsychology2013,
  title = {Statistical Methods for Psychology},
  author = {Howell, David C},
  year = {2013},
  publisher = {{Wadsworth Cengage Learning}},
  address = {{Belmont, CA}},
  language = {English}
}




@book{howell2013,
	title = {Statistical methods for psychology},
	author = {{Howell}, {David C}},
	year = {2013},
	date = {2013},
	publisher = {Wadsworth Cengage Learning},
	address = {Belmont, CA},
	langid = {English}
}


@book{foxCompanionAppliedRegression2019,
  title = {An {{R}} Companion to Applied Regression},
  author = {Fox, John and Weisberg, Sanford},
  year = {2019},
  edition = {Third},
  publisher = {{Sage}},
  address = {{Thousand Oaks CA}}
}





@article{olejnikGeneralizedEtaOmega2003,
  title = {Generalized {{Eta}} and {{Omega Squared Statistics}}: {{Measures}} of {{Effect Size}} for {{Some Common Research Designs}}.},
  shorttitle = {Generalized {{Eta}} and {{Omega Squared Statistics}}},
  author = {Olejnik, Stephen and Algina, James},
  year = {2003},
  volume = {8},
  pages = {434--447},
  doi = {10.1037/1082-989X.8.4.434},
  file = {C\:\\Users\\singm\\Zotero\\storage\\8GTRS7CB\\OlejnikS2003a.pdf},
  journal = {Psychological Methods},
  number = {4}
}





@article{bakemanRecommendedEffectSize2005,
  title = {Recommended Effect Size Statistics for Repeated Measures Designs},
  author = {Bakeman, Roger},
  year = {2005},
  month = aug,
  volume = {37},
  pages = {379--384},
  doi = {10.3758/BF03192707},
  file = {C\:\\Users\\singm\\Zotero\\storage\\K4IUREZI\\Bakeman - 2005 - Recommended effect size statistics for repeated me.pdf},
  journal = {Behavior Research Methods},
  number = {3}
}





@article{lakensCalculatingReportingEffect2013,
  title = {Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for t-Tests and {{ANOVAs}}},
  shorttitle = {Calculating and Reporting Effect Sizes to Facilitate Cumulative Science},
  author = {Lakens, Daniel},
  year = {2013},
  volume = {4},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00863},
  abstract = {Effect sizes are the most important outcome of empirical studies. Most articles on effect sizes highlight their importance to communicate the practical significance of results. For scientists themselves, effect sizes are most useful because they facilitate cumulative science. Effect sizes can be used to determine the sample size for follow-up studies, or examining effects across studies. This article aims to provide a practical primer on how to calculate and report effect sizes for t-tests and ANOVA's such that effect sizes can be used in a-priori power analyses and meta-analyses. Whereas many articles about effect sizes focus on between-subjects designs and address within-subjects designs only briefly, I provide a detailed overview of the similarities and differences between within- and between-subjects designs. I suggest that some research questions in experimental psychology examine inherently intra-individual effects, which makes effect sizes that incorporate the correlation between measures the best summary of the results. Finally, a supplementary spreadsheet is provided to make it as easy as possible for researchers to incorporate effect size calculations into their workflow.},
  file = {C\:\\Users\\singm\\Zotero\\storage\\EDWBSNWA\\Lakens - 2013 - Calculating and reporting effect sizes to facilita.pdf},
  journal = {Frontiers in Psychology},
  keywords = {Cohen's d,effect sizes,eta-squared,power analysis,sample size planning},
  language = {English}
}





@article{baguleyStandardizedSimpleEffect2009,
  title = {Standardized or Simple Effect Size: {{What}} Should Be Reported?},
  shorttitle = {Standardized or Simple Effect Size},
  author = {Baguley, Thom},
  year = {2009},
  month = aug,
  volume = {100},
  pages = {603--617},
  issn = {2044-8295},
  doi = {10.1348/000712608X377117},
  abstract = {It is regarded as best practice for psychologists to report effect size when disseminating quantitative research findings. Reporting of effect size in the psychological literature is patchy \textendash{} though this may be changing \textendash{} and when reported it is far from clear that appropriate effect size statistics are employed. This paper considers the practice of reporting point estimates of standardized effect size and explores factors such as reliability, range restriction and differences in design that distort standardized effect size unless suitable corrections are employed. For most purposes simple (unstandardized) effect size is more robust and versatile than standardized effect size. Guidelines for deciding what effect size metric to use and how to report it are outlined. Foremost among these are: (i) a preference for simple effect size over standardized effect size, and (ii) the use of confidence intervals to indicate a plausible range of values the effect might take. Deciding on the appropriate effect size statistic to report always requires careful thought and should be influenced by the goals of the researcher, the context of the research and the potential needs of readers.},
  file = {C\:\\Users\\singm\\Zotero\\storage\\AJU59HS7\\Baguley - 2009 - Standardized or simple effect size What should be.pdf},
  journal = {British Journal of Psychology},
  language = {en},
  number = {3}
}





@article{lenthPracticalGuidelinesEffective2001,
  title = {Some {{Practical Guidelines}} for {{Effective Sample Size Determination}}},
  author = {Lenth, Russell V},
  year = {2001},
  month = aug,
  volume = {55},
  pages = {187--193},
  issn = {0003-1305},
  doi = {10.1198/000313001317098149},
  abstract = {Sample size determination is often an important step in planning a statistical study\textemdash and it is usually a difficult one. Among the important hurdles to be surpassed, one must obtain an estimate of one or more error variances and specify an effect size of importance. There is the temptation to take some shortcuts. This article offers some suggestions for successful and meaningful sample size determination. Also discussed is the possibility that sample size may not be the main issue, that the real goal is to design a high-quality study. Finally, criticism is made of some ill-advised shortcuts relating to power and sample size.},
  file = {C\:\\Users\\singm\\Zotero\\storage\\KVHWN4JW\\Lenth - 2001 - Some Practical Guidelines for Effective Sample Siz.pdf},
  journal = {The American Statistician},
  number = {3}
}




@book{baguleySeriousStatsGuide2012,
	title = {Serious stats : a guide to advanced statistics for the behavioral sciences},
	author = {{Baguley}, {Thomas}},
	year = {2012},
	date = {2012},
	publisher = {Palgrave Macmillan},
	address = {Houndmills, Basingstoke, Hampshire; New York},
	langid = {English}
}


@article{muellerPenMightierKeyboard2014,
  title = {The {{Pen Is Mightier Than}} the {{Keyboard}}: {{Advantages}} of {{Longhand Over Laptop Note Taking}}},
  shorttitle = {The {{Pen Is Mightier Than}} the {{Keyboard}}},
  author = {Mueller, Pam A. and Oppenheimer, Daniel M.},
  year = {2014},
  month = jun,
  volume = {25},
  pages = {1159--1168},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797614524581},
  abstract = {Taking notes on laptops rather than in longhand is increasingly common. Many researchers have suggested that laptop note taking is less effective than longhand note taking for learning. Prior studies have primarily focused on students' capacity for multitasking and distraction when using laptops. The present research suggests that even when laptops are used solely to take notes, they may still be impairing learning because their use results in shallower processing. In three studies, we found that students who took notes on laptops performed worse on conceptual questions than students who took notes longhand. We show that whereas taking more notes can be beneficial, laptop note takers' tendency to transcribe lectures verbatim rather than processing information and reframing it in their own words is detrimental to learning.},
  file = {C\:\\Users\\singm\\Zotero\\storage\\6GKDIP3S\\Mueller and Oppenheimer - 2014 - The Pen Is Mightier Than the Keyboard Advantages .pdf},
  journal = {Psychological Science},
  keywords = {academic achievement,cognitive processes,educational psychology,memory,open data,open materials},
  language = {en},
  number = {6}
}





@article{opensciencecollaborationEstimatingReproducibilityPsychological2015,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {{Open Science Collaboration}},
  year = {2015},
  month = aug,
  volume = {349},
  pages = {aac4716},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aac4716},
  abstract = {Empirically analyzing empirical evidence One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study. Science, this issue 10.1126/science.aac4716 Structured Abstract INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error. RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science. RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P {$<$} .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams. CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that ``we already know this'' belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know. Download high-res image Open in new tab Download Powerpoint Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects. Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams. A large-scale assessment suggests that experimental reproducibility in psychology leaves a lot to be desired. A large-scale assessment suggests that experimental reproducibility in psychology leaves a lot to be desired.},
  copyright = {Copyright \textcopyright{} 2015, American Association for the Advancement of Science},
  file = {C\:\\Users\\singm\\Zotero\\storage\\XDF2PK2F\\Collaboration - 2015 - Estimating the reproducibility of psychological sc.pdf},
  journal = {Science},
  language = {en},
  number = {6251}
}





@article{camererEvaluatingReplicabilitySocial2018,
  title = {Evaluating the Replicability of Social Science Experiments in {{Nature}} and {{Science}} between 2010 and 2015},
  author = {Camerer, Colin F. and Dreber, Anna and Holzmeister, Felix and Ho, Teck-Hua and Huber, J{\"u}rgen and Johannesson, Magnus and Kirchler, Michael and Nave, Gideon and Nosek, Brian A. and Pfeiffer, Thomas and Altmejd, Adam and Buttrick, Nick and Chan, Taizan and Chen, Yiling and Forsell, Eskil and Gampa, Anup and Heikensten, Emma and Hummer, Lily and Imai, Taisuke and Isaksson, Siri and Manfredi, Dylan and Rose, Julia and Wagenmakers, Eric-Jan and Wu, Hang},
  year = {2018},
  month = aug,
  pages = {1},
  issn = {2397-3374},
  doi = {10.1038/s41562-018-0399-z},
  abstract = {Camerer et al. carried out replications of 21 Science and Nature social science experiments, successfully replicating 13 out of 21 (62\%). Effect sizes of replications were about half of the size of the originals.},
  copyright = {2018 The Author(s)},
  file = {C\:\\Users\\singm\\Zotero\\storage\\N3DCDTGL\\Camerer et al. - 2018 - Evaluating the replicability of social science exp.pdf},
  journal = {Nature Human Behaviour},
  language = {en}
}





@article{kleinManyLabsInvestigating2018,
  title = {Many {{Labs}} 2: {{Investigating Variation}} in {{Replicability Across Samples}} and {{Settings}}},
  shorttitle = {Many {{Labs}} 2},
  author = {Klein, Richard A. and Vianello, Michelangelo and Hasselman, Fred and Adams, Byron G. and Adams, Reginald B. and Alper, Sinan and Aveyard, Mark and Axt, Jordan R. and Babalola, Mayowa T. and Bahn{\'i}k, {\v S}t{\v e}p{\'a}n and Batra, Rishtee and Berkics, Mih{\'a}ly and Bernstein, Michael J. and Berry, Daniel R. and Bialobrzeska, Olga and Binan, Evans Dami and Bocian, Konrad and Brandt, Mark J. and Busching, Robert and R{\'e}dei, Anna Cabak and Cai, Huajian and Cambier, Fanny and Cantarero, Katarzyna and Carmichael, Cheryl L. and Ceric, Francisco and Chandler, Jesse and Chang, Jen-Ho and Chatard, Armand and Chen, Eva E. and Cheong, Winnee and Cicero, David C. and Coen, Sharon and Coleman, Jennifer A. and Collisson, Brian and Conway, Morgan A. and Corker, Katherine S. and Curran, Paul G. and Cushman, Fiery and Dagona, Zubairu K. and Dalgar, Ilker and Dalla Rosa, Anna and Davis, William E. and {de Bruijn}, Maaike and De Schutter, Leander and Devos, Thierry and {de Vries}, Marieke and Do{\u g}ulu, Canay and Dozo, Nerisa and Dukes, Kristin Nicole and Dunham, Yarrow and Durrheim, Kevin and Ebersole, Charles R. and Edlund, John E. and Eller, Anja and English, Alexander Scott and Finck, Carolyn and Frankowska, Natalia and Freyre, Miguel-{\'A}ngel and Friedman, Mike and Galliani, Elisa Maria and Gandi, Joshua C. and Ghoshal, Tanuka and Giessner, Steffen R. and Gill, Tripat and Gnambs, Timo and G{\'o}mez, {\'A}ngel and Gonz{\'a}lez, Roberto and Graham, Jesse and Grahe, Jon E. and Grahek, Ivan and Green, Eva G. T. and Hai, Kakul and Haigh, Matthew and Haines, Elizabeth L. and Hall, Michael P. and Heffernan, Marie E. and Hicks, Joshua A. and Houdek, Petr and Huntsinger, Jeffrey R. and Huynh, Ho Phi and IJzerman, Hans and Inbar, Yoel and {Innes-Ker}, {\AA}se H. and {Jim{\'e}nez-Leal}, William and John, Melissa-Sue and {Joy-Gaba}, Jennifer A. and Kamilo{\u g}lu, Roza G. and Kappes, Heather Barry and Karabati, Serdar and Karick, Haruna and Keller, Victor N. and Kende, Anna and Kervyn, Nicolas and Kne{\v z}evi{\'c}, Goran and Kovacs, Carrie and Krueger, Lacy E. and Kurapov, German and Kurtz, Jamie and Lakens, Dani{\"e}l and Lazarevi{\'c}, Ljiljana B. and Levitan, Carmel A. and Lewis, Neil A. and Lins, Samuel and Lipsey, Nikolette P. and Losee, Joy E. and Maassen, Esther and Maitner, Angela T. and Malingumu, Winfrida and Mallett, Robyn K. and Marotta, Satia A. and Me{\dj}edovi{\'c}, Janko and {Mena-Pacheco}, Fernando and Milfont, Taciano L. and Morris, Wendy L. and Murphy, Sean C. and Myachykov, Andriy and Neave, Nick and Neijenhuijs, Koen and Nelson, Anthony J. and Neto, F{\'e}lix and Lee Nichols, Austin and Ocampo, Aaron and O'Donnell, Susan L. and Oikawa, Haruka and Oikawa, Masanori and Ong, Elsie and Orosz, G{\'a}bor and Osowiecka, Malgorzata and Packard, Grant and {P{\'e}rez-S{\'a}nchez}, Rolando and Petrovi{\'c}, Boban and Pilati, Ronaldo and Pinter, Brad and Podesta, Lysandra and Pogge, Gabrielle and Pollmann, Monique M. H. and Rutchick, Abraham M. and Saavedra, Patricio and Saeri, Alexander K. and Salomon, Erika and Schmidt, Kathleen and Sch{\"o}nbrodt, Felix D. and Sekerdej, Maciej B. and Sirlop{\'u}, David and Skorinko, Jeanine L. M. and Smith, Michael A. and {Smith-Castro}, Vanessa and Smolders, Karin C. H. J. and Sobkow, Agata and Sowden, Walter and Spachtholz, Philipp and Srivastava, Manini and Steiner, Troy G. and Stouten, Jeroen and Street, Chris N. H. and Sundfelt, Oskar K. and Szeto, Stephanie and Szumowska, Ewa and Tang, Andrew C. W. and Tanzer, Norbert and Tear, Morgan J. and Theriault, Jordan and Thomae, Manuela and Torres, David and Traczyk, Jakub and Tybur, Joshua M. and Ujhelyi, Adrienn and {van Aert}, Robbie C. M. and {van Assen}, Marcel A. L. M. and {van der Hulst}, Marije and {van Lange}, Paul A. M. and {van 't Veer}, Anna Elisabeth and {V{\'a}squez- Echeverr{\'i}a}, Alejandro and Ann Vaughn, Leigh and V{\'a}zquez, Alexandra and Vega, Luis Diego and Verniers, Catherine and Verschoor, Mark and Voermans, Ingrid P. J. and Vranka, Marek A. and Welch, Cheryl and Wichman, Aaron L. and Williams, Lisa A. and Wood, Michael and Woodzicka, Julie A. and Wronska, Marta K. and Young, Liane and Zelenski, John M. and Zhijia, Zeng and Nosek, Brian A.},
  year = {2018},
  month = dec,
  volume = {1},
  pages = {443--490},
  issn = {2515-2459},
  doi = {10.1177/2515245918810225},
  abstract = {We conducted preregistered replications of 28 classic and contemporary published findings, with protocols that were peer reviewed in advance, to examine variation in effect magnitudes across samples and settings. Each protocol was administered to approximately half of 125 samples that comprised 15,305 participants from 36 countries and territories. Using the conventional criterion of statistical significance (p {$<$} .05), we found that 15 (54\%) of the replications provided evidence of a statistically significant effect in the same direction as the original finding. With a strict significance criterion (p {$<$} .0001), 14 (50\%) of the replications still provided such evidence, a reflection of the extremely high-powered design. Seven (25\%) of the replications yielded effect sizes larger than the original ones, and 21 (75\%) yielded effect sizes smaller than the original ones. The median comparable Cohen's ds were 0.60 for the original findings and 0.15 for the replications. The effect sizes were small ({$<$} 0.20) in 16 of the replications (57\%), and 9 effects (32\%) were in the direction opposite the direction of the original effect. Across settings, the Q statistic indicated significant heterogeneity in 11 (39\%) of the replication effects, and most of those were among the findings with the largest overall effect sizes; only 1 effect that was near zero in the aggregate showed significant heterogeneity according to this measure. Only 1 effect had a tau value greater than .20, an indication of moderate heterogeneity. Eight others had tau values near or slightly above .10, an indication of slight heterogeneity. Moderation tests indicated that very little heterogeneity was attributable to the order in which the tasks were performed or whether the tasks were administered in lab versus online. Exploratory comparisons revealed little heterogeneity between Western, educated, industrialized, rich, and democratic (WEIRD) cultures and less WEIRD cultures (i.e., cultures with relatively high and low WEIRDness scores, respectively). Cumulatively, variability in the observed effect sizes was attributable more to the effect being studied than to the sample or setting in which it was studied.},
  file = {C\:\\Users\\singm\\Zotero\\storage\\HNSXPBH7\\Klein et al. - 2018 - Many Labs 2 Investigating Variation in Replicabil.pdf},
  journal = {Advances in Methods and Practices in Psychological Science},
  language = {en},
  number = {4}
}





@article{camererEvaluatingReplicabilityLaboratory2016,
  title = {Evaluating Replicability of Laboratory Experiments in Economics},
  author = {Camerer, Colin F. and Dreber, Anna and Forsell, Eskil and Ho, Teck-Hua and Huber, J{\"u}rgen and Johannesson, Magnus and Kirchler, Michael and Almenberg, Johan and Altmejd, Adam and Chan, Taizan and Heikensten, Emma and Holzmeister, Felix and Imai, Taisuke and Isaksson, Siri and Nave, Gideon and Pfeiffer, Thomas and Razen, Michael and Wu, Hang},
  year = {2016},
  month = mar,
  volume = {351},
  pages = {1433--1436},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aaf0918},
  abstract = {Another social science looks at itself Experimental economists have joined the reproducibility discussion by replicating selected published experiments from two top-tier journals in economics. Camerer et al. found that two-thirds of the 18 studies examined yielded replicable estimates of effect size and direction. This proportion is somewhat lower than unaffiliated experts were willing to bet in an associated prediction market, but roughly in line with expectations from sample sizes and P values. Science, this issue p. 1433 The replicability of some scientific findings has recently been called into question. To contribute data about replicability in economics, we replicated 18 studies published in the American Economic Review and the Quarterly Journal of Economics between 2011 and 2014. All of these replications followed predefined analysis plans that were made publicly available beforehand, and they all have a statistical power of at least 90\% to detect the original effect size at the 5\% significance level. We found a significant effect in the same direction as in the original study for 11 replications (61\%); on average, the replicated effect size is 66\% of the original. The replicability rate varies between 67\% and 78\% for four additional replicability indicators, including a prediction market measure of peer beliefs. By several metrics, economics experiments do replicate, although not as often as predicted. By several metrics, economics experiments do replicate, although not as often as predicted.},
  chapter = {Report},
  copyright = {Copyright \textcopyright{} 2016, American Association for the Advancement of Science},
  file = {C\:\\Users\\singm\\Zotero\\storage\\XNLKF9G5\\Camerer et al. - 2016 - Evaluating replicability of laboratory experiments.pdf},
  journal = {Science},
  language = {en},
  number = {6280},
  pmid = {26940865}
}





@book{chambersSevenDeadlySins2017,
  title = {The {{Seven Deadly Sins}} of {{Psychology}}: {{A Manifesto}} for {{Reforming}} the {{Culture}} of {{Scientific Practice}}},
  shorttitle = {The {{Seven Deadly Sins}} of {{Psychology}}},
  author = {Chambers, Chris},
  year = {2017},
  month = may,
  publisher = {{Princeton University Press}},
  address = {{Princeton}},
  abstract = {Why psychology is in peril as a scientific discipline--and how to save it Psychological science has made extraordinary discoveries about the human mind, but can we trust everything its practitioners are telling us? In recent years, it has become increasingly apparent that a lot of research in psychology is based on weak evidence, questionable practices, and sometimes even fraud. The Seven Deadly Sins of Psychology diagnoses the ills besetting the discipline today and proposes sensible, practical solutions to ensure that it remains a legitimate and reliable science in the years ahead. In this unflinchingly candid manifesto, Chris Chambers draws on his own experiences as a working scientist to reveal a dark side to psychology that few of us ever see. Using the seven deadly sins as a metaphor, he shows how practitioners are vulnerable to powerful biases that undercut the scientific method, how they routinely torture data until it produces outcomes that can be published in prestigious journals, and how studies are much less reliable than advertised. He reveals how a culture of secrecy denies the public and other researchers access to the results of psychology experiments, how fraudulent academics can operate with impunity, and how an obsession with bean counting creates perverse incentives for academics. Left unchecked, these problems threaten the very future of psychology as a science--but help is here. Outlining a core set of best practices that can be applied across the sciences, Chambers demonstrates how all these sins can be corrected by embracing open science, an emerging philosophy that seeks to make research and its outcomes as transparent as possible.},
  isbn = {978-0-691-15890-7},
  language = {English}
}





@article{lewandowskyRoleConspiracistIdeation2013,
  title = {The Role of Conspiracist Ideation and Worldviews in Predicting Rejection of Science},
  author = {Lewandowsky, Stephan and Gignac, Gilles E. and Oberauer, Klaus},
  year = {2013},
  volume = {8},
  pages = {e75637},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0075637},
  abstract = {BACKGROUND: Among American Conservatives, but not Liberals, trust in science has been declining since the 1970's. Climate science has become particularly polarized, with Conservatives being more likely than Liberals to reject the notion that greenhouse gas emissions are warming the globe. Conversely, opposition to genetically-modified (GM) foods and vaccinations is often ascribed to the political Left although reliable data are lacking. There are also growing indications that rejection of science is suffused by conspiracist ideation, that is the general tendency to endorse conspiracy theories including the specific beliefs that inconvenient scientific findings constitute a "hoax." METHODOLOGY/PRINCIPAL FINDINGS: We conducted a propensity weighted internet-panel survey of the U.S. population and show that conservatism and free-market worldview strongly predict rejection of climate science, in contrast to their weaker and opposing effects on acceptance of vaccinations. The two worldview variables do not predict opposition to GM. Conspiracist ideation, by contrast, predicts rejection of all three scientific propositions, albeit to greatly varying extents. Greater endorsement of a diverse set of conspiracy theories predicts opposition to GM foods, vaccinations, and climate science. CONCLUSIONS: Free-market worldviews are an important predictor of the rejection of scientific findings that have potential regulatory implications, such as climate science, but not necessarily of other scientific issues. Conspiracist ideation, by contrast, is associated with the rejection of all scientific propositions tested. We highlight the manifold cognitive reasons why conspiracist ideation would stand in opposition to the scientific method. The involvement of conspiracist ideation in the rejection of science has implications for science communicators.},
  file = {C\:\\Users\\singm\\Zotero\\storage\\K7BECK3V\\Lewandowsky et al. - 2013 - The role of conspiracist ideation and worldviews i.pdf},
  journal = {PloS One},
  keywords = {Attitude,Culture,Data Collection,Female,Humans,Male,Models; Statistical,Politics,Rejection; Psychology,Science},
  language = {eng},
  number = {10},
  pmcid = {PMC3788812},
  pmid = {24098391}
}





@article{lewandowskyCorrectionRoleConspiracist2015,
  title = {Correction: {{The Role}} of {{Conspiracist Ideation}} and {{Worldviews}} in {{Predicting Rejection}} of {{Science}}},
  shorttitle = {Correction},
  author = {Lewandowsky, Stephan and Gignac, Gilles E. and Oberauer, Klaus},
  year = {2015},
  month = aug,
  volume = {10},
  pages = {e0134773},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0134773},
  file = {C\:\\Users\\singm\\Zotero\\storage\\ZET3ZVXK\\Lewandowsky et al. - 2015 - Correction The Role of Conspiracist Ideation and .pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {8}
}





@article{kahnemanProspectTheoryAnalysis1979,
  title = {Prospect {{Theory}}: {{An Analysis}} of {{Decision}} under {{Risk}}},
  shorttitle = {Prospect {{Theory}}},
  author = {Kahneman, Daniel and Tversky, Amos},
  year = {1979},
  month = mar,
  volume = {47},
  pages = {263},
  issn = {00129682},
  doi = {10.2307/1914185},
  file = {C\:\\Users\\singm\\Zotero\\storage\\JRP9CEKX\\Kahneman und Tversky - 1979 - Prospect Theory An Analysis of Decision under Ris.pdf},
  journal = {Econometrica},
  number = {2}
}





@article{tomNeuralBasisLoss2007,
  title = {The {{Neural Basis}} of {{Loss Aversion}} in {{Decision}}-{{Making Under Risk}}},
  author = {Tom, Sabrina M. and Fox, Craig R. and Trepel, Christopher and Poldrack, Russell A.},
  year = {2007},
  month = jan,
  volume = {315},
  pages = {515--518},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1134239},
  abstract = {People typically exhibit greater sensitivity to losses than to equivalent gains when making decisions. We investigated neural correlates of loss aversion while individuals decided whether to accept or reject gambles that offered a 50/50 chance of gaining or losing money. A broad set of areas (including midbrain dopaminergic regions and their targets) showed increasing activity as potential gains increased. Potential losses were represented by decreasing activity in several of these same gain-sensitive areas. Finally, individual differences in behavioral loss aversion were predicted by a measure of neural loss aversion in several regions, including the ventral striatum and prefrontal cortex.},
  file = {C\:\\Users\\singm\\Zotero\\storage\\KRQX4AAB\\Tom et al. - 2007 - The Neural Basis of Loss Aversion in Decision-Maki.pdf;C\:\\Users\\singm\\Zotero\\storage\\XU4RHK98\\Tom.SOM.pdf},
  journal = {Science},
  language = {en},
  number = {5811},
  pmid = {17255512}
}




@article{walasekHowMakeLoss2015,
	title = {How to make loss aversion disappear and reverse: Tests of the decision by sampling origin of loss aversion.},
	author = {{Walasek}, {Lukasz} and {Stewart}, {Neil}},
	year = {2015},
	date = {2015},
	journal = {Journal of Experimental Psychology: General},
	pages = {7--11},
	volume = {144},
	number = {1},
	doi = {10.1037/xge0000039},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xge0000039},
	langid = {en}
}


@article{harinckWhenGainsLoom2007,
  title = {When {{Gains Loom Larger Than Losses}}: {{Reversed Loss Aversion}} for {{Small Amounts}} of {{Money}}},
  shorttitle = {When {{Gains Loom Larger Than Losses}}},
  author = {Harinck, Fieke and Van Dijk, Eric and Van Beest, Ilja and Mersmann, Paul},
  year = {2007},
  month = dec,
  journal = {Psychological Science},
  volume = {18},
  number = {12},
  pages = {1099--1105},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.2007.02031.x},
  abstract = {Previous research has generally shown that people are loss averse; that is, they weigh losses more heavily than gains. In a series of three experiments, we found that for small outcomes, this pattern is reversed, and gains loom larger than losses. We explain this reversal on the basis of (a) the hedonic principle, which states that individuals are motivated to maximize pleasure and to minimize pain, and (b) the assumption that small losses are more easily discounted cognitively than large losses are.},
  language = {en},
  file = {C\:\\Users\\singm\\Zotero\\storage\\C9JR82Z5\\Harinck et al. - 2007 - When Gains Loom Larger Than Losses Reversed Loss .pdf}
}





@article{camererThreeCheersPsychological2005,
  title = {Three {{Cheers}}\textemdash{{Psychological}}, {{Theoretical}}, {{Empirical}}\textemdash for {{Loss Aversion}}},
  author = {Camerer, Colin},
  year = {2005},
  month = may,
  journal = {Journal of Marketing Research},
  volume = {42},
  number = {2},
  pages = {129--133},
  issn = {0022-2437},
  doi = {10.1509/jmkr.42.2.129.62286},
  abstract = {This note emphasizes the special role of prospect theory in drawing psychophysical considerations into theories of decision making with respect to risk. An example of such a consideration is the dependence of outcome value on a reference point and the increased sensitivity of loss relative to gain (i.e., loss aversion). Loss aversion can explain the St. Petersburg paradox without requiring concave utility, it has the correct psychological foundation, it is theoretically useful, and it is a parsimonious principle that can explain many puzzles. A few open questions are whether loss aversion is a stable feature of preference, whether it is an expression of fear, and what are its properties.},
  file = {C\:\\Users\\singm\\Zotero\\storage\\RBKJQCPT\\Camerer - 2005 - Three Cheers‚ÄîPsychological, Theoretical, Empirical.pdf}
}





@article{stewartDecisionSampling2006,
  title = {Decision by Sampling},
  author = {Stewart, Neil and Chater, Nick and Brown, Gordon D. A.},
  year = {2006},
  month = aug,
  journal = {Cognitive Psychology},
  volume = {53},
  number = {1},
  pages = {1--26},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2005.10.003},
  abstract = {We present a theory of decision by sampling (DbS) in which, in contrast with traditional models, there are no underlying psychoeconomic scales. Instead, we assume that an attribute's subjective value is constructed from a series of binary, ordinal comparisons to a sample of attribute values drawn from memory and is its rank within the sample. We assume that the sample reflects both the immediate distribution of attribute values from the current decision's context and also the background, real-world distribution of attribute values. DbS accounts for concave utility functions; losses looming larger than gains; hyperbolic temporal discounting; and the overestimation of small probabilities and the underestimation of large probabilities.},
  keywords = {Decision Making,Gains and losses,judgment,memory,Sampling,Subjective probability,Temporal discounting,Utility},
  file = {C\:\\Users\\singm\\Zotero\\storage\\KS68IK68\\Stewart et al. - 2006 - Decision by sampling.pdf}
}





@article{kellenProblemCoordinationPursuit2021,
  title = {The {{Problem}} of {{Coordination}} and the {{Pursuit}} of {{Structural Constraints}} in {{Psychology}}},
  author = {Kellen, David and {Davis-Stober}, Clintin P. and Dunn, John C. and Kalish, Michael L.},
  year = {2021},
  month = jan,
  journal = {Perspectives on Psychological Science},
  pages = {1745691620974771},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/1745691620974771},
  abstract = {Paul Meehl's famous critique detailed many of the problematic practices and conceptual confusions that stand in the way of meaningful theoretical progress in psychological science. By integrating many of Meehl's points, we argue that one of the reasons for the slow progress in psychology is the failure to acknowledge the problem of coordination. This problem arises whenever we attempt to measure quantities that are not directly observable but can be inferred from observable variables. The solution to this problem is far from trivial, as demonstrated by a historical analysis of thermometry. The key challenge is the specification of a functional relationship between theoretical concepts and observations. As we demonstrate, empirical means alone cannot determine this relationship. In the case of psychology, the problem of coordination has dramatic implications in the sense that it severely constrains our ability to make meaningful theoretical claims. We discuss several examples and outline some of the solutions that are currently available.},
  language = {en},
  keywords = {measurement,order-constrained inference,quantitative modeling,scaling,theory},
  file = {C\:\\Users\\singm\\Zotero\\storage\\8PHIQ855\\Kellen et al. - 2021 - The Problem of Coordination and the Pursuit of Str.pdf;C\:\\Users\\singm\\Zotero\\storage\\MRXMHZ5P\\Kellen et al. - 2020 - The Problem of Coordination and the Pursuit of Str.pdf}
}





@article{doyenBehavioralPrimingIt2012,
  title = {Behavioral {{Priming}}: {{It}}'s {{All}} in the {{Mind}}, but {{Whose Mind}}?},
  shorttitle = {Behavioral {{Priming}}},
  author = {Doyen, St{\'e}phane and Klein, Olivier and Pichon, Cora-Lise and Cleeremans, Axel},
  year = {2012},
  month = jan,
  journal = {PLOS ONE},
  volume = {7},
  number = {1},
  pages = {e29081},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0029081},
  abstract = {The perspective that behavior is often driven by unconscious determinants has become widespread in social psychology. Bargh, Chen, and Burrows' (1996) famous study, in which participants unwittingly exposed to the stereotype of age walked slower when exiting the laboratory, was instrumental in defining this perspective. Here, we present two experiments aimed at replicating the original study. Despite the use of automated timing methods and a larger sample, our first experiment failed to show priming. Our second experiment was aimed at manipulating the beliefs of the experimenters: Half were led to think that participants would walk slower when primed congruently, and the other half was led to expect the opposite. Strikingly, we obtained a walking speed effect, but only when experimenters believed participants would indeed walk slower. This suggests that both priming and experimenters' expectations are instrumental in explaining the walking speed effect. Further, debriefing was suggestive of awareness of the primes. We conclude that unconscious behavioral priming is real, while real, involves mechanisms different from those typically assumed to cause the effect.},
  language = {en},
  keywords = {Animal behavior,Behavior,Conceptual semantics,Experimental psychology,Priming (psychology),Social cognition,Social psychology,Time measurement},
  file = {C\:\\Users\\singm\\Zotero\\storage\\WB3SSC6V\\Doyen et al. - 2012 - Behavioral Priming It's All in the Mind, but Whos.pdf}
}





@article{harrisTrainWreckAny2021,
  title = {A {{Train Wreck}} by {{Any Other Name}}},
  author = {Harris, Christine and Rohrer, Doug and Pashler, Harold},
  year = {2021},
  month = jan,
  journal = {Psychological Inquiry},
  volume = {32},
  number = {1},
  pages = {17--23},
  publisher = {{Routledge}},
  issn = {1047-840X},
  doi = {10.1080/1047840X.2021.1889317},
  annotation = {\_eprint: https://doi.org/10.1080/1047840X.2021.1889317},
  file = {C\:\\Users\\singm\\Zotero\\storage\\E6YR5AT6\\Harris et al. - 2021 - A Train Wreck by Any Other Name.pdf}
}





@article{baumannLinearThresholdModel2020,
  title = {A Linear Threshold Model for Optimal Stopping Behavior},
  author = {Baumann, Christiane and Singmann, Henrik and Gershman, Samuel J. and von Helversen, Bettina},
  year = {2020},
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {117},
  number = {23},
  pages = {12750--12755},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2002312117},
  chapter = {Social Sciences},
  copyright = {\textcopyright{} 2020 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
  isbn = {9782002312114},
  language = {en},
  pmid = {32461363},
  keywords = {adaptive behavior,cognitive modeling,optimal stopping,sequential decision making},
  file = {C\:\\Users\\singm\\Zotero\\storage\\9AUK8S8I\\pnas.2002312117.sapp.pdf;C\:\\Users\\singm\\Zotero\\storage\\AVIJU97K\\Baumann et al. - 2020 - A linear threshold model for optimal stopping beha.pdf}
}





@article{dawModelBasedInfluencesHumans2011,
  title = {Model-{{Based Influences}} on {{Humans}}' {{Choices}} and {{Striatal Prediction Errors}}},
  author = {Daw, Nathaniel D. and Gershman, Samuel J. and Seymour, Ben and Dayan, Peter and Dolan, Raymond J.},
  year = {2011},
  month = mar,
  journal = {Neuron},
  volume = {69},
  number = {6},
  pages = {1204--1215},
  issn = {08966273},
  doi = {10.1016/j.neuron.2011.02.027},
  language = {en},
  file = {C\:\\Users\\singm\\Zotero\\storage\\GAIBFB2K\\Daw et al. - 2011 - Model-Based Influences on Humans' Choices and Stri.pdf;C\:\\Users\\singm\\Zotero\\storage\\XVH3SGAV\\Daw et al. - 2011 - Model-Based Influences on Humans' Choices and Stri.pdf}
}





@article{akamSimplePlansSophisticated2015,
  title = {Simple {{Plans}} or {{Sophisticated Habits}}? {{State}}, {{Transition}} and {{Learning Interactions}} in the {{Two}}-{{Step Task}}},
  shorttitle = {Simple {{Plans}} or {{Sophisticated Habits}}?},
  author = {Akam, Thomas and Costa, Rui and Dayan, Peter},
  year = {2015},
  month = dec,
  journal = {PLOS Computational Biology},
  volume = {11},
  number = {12},
  pages = {e1004648},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004648},
  abstract = {The recently developed `two-step' behavioural task promises to differentiate model-based from model-free reinforcement learning, while generating neurophysiologically-friendly decision datasets with parametric variation of decision variables. These desirable features have prompted its widespread adoption. Here, we analyse the interactions between a range of different strategies and the structure of transitions and outcomes in order to examine constraints on what can be learned from behavioural performance. The task involves a trade-off between the need for stochasticity, to allow strategies to be discriminated, and a need for determinism, so that it is worth subjects' investment of effort to exploit the contingencies optimally. We show through simulation that under certain conditions model-free strategies can masquerade as being model-based. We first show that seemingly innocuous modifications to the task structure can induce correlations between action values at the start of the trial and the subsequent trial events in such a way that analysis based on comparing successive trials can lead to erroneous conclusions. We confirm the power of a suggested correction to the analysis that can alleviate this problem. We then consider model-free reinforcement learning strategies that exploit correlations between where rewards are obtained and which actions have high expected value. These generate behaviour that appears model-based under these, and also more sophisticated, analyses. Exploiting the full potential of the two-step task as a tool for behavioural neuroscience requires an understanding of these issues.},
  language = {en},
  keywords = {Agent-based modeling,Behavior,Decision making,Habits,Learning,Optimization,Random walk,Regression analysis},
  file = {C\:\\Users\\singm\\Zotero\\storage\\KNG53SQZ\\Akam et al. - 2015 - Simple Plans or Sophisticated Habits State, Trans.pdf}
}





@article{greeneFMRIInvestigationEmotional2001,
  title = {An {{fMRI Investigation}} of {{Emotional Engagement}} in {{Moral Judgment}}},
  author = {Greene, Joshua D. and Sommerville, R. Brian and Nystrom, Leigh E. and Darley, John M. and Cohen, Jonathan D.},
  year = {2001},
  month = sep,
  journal = {Science},
  volume = {293},
  number = {5537},
  pages = {2105--2108},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1062872},
  abstract = {The long-standing rationalist tradition in moral psychology emphasizes the role of reason in moral judgment. A more recent trend places increased emphasis on emotion. Although both reason and emotion are likely to play important roles in moral judgment, relatively little is known about their neural correlates, the nature of their interaction, and the factors that modulate their respective behavioral influences in the context of moral judgment. In two functional magnetic resonance imaging (fMRI) studies using moral dilemmas as probes, we apply the methods of cognitive neuroscience to the study of moral judgment. We argue that moral dilemmas vary systematically in the extent to which they engage emotional processing and that these variations in emotional engagement influence moral judgment. These results may shed light on some puzzling patterns in moral judgment observed by contemporary philosophers.},
  chapter = {Report},
  language = {en},
  pmid = {11557895},
  file = {C\:\\Users\\singm\\Zotero\\storage\\RGUFULNT\\Greene et al. - 2001 - An fMRI Investigation of Emotional Engagement in M.pdf}
}





@article{lejuezEvaluationBehavioralMeasure2002,
  title = {Evaluation of a Behavioral Measure of Risk Taking: {{The Balloon Analogue Risk Task}} ({{BART}}).},
  shorttitle = {Evaluation of a Behavioral Measure of Risk Taking},
  author = {Lejuez, C. W. and Read, Jennifer P. and Kahler, Christopher W. and Richards, Jerry B. and Ramsey, Susan E. and Stuart, Gregory L. and Strong, David R. and Brown, Richard A.},
  year = {2002},
  journal = {Journal of Experimental Psychology: Applied},
  volume = {8},
  number = {2},
  pages = {75--84},
  issn = {1939-2192, 1076-898X},
  doi = {10.1037/1076-898X.8.2.75},
  language = {en},
  file = {C\:\\Users\\singm\\Zotero\\storage\\TH7D9BSJ\\Lejuez et al. - 2002 - Evaluation of a behavioral measure of risk taking.pdf}
}





@article{fignerAffectiveDeliberativeProcesses2009,
  title = {Affective and Deliberative Processes in Risky Choice: {{Age}} Differences in Risk Taking in the {{Columbia Card Task}}.},
  shorttitle = {Affective and Deliberative Processes in Risky Choice},
  author = {Figner, Bernd and Mackinlay, Rachael J. and Wilkening, Friedrich and Weber, Elke U.},
  year = {2009},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {35},
  number = {3},
  pages = {709--730},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/a0014983},
  language = {en},
  file = {C\:\\Users\\singm\\Zotero\\storage\\BGU5WB5P\\Figner et al. - 2009 - Affective and deliberative processes in risky choi.pdf}
}





@article{pedroniRiskElicitationPuzzle2017,
  title = {The Risk Elicitation Puzzle},
  author = {Pedroni, Andreas and Frey, Renato and Bruhin, Adrian and Dutilh, Gilles and Hertwig, Ralph and Rieskamp, J{\"o}rg},
  year = {2017},
  month = oct,
  journal = {Nature Human Behaviour},
  pages = {1},
  issn = {2397-3374},
  doi = {10.1038/s41562-017-0219-x},
  abstract = {Evidence shows that people's preference for risk changes considerably when measured using different methods, which led us to question whether the common practice of using a single behavioural elicitation method (EM) reflects a valid measure. The present study addresses this question by examining the across-methods consistency of observed risk preferences in 1,507 healthy participants using six EMs. Our analyses show that risk preferences are not consistent across methods when operationalized on an absolute scale, a rank scale or the level of model parameters of cumulative prospect theory. This is at least partly explained by the finding that participants do not consistently follow the same decision strategy across EMs. After controlling for methodological and human factors that may impede consistency, our results challenge the view that different EMs manage to stably capture risk preference. Instead, we interpret the results as suggesting that risk preferences may be constructed when they are elicited, and different cognitive processes can lead to varying preferences. Pedroni et al. show that risk preferences vary across behavioural elicitation methods, challenging the view that risk preferences can be consistently captured by a single method.},
  copyright = {2017 The Author(s)},
  language = {En},
  file = {C\:\\Users\\singm\\Zotero\\storage\\2432X5F9\\41562_2017_219_MOESM1_ESM.pdf;C\:\\Users\\singm\\Zotero\\storage\\3DRS8IXP\\Pedroni et al. - 2017 - The risk elicitation puzzle.pdf}
}





@article{freyRiskPreferenceShares2017,
  title = {Risk Preference Shares the Psychometric Structure of Major Psychological Traits},
  author = {Frey, Renato and Pedroni, Andreas and Mata, Rui and Rieskamp, J{\"o}rg and Hertwig, Ralph},
  year = {2017},
  month = oct,
  journal = {Science Advances},
  volume = {3},
  pages = {e1701381},
  doi = {10.1126/sciadv.1701381},
  abstract = {To what extent is there a general factor of risk preference, R, akin to g, the general factor of intelligence? Can risk preference be regarded as a stable psychological trait? These conceptual issues persist because few attempts have been made to integrate multiple risk-taking measures, particularly measures from different and largely unrelated measurement traditions (self-reported propensity measures assessing stated preferences, incentivized behavioral measures eliciting revealed preferences, and frequency measures assessing actual risky activities). Adopting a comprehensive psychometric approach (1507 healthy adults completing 39 risk-taking measures, with a subsample of 109 participants completing a retest session after 6 months), we provide a substantive empirical foundation to address these issues, finding that correlations between propensity and behavioral measures were weak. Yet, a general factor of risk preference, R, emerged from stated preferences and generalized to specific and actual real-world risky activities (for example, smoking). Moreover, R proved to be highly reliable across time, indicative of a stable psychological trait. Our findings offer a first step toward a general mapping of the construct risk preference, which encompasses both general and domain-specific components, and have implications for the assessment of risk preference in the laboratory and in the wild.},
  file = {C\:\\Users\\singm\\Zotero\\storage\\NTFWSAGF\\Frey et al. - 2017 - Risk preference shares the psychometric structure .pdf}
}





@article{ruggeriReplicatingPatternsProspect2020,
  title = {Replicating Patterns of Prospect Theory for Decision under Risk},
  author = {Ruggeri, Kai and Al{\'i}, Sonia and Berge, Mari Louise and Bertoldo, Giulia and Bj{\o}rndal, Ludvig D. and {Cortijos-Bernabeu}, Anna and Davison, Clair and Demi{\'c}, Emir and {Esteban-Serna}, Celia and Friedemann, Maja and Gibson, Shannon P. and Jarke, Hannes and Karakasheva, Ralitsa and Khorrami, Peggah R. and Kveder, Jakob and Andersen, Thomas Lind and Lofthus, Ingvild S. and McGill, Lucy and Nieto, Ana E. and P{\'e}rez, Jacobo and Quail, Sahana K. and Rutherford, Charlotte and Tavera, Felice L. and Tomat, Nastja and Reyn, Chiara Van and Ve{\'c}kalov, Bojana and Wang, Keying and Yosifova, Aleksandra and Papa, Francesca and Rubaltelli, Enrico and van der Linden, Sander and Folke, Tomas},
  year = {2020},
  month = jun,
  journal = {Nature Human Behaviour},
  volume = {4},
  number = {6},
  pages = {622--633},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-020-0886-x},
  abstract = {Prospect theory is among the most influential frameworks in behavioural science, specifically in research on decision-making under risk. Kahneman and Tversky's 1979 study tested financial choices under risk, concluding that such judgements deviate significantly from the assumptions of expected utility theory, which had remarkable impacts on science, policy and industry. Though substantial evidence supports prospect theory, many presumed canonical theories have drawn scrutiny for recent replication failures. In response, we directly test the original methods in a multinational study (n\,=\,4,098 participants, 19 countries, 13 languages), adjusting only for current and local currencies while requiring all participants to respond to all items. The results replicated for 94\% of items, with some attenuation. Twelve of 13 theoretical contrasts replicated, with 100\% replication in some countries. Heterogeneity between countries and intra-individual variation highlight meaningful avenues for future theorizing and applications. We conclude that the empirical foundations for prospect theory replicate beyond any reasonable thresholds.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
  language = {en},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Economics;Human behaviour;Psychology Subject\_term\_id: economics;human-behaviour;psychology},
  file = {C\:\\Users\\singm\\Zotero\\storage\\9RJJLIZR\\Ruggeri - Replicating patterns of prospect theory for decisi.pdf;C\:\\Users\\singm\\Zotero\\storage\\RYLTUGR9\\Ruggeri et al. - 2020 - Replicating patterns of prospect theory for decisi.pdf}
}





@article{walasekContextdependentSensitivityLosses2019,
  title = {Context-Dependent Sensitivity to Losses: {{Range}} and Skew Manipulations.},
  shorttitle = {Context-Dependent Sensitivity to Losses},
  author = {Walasek, Lukasz and Stewart, Neil},
  year = {2019},
  month = jun,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {45},
  number = {6},
  pages = {957--968},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000629},
  abstract = {The assumption that losses loom larger than gains is widely used to explain many behavioral phenomena in judgment and decision-making. It is also generally accepted that loss aversion is a stable, traitlike individual difference characterizing people's sensitivity to gains and losses. This interpretation was recently challenged by Walasek and Stewart (2015), who showed that by manipulating the range of the gains and losses used in the acceptœ™reject task it is possible to find loss aversion, loss neutrality, and a reversal of loss aversion. Here, we reexamined the claim that these context effects arise as a result of people being sensitive to the rank position of a given gain among other gains and the rank position of a loss among other losses. We used skewed distributions of outcomes to manipulate the rank position of gains and losses while keeping the range of possible outcomes constant. We found a small but robust effect of skew on the propensity to accept mixed gambles. We compared the sizes of skew and range effects and found that they are of similar magnitude but that the range effects are smaller than those reported by Walasek and Stewart. We were able to attenuate loss aversion, but we were not able to replicate Walasek and Stewart's reversal of loss aversion. We conclude that rank effects are, at least in part, responsible for the loss aversion seen in the acceptœ™reject task.},
  language = {en},
  file = {C\:\\Users\\singm\\Zotero\\storage\\MMWJY6YS\\Walasek and Stewart - 2019 - Context-dependent sensitivity to losses Range and.pdf}
}





@article{schneiderEffectsSurroundingPositive2016,
  title = {The Effects of Surrounding Positive and Negative Experiences on Risk Taking},
  author = {Schneider, Sandra and Kauffman, Sandra and Ranieri, Andrea},
  year = {2016},
  journal = {Judgment and Decision Making},
  volume = {11},
  number = {5},
  pages = {17},
  abstract = {Two experiments explored how the context of recently experiencing an abundance of positive or negative outcomes within a series of choices influences risk preferences. In each experiment, choices were made between a series of pairs of hypothetical 50/50 two-outcome gambles. Participants experienced a control set of mixed outcome gamble pairs intermingled with a randomly assigned set of (a) all-gain, (b) all-loss, or (c) a mixture of all-gain and all-loss gamble pairs. In both experiments, a positive experience led to reduced risk taking in the control set and a negative experience led to increased risk taking. These patterns persisted even after the all-gain and all-loss gamble pairs were no longer present. In addition, we showed that the good luck attributed to positive experiences was associated with decreased, rather than increased, risk taking. These results ran counter to the house money effect, and could not readily be accounted for by changes in assets. We suggest that the goals associated with the predominant valence are likely to be assimilated and applied to other choices within a given situation. We also discuss the need to learn more about the characteristics of choice bracketing and mental accounting that influence which aspects of situational context will be included or excluded from consideration when making each choice.},
  language = {en},
  file = {C\:\\Users\\singm\\Zotero\\storage\\7AZU96P6\\Schneider et al. - 2016 - The effects of surrounding positive and negative e.pdf}
}





@article{grunbaumFreudianPsychoanalyticTheory1986,
  title = {Is {{Freudian}} Psychoanalytic Theory Really Falsifiable?},
  author = {Grunbaum, Adolf},
  year = {1986},
  month = jun,
  journal = {Behavioral and Brain Sciences},
  volume = {9},
  number = {2},
  pages = {250--252},
  publisher = {{Cambridge University Press}},
  issn = {1469-1825, 0140-525X},
  doi = {10.1017/S0140525X00022512},
  abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0140525X00022512/resource/name/firstPage-S0140525X00022512a.jpg},
  language = {en},
  file = {C\:\\Users\\singm\\Zotero\\storage\\DS6K7RLH\\Grunbaum - 1986 - Is Freudian psychoanalytic theory really falsifiab.pdf}
}





@book{haigInvestigatingPsychologicalWorld2014,
  title = {Investigating the Psychological World: Scientific Method in the Behavioral Sciences},
  shorttitle = {Investigating the Psychological World},
  author = {Haig, Brian D},
  year = {2014},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass.}},
  isbn = {978-0-262-02736-6},
  language = {English},
  annotation = {OCLC: 889990976},
  file = {C\:\\Users\\singm\\Zotero\\storage\\HM9XWLFK\\Haig - 2014 - Investigating the psychological world scientific .pdf}
}





@article{mcgrawComparingGainsLosses2010,
  title = {Comparing {{Gains}} and {{Losses}}},
  author = {McGraw, A. Peter and Larsen, Jeff T. and Kahneman, Daniel and Schkade, David},
  year = {2010},
  month = oct,
  journal = {Psychological Science},
  volume = {21},
  number = {10},
  pages = {1438--1445},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797610381504},
  abstract = {Loss aversion in choice is commonly assumed to arise from the anticipation that losses have a greater effect on feelings than gains, but evidence for this assumption in research on judged feelings is mixed. We argue that loss aversion is present in judged feelings when people compare gains and losses and assess them on a common scale. But many situations in which people judge and express their feelings lack these features.When judging their feelings about an outcome, people naturally consider a context of similar outcomes for comparison (e.g., they consider losses against other losses).This process permits gains and losses to be normed separately and produces psychological scale units that may not be the same in size or meaning for gains and losses. Our experiments show loss aversion in judged feelings for tasks that encourage gain-loss comparisons, but not tasks that discourage them, particularly those using bipolar scales.},
  language = {en},
  file = {C\:\\Users\\singm\\Zotero\\storage\\L9WXTFXG\\McGraw et al. - 2010 - Comparing Gains and Losses.pdf}
}





@article{battalioTestingAlternativeModels1990,
  title = {Testing between Alternative Models of Choice under Uncertainty: {{Some}} Initial Results},
  shorttitle = {Testing between Alternative Models of Choice under Uncertainty},
  author = {Battalio, Raymond C. and Kagel, John H. and Jiranyakul, Komain},
  year = {1990},
  month = mar,
  journal = {Journal of Risk and Uncertainty},
  volume = {3},
  number = {1},
  pages = {25--50},
  issn = {1573-0476},
  doi = {10.1007/BF00213259},
  abstract = {Experiments have identified a number of well-known violations of expected utility theory, giving rise to alternative models of choice under uncertainty, all of which are able to explain these violations. In this article, predictions of several prominent rival formulations are examined. No single alternative consistently organizes choices. Among the more important inconsistencies, we identify conditions generating systematic fanning in of indifference curves in the unit probability triangle, and find risk-loving over a number of gambles with all positive payoffs, in cases where prospect theory predicts risk aversion.},
  language = {en},
  file = {C\:\\Users\\singm\\Zotero\\storage\\IRVMWU9G\\Battalio et al. - 1990 - Testing between alternative models of choice under.pdf}
}





@article{brooksLossAverseBehavior2005,
  title = {Loss {{Averse Behavior}}},
  author = {Brooks, Peter and Zank, Horst},
  year = {2005},
  month = dec,
  journal = {Journal of Risk and Uncertainty},
  volume = {31},
  number = {3},
  pages = {301--325},
  issn = {1573-0476},
  doi = {10.1007/s11166-005-5105-7},
  abstract = {A behavioral condition of loss aversion is proposed and tested. Forty-nine students participated in experiments on binary choices among lotteries involving small scale real gains and losses. At the aggregate level, a significant proportion of the choices are in the direction predicted by loss aversion. Individuals can be classified as loss averse (28 participants), gain seeking (12), and unclassified (9). A comparison with risk behavior for binary choices on lotteries involving only gains shows that risk attitudes vary across these domains of lotteries. A gender effect is also observed: proportionally more women are loss averse. In contrast to the predictions of comonotonic independence, the size of common outcomes has systematic influence on choice behavior.},
  language = {en},
  file = {C\:\\Users\\singm\\Zotero\\storage\\WSNI8D5P\\Brooks and Zank - 2005 - Loss Averse Behavior.pdf}
}





@incollection{steupEpistemology2020,
  title = {Epistemology},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  author = {Steup, Matthias and Neta, Ram},
  editor = {Zalta, Edward N.},
  year = {2020},
  edition = {Fall 2020},
  publisher = {{Metaphysics Research Lab, Stanford University}},
  abstract = {The term ``epistemology'' comes from the Greek words``episteme'' and ``logos''. ``Episteme''can be translated as ``knowledge'' or``understanding'' or ``acquaintance'', while``logos'' can be translated as ``account'' or``argument'' or ``reason''. Just as each of thesedifferent translations captures some facet of the meaning of theseGreek terms, so too does each translation capture a different facet ofepistemology itself. Although the term ``epistemology'' isno more than a couple of centuries old, the field of epistemology isat least as old as any in  philosophy.[1]  In different parts of its extensive history, different facets ofepistemology have attracted attention.  Plato's epistemology wasan attempt to understand what it was to know, and how knowledge(unlike mere true opinion) is good for the knower. Locke'sepistemology was an attempt to understand the operations of humanunderstanding, Kant's epistemology was an attempt to understandthe conditions of the possibility of human understanding, andRussell's epistemology was an attempt to understand how modernscience could be justified by appeal to sensory experience. Muchrecent work in formal epistemology is an attempt to understand how ourdegrees of confidence are rationally constrained by our evidence, andmuch recent work in feminist epistemology is an attempt to understandthe ways in which interests affect our evidence, and affect ourrational constraints more generally. In all these cases, epistemologyseeks to understand one or another kind ofcognitive success (or, correspondingly, cognitivefailure). This entry surveys the varieties of cognitivesuccess, and some recent efforts to understand some of thosevarieties.}
}





@article{pashlerLearningStylesConcepts2008,
  title = {Learning {{Styles}}: {{Concepts}} and {{Evidence}}},
  shorttitle = {Learning {{Styles}}},
  author = {Pashler, Harold and McDaniel, Mark and Rohrer, Doug and Bjork, Robert},
  year = {2008},
  month = dec,
  journal = {Psychological Science in the Public Interest},
  volume = {9},
  number = {3},
  pages = {105--119},
  publisher = {{SAGE Publications Inc}},
  issn = {1529-1006},
  doi = {10.1111/j.1539-6053.2009.01038.x},
  abstract = {The term ``learning styles'' refers to the concept that individuals differ in regard to what mode of instruction or study is most effective for them. Proponents of learning-style assessment contend that optimal instruction requires diagnosing individuals' learning style and tailoring instruction accordingly. Assessments of learning style typically ask people to evaluate what sort of information presentation they prefer (e.g., words versus pictures versus speech) and/or what kind of mental activity they find most engaging or congenial (e.g., analysis versus listening), although assessment instruments are extremely diverse. The most common\textemdash but not the only\textemdash hypothesis about the instructional relevance of learning styles is the meshing hypothesis, according to which instruction is best provided in a format that matches the preferences of the learner (e.g., for a ``visual learner,'' emphasizing visual presentation of information)., The learning-styles view has acquired great influence within the education field, and is frequently encountered at levels ranging from kindergarten to graduate school. There is a thriving industry devoted to publishing learning-styles tests and guidebooks for teachers, and many organizations offer professional development workshops for teachers and educators built around the concept of learning styles., The authors of the present review were charged with determining whether these practices are supported by scientific evidence. We concluded that any credible validation of learning-styles-based instruction requires robust documentation of a very particular type of experimental finding with several necessary criteria. First, students must be divided into groups on the basis of their learning styles, and then students from each group must be randomly assigned to receive one of multiple instructional methods. Next, students must then sit for a final test that is the same for all students. Finally, in order to demonstrate that optimal learning requires that students receive instruction tailored to their putative learning style, the experiment must reveal a specific type of interaction between learning style and instructional method: Students with one learning style achieve the best educational outcome when given an instructional method that differs from the instructional method producing the best outcome for students with a different learning style. In other words, the instructional method that proves most effective for students with one learning style is not the most effective method for students with a different learning style., Our review of the literature disclosed ample evidence that children and adults will, if asked, express preferences about how they prefer information to be presented to them. There is also plentiful evidence arguing that people differ in the degree to which they have some fairly specific aptitudes for different kinds of thinking and for processing different types of information. However, we found virtually no evidence for the interaction pattern mentioned above, which was judged to be a precondition for validating the educational applications of learning styles. Although the literature on learning styles is enormous, very few studies have even used an experimental methodology capable of testing the validity of learning styles applied to education. Moreover, of those that did use an appropriate method, several found results that flatly contradict the popular meshing hypothesis., We conclude therefore, that at present, there is no adequate evidence base to justify incorporating learning-styles assessments into general educational practice. Thus, limited education resources would better be devoted to adopting other educational practices that have a strong evidence base, of which there are an increasing number. However, given the lack of methodologically sound studies of learning styles, it would be an error to conclude that all possible versions of learning styles have been tested and found wanting; many have simply not been tested at all. Further research on the use of learning-styles assessment in instruction may in some cases be warranted, but such research needs to be performed appropriately.},
  language = {en},
  file = {C\:\\Users\\singm\\Zotero\\storage\\MT6V3UHE\\Pashler et al. - 2008 - Learning Styles Concepts and Evidence.pdf}
}



