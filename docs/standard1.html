<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 The Standard Approach for One Independent Variable | Introduction to Statistics for Experimental Psychology with R</title>
<meta name="author" content="Henrik Singmann">
<meta name="description" content="In this chapter we are introducing the standard statistical approach for analysing experimental data with one independent variable (i.e., one factor). The simple case for this is a study comparing...">
<meta name="generator" content="bookdown 0.24.1 with bs4_book()">
<meta property="og:title" content="Chapter 5 The Standard Approach for One Independent Variable | Introduction to Statistics for Experimental Psychology with R">
<meta property="og:type" content="book">
<meta property="og:description" content="In this chapter we are introducing the standard statistical approach for analysing experimental data with one independent variable (i.e., one factor). The simple case for this is a study comparing...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 5 The Standard Approach for One Independent Variable | Introduction to Statistics for Experimental Psychology with R">
<meta name="twitter:description" content="In this chapter we are introducing the standard statistical approach for analysing experimental data with one independent variable (i.e., one factor). The simple case for this is a study comparing...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.10/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.5.1/tabs.js"></script><script src="libs/bs3compat-0.2.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="include/style.css">
<link rel="stylesheet" href="include/webex.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Introduction to Statistics for Experimental Psychology with <code>R</code></a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="role-of-statistics-in-the-research-process.html"><span class="header-section-number">1</span> Role of Statistics in the Research Process</a></li>
<li><a class="" href="chapter-1-quiz.html">Chapter 1: Quiz</a></li>
<li><a class="" href="research-designs.html"><span class="header-section-number">2</span> Data and Research Designs</a></li>
<li><a class="" href="chapter-2-quiz.html">Chapter 2: Quiz</a></li>
<li><a class="" href="tidyverse-intro.html"><span class="header-section-number">3</span> Short Introduction to R and the tidyverse</a></li>
<li><a class="" href="tidyverse-exercises.html">tidyverse: Example, Quiz, and Exercises</a></li>
<li><a class="" href="ggplot2-intro.html"><span class="header-section-number">4</span> Data Visualisation with ggplot2</a></li>
<li><a class="" href="ggplot-exercises.html">ggplot2: Example, Quiz, and Exercises</a></li>
<li><a class="active" href="standard1.html"><span class="header-section-number">5</span> The Standard Approach for One Independent Variable</a></li>
<li><a class="" href="case-study-laptop.html"><span class="header-section-number">6</span> Case Study 1: More Results from Note Taking Studies</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/singmann/stats_for_experiments">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="standard1" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> The Standard Approach for One Independent Variable<a class="anchor" aria-label="anchor" href="#standard1"><i class="fas fa-link"></i></a>
</h1>
<p>In this chapter we are introducing the standard statistical approach for analysing experimental data with one independent variable (i.e., one factor). The simple case for this is a study comparing two experimental conditions on one dependent variable. We will exemplify the standard approach for this design using a recent and straightforward experiment.</p>
<div id="ex:urry" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Example Data: Note Taking Experiment<a class="anchor" aria-label="anchor" href="#ex:urry"><i class="fas fa-link"></i></a>
</h2>
<p>Heather Urry and 87 of her undergraduate and graduate students <span class="citation">(<a href="references.html#ref-urry2021" role="doc-biblioref">Urry et al. 2021</a>)</span> (yes, all 87 students are co-authors!) compared the effectiveness of taking notes on a laptop versus longhand (i.e., pen and paper) for learning from lectures. 142 participants (which differed from the 88 authors) first viewed one of several 15 minutes lectures (TED talks) during which they were asked to take notes either on a laptop or with pen and paper. As this was a proper experiment, participants were randomly assigned to either the laptop (<span class="math inline">\(N = 68\)</span>) or longhand condition (<span class="math inline">\(N = 74\)</span>). After a 30 minutes delay, participants were quizzed on the content of the lecture. The answers from each participant were then independently rated from several raters (which agreed very strongly with each other; i.e., showed high inter-rater reliability) using a standardised scoring key. This procedure produced one memory score per participant representing the percentage of information remembered ranging from 0 (= no memory) to 100 (= perfect memory).<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Urry et al. transformed the memory scores before their analysis based on an earlier paper doing the same. This was initially done to make it easy to compare the results for different types of memory scores &lt;span class="citation"&gt;(&lt;a href="references.html#ref-muellerPenMightierKeyboard2014" role="doc-biblioref"&gt;Mueller and Oppenheimer 2014&lt;/a&gt;)&lt;/span&gt;. However, the memory scores from 0 to 100 are easier to understand than the transformed scores. As the results are qualitatively the same for both approaches, we use the untransformed memory scores here.&lt;/p&gt;'><sup>44</sup></a> Figure <a href="standard1.html#fig:laptop-dist">5.1</a> below shows the memory scores across both note taking conditions.</p>
<div class="webex-solution">
<button>
Show Code
</button>
<div>
<p>
<em>Note:</em> The code below is only included for advanced readers or general interest. Understanding the code is not necessary for understanding the content of the chapter.
</p>
</div>
<div class="sourceCode" id="cb135"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://tidyverse.tidyverse.org">"tidyverse"</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="http://afex.singmann.science/">"afex"</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/eclarke/ggbeeswarm">"ggbeeswarm"</a></span><span class="op">)</span>  <span class="co">## only needed later, but already loaded here</span>
<span class="fu">theme_set</span><span class="op">(</span><span class="fu">theme_bw</span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">15</span><span class="op">)</span> <span class="op">+</span> 
            <span class="fu">theme</span><span class="op">(</span>legend.position<span class="op">=</span><span class="st">"bottom"</span>, 
                  panel.grid.major.x <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"laptop_urry"</span>, package <span class="op">=</span> <span class="st">"afex"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234566</span><span class="op">)</span> <span class="co">## needed to ensure jittered points are at same position</span>
<span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">laptop_urry</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">condition</span>, y <span class="op">=</span> <span class="va">overall</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_violin</span><span class="op">(</span>draw_quantiles <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">ggbeeswarm</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ggbeeswarm/man/geom_quasirandom.html">geom_quasirandom</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">stat_summary</span><span class="op">(</span>colour <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">labs</span><span class="op">(</span>y <span class="op">=</span> <span class="st">"memory score"</span><span class="op">)</span>
<span class="co"># to show figure execute (without comment):</span>
<span class="co"># p1</span></code></pre></div>
</div>
<div class="figure">
<span style="display:block;" id="fig:laptop-dist"></span>
<img src="02-standard_approach_files/figure-html/laptop-dist-1.png" alt="Distribution of memory scores from Urry et al. (2021) across the two note taking conditions." width="100%"><p class="caption">
Figure 5.1: Distribution of memory scores from Urry et al. (2021) across the two note taking conditions.
</p>
</div>
<p>In Figure <a href="standard1.html#fig:laptop-dist">5.1</a>, each black point shows the memory score of one participant so the full distribution of the data is visible. The shape of the distribution is also shown via a violin plot (i.e., the black outline around the points) to which we have added three lines representing three summary statistics of the data. From top to bottom these lines are the 75% quantile, the 50% quantile (i.e., the median), and the 25% quantile. The red points show the mean and the associated error bars show the standard error of the mean<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;We will discuss standard errors in detail in the coming chapters. Until then, it is enough to understand the standard error as a representation of the statistical precision of the mean. In other words, the larger the standard error, the less sure we are about the “true” value of the mean (again, what we mean with true will be discussed later).&lt;/p&gt;"><sup>45</sup></a>. We see that the two means are quite similar, although the mean in the laptop condition is slightly larger, by 2.0 points (mean laptop = 68.2, mean longhand = 66.2).</p>
</div>
<div id="generalising-from-sample-to-population" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> Generalising From Sample to Population<a class="anchor" aria-label="anchor" href="#generalising-from-sample-to-population"><i class="fas fa-link"></i></a>
</h2>
<p>The previous paragraph provide us with <em>descriptive statistics</em> describing the results in the experiment by <span class="citation"><a href="references.html#ref-urry2021" role="doc-biblioref">Urry et al.</a> (<a href="references.html#ref-urry2021" role="doc-biblioref">2021</a>)</span>: There is a memory difference of 2.0 points on the scale from 0 to 100 between the laptop and the longhand condition for the <em>sample</em> of 142 participants. However, as researchers we are usually not primarily interested what happens in our sample. What we would like to know if our results generalise to the <em>population</em> from which this sample is drawn.</p>
<p>Let’s clarify what we mean with “population” and “sample,” as these are two key concepts in statistics, even though this discussion leads us a bit on a tangent. One way of thinking about these terms is that the population encompasses all individual that could in principle take part in the study whereas the sample are the particular individuals for which we have data. In this sense, the population are all <em>potential participants</em> whereas the sample are the <em>actual participants</em> of a study. Consequently, the sample is always a subset of the population; we say the sample is <em>drawn</em> from the population.</p>
<p>In the case of <span class="citation"><a href="references.html#ref-urry2021" role="doc-biblioref">Urry et al.</a> (<a href="references.html#ref-urry2021" role="doc-biblioref">2021</a>)</span>, we should probably understand the population as undergraduate students from Tufts University, a research intensive (so-called <em>R1</em>) US university. This is the technically appropriate definition as all participants were undergraduates from Tufts university (i.e., participants were drawn from the pool of Tufts University undergraduates). The problem with this understanding of population is that the possible generalisation of the results is somewhat limited. We are not really interested whether the memory difference between note taking with laptop versus longhand only holds for Tufts undergraduates, but whether it holds for <em>students in general</em>.</p>
<p>The population we are actually interested in is all students, including students at very different institutions (e.g., students at Universities in non-Western countries) and future students that might take notes either in longhand format or with a laptop (even students not yet born). Ideally, we hope that our results generalise to this population of students. As undergraduates from Tufts are also a subset of this larger population, we might wonder whether we can also generalise to this population. Whether or not this generalisation is permitted is not a statistical question, but a question of external validity (see Section <a href="research-designs.html#internal-external-validity">2.5.3</a>). It depends on how <em>representative</em> Tufts undergraduates are with respect to our research question for the overall population of students. If, for example, there is something special about how Tufts students take notes or remember information (or about students on the US east coast, or students at R1 US Universities, or …), then our generalisation would only hold for this sub-population of students and not all students. To stay within the terminology introduced in this book, the question is whether there are plausible <em>alternative explanations</em> preventing us to generalise from one population to the other.</p>
<p>To sum up, the statistical methods introduced below only permit the generalisation from the sample to the actual population from which this sample is drawn. If our sample are only undergraduate students from a specific institution (as is commonly the case), then strictly speaking the statistical methods only permit to generalise to the population of students from this institution.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Very strictly speaking this generalisation only holds if the sample is &lt;em&gt;drawn randomly&lt;/em&gt; from the population. Drawn randomly means that every member of the population has the same probability to be part of the sample. It is clear that in many situations this is not the case. For example, participating in psychological studies is a course or degree requirement of many psychology programs. As a consequence, psychology students are usually vastly overrepresented in undergraduate samples compared to students studying other subjects (e.g., engineering students). The degree to which this is a problem depends on whether we can come up with plausible arguments why a specific non-random sample is unrepresentative of the population. In general, systematic differences – such as over-representation of psychology students compared to other students in psychological research – are a serious problem if the research question is related to the systematic difference. For example, when studying students’ mathematical abilities, a sample that does not contain any STEM students will likely only produce results of limited generalisability.&lt;/p&gt;"><sup>46</sup></a> Whether we can generalise to the larger population we are usually interested in (e.g., all students or all humans), is not a question statistical methods can solve. This can be seen as yet another epistemic gap that needs to be bridged using non-statistical arguments from the researcher. For example, one way to make a convincing case that a finding generalises to the larger population is to collect data from a larger population and show that it does generalise to that population. For example, instead of only collecting data from Western undergraduate students, we could attempt to collect data from students from other parts of the world.</p>
<p>Interestingly, a recent large scale analysis replicating (i.e., repeating) 28 classical psychological phenomena across 36 countries and territories found that overall differences between countries and cultures were surprisingly small for the specific phenomena investigated <span class="citation">(<a href="references.html#ref-kleinManyLabsInvestigating2018" role="doc-biblioref">Klein et al. 2018</a>)</span>, with few exceptions. So whereas even in this large study most participants were still mostly undergraduate students, albeit from very different parts of the world, it provides some assurances that many phenomena studied in psychology at least generalise from undergraduate populations at specific institutions to undergraduate populations world wide. Of course, whether this also holds for the specific research question investigated here cannot be conclusively answered as it was not included in this study.</p>
</div>
<div id="nhst-logic" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> The Logic of Inferential Statistics<a class="anchor" aria-label="anchor" href="#nhst-logic"><i class="fas fa-link"></i></a>
</h2>
<p>Going beyond the the present sample is the goal of <em>inferential statistics</em>. There are different inferential statistical approaches, and we are focussing on the most popular one, <em>null hypothesis significance testing</em> (NHST). We will describe NHST more thoroughly in a later chapter, but will already introduce its main ideas here. For NHST, the question of generalising from sample to population is about two different possible true states of the world: There either is no difference in conditions means in the population – in which case the mean difference observed in our sample is only due to chance – or there is a difference in the condition means in the population.</p>
<p>To decide between these possibilities, we set up a <em>statistical model</em> for the data. This statistical model allows us to assess if there is no difference in the population – we call this possible state of the world the <em>null hypothesis</em>.
More specifically, the statistical model allows us to test how compatible the observed data is with the null hypothesis of no difference. The test of the null hypothesis proceeds as follows:</p>
<ol style="list-style-type: decimal">
<li>We assume that the state of the world in which there is no difference in the population means is true.</li>
<li>Based on this assumption we calculate how likely it is to observe a difference as large as the one we have observed in our sample. This is done by comparing the observed level of noise with the observed difference – that is, the observed difference between conditions. If the observed difference is small given the observed level of noise, it is likely that such a difference comes from a state of the world in which there is no difference in the population means. If the observed difference is large given the observed level of noise, it is unlikely that such a difference comes from a state of the world in which there is no difference.</li>
<li>If the probability of observing a difference as large as the one we have is very small, we take this as evidence that the null hypothesis of no difference is not true – we <em>reject the null hypothesis</em>.</li>
<li>We act as if there were a difference in the population. In this case (i.e., we reject the null hypothesis and act as if there is a difference), we say our experimental manipulation <em>has an effect</em>.</li>
</ol>
<p>As is clear from this description, the logic underlying inferential statistics using NHST is not trivial. To make it clearer, let us apply the logic to the example data. We want to know whether the observed mean memory difference between note taking with a laptop and note taking in long hand format in our sample generalises to the population of students that take note in either of these formats. To do so, we set up a statistical model for our data. This model allows us to test how compatible our data is with the null hypothesis that there is no mean memory difference in the population. This is done by comparing the overall noise in the data (i.e., the variability visible in Figure <a href="standard1.html#fig:laptop-dist">5.1</a>) to the observed difference between conditions.</p>
<p>Specifically, the model allows us to calculate the probability of obtaining a memory difference as large as the one we have observed assuming the there is no mean memory difference in the population. If our data is incompatible with the null hypothesis – that is, it is unlikely to obtain a memory difference as large as the one we have observed if the null hypothesis were true – we reject the null hypothesis of no mean memory difference in the population. Because we reject the null hypothesis, we then act as if there was a mean memory difference in the population. In other words, we then act as if the type of note taking had an effect on memory after lectures in the population.</p>
<p>Even though the logic of NHST is not necessarily intuitive, it is clearly helpful for researchers. After running an experiment we really would like to know if the difference observed in our experiment (i.e., in our sample) is meaningful in the sense that it generalises to the population from which we have drawn our sample. And in almost every actual experiment there is some mean difference between the condition (i.e., it is extreme unlikely that both conditions have exactly the same mean). Thus, we pretty much always face this question. NHST allows us to test whether the observed difference is compatible with a world in which there is no difference. If this is unlikely, we decide – that is, we act as if – there was a difference.</p>
<p>What we can see from spelling out the logic in detail is that there are quite a few inferential steps we have to make to get to what we want. We design experiments with the goal in mind to find a difference between the different experimental conditions. However, we then do not test this directly. Instead, we test the compatibility of the data with the converse of what we are actually interested in – the null hypothesis of no effect. If this test “fails” (i.e., shows that the data is likely incompatible with the null hypothesis) we then make two inferential steps. First we reject the null hypothesis and then we act as if there were a difference. Both of these inferential steps are not necessitated logically. What this means is what we have already discussed when discussing the second inferential gap (Section <a href="role-of-statistics-in-the-research-process.html#epistemic-gap-2-signal-versus-noise">1.3.2</a>), inferences based on NHST alone are never extremely strong.</p>
<p>NHST is the de facto standard procedure for inferential statistics across empirical sciences (i.e., not only in psychology and related disciplines). Understanding the logic of NHST will enable you to understand the majority of empirical papers and will also allow you to apply inferential statistics in your own research. Nevertheless, there exist a long list of popular criticisms of NHST <span class="citation">(e.g., <a href="references.html#ref-rozeboom1960" role="doc-biblioref">Rozeboom 1960</a>; <a href="references.html#ref-meehl1978" role="doc-biblioref">Meehl 1978</a>; <a href="references.html#ref-cohen1994" role="doc-biblioref">Cohen 1994</a>; <a href="references.html#ref-nickerson2000" role="doc-biblioref">Nickerson 2000</a>; <a href="references.html#ref-wagenmakers2007" role="doc-biblioref">Wagenmakers 2007</a>)</span>. We will discuss these criticisms in more detail in later chapters, but for now it is important to realise that NHST does not allow to test, or prove, whether there is a mean difference in the population. The only thing NHST calculates is the probability of how compatible the data is with the null hypothesis. If this probability is low that does not necessarily mean that there is a difference. Likewise, if this probability is high that does not necessarily mean there is no difference. All inferences we draw based on NHST results are probabilistic in itself (i.e., can be false). So the most important rule when interpreting the results from NHST is to be humble. NHST never “proves” or “confirms” anything. Instead, NHST results “suggest” or “indicate” certain interpretations. If we do not over-interpret results, but instead stay humble in our interpretations, we are unlikely to fall prey to the common (and often justifiable) criticisms of the NHST framework.</p>
</div>
<div id="basic-stats-model" class="section level2" number="5.4">
<h2>
<span class="header-section-number">5.4</span> The Basic Statistical Model<a class="anchor" aria-label="anchor" href="#basic-stats-model"><i class="fas fa-link"></i></a>
</h2>
<p>To apply inferential statistics in the NHST framework to our data, we begin by setting up a <em>statistical model</em> to the data. A statistical model attempts to explain (or predict) the observed values of the dependent variable (DV) from the independent variable (IV).<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;All statistical models considered in this book are solely based on observable quantities. We predict the DV (i.e., what we measure) from the IVs we either manipulate (in experiments) or observe/measure (for non-experimental DVs). However, statistical models can also use non-observable (latent) quantities to explain the DV. Popular examples in psychology are structural equation models &lt;span class="citation"&gt;(e.g., &lt;a href="references.html#ref-kline2015" role="doc-biblioref"&gt;Kline 2015&lt;/a&gt;)&lt;/span&gt; or cognitive models &lt;span class="citation"&gt;(e.g., &lt;a href="references.html#ref-lee2013" role="doc-biblioref"&gt;Lee and Wagenmakers 2013&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;'><sup>47</sup></a> In the experimental context this means predicting our observed outcome, the DV, from the experimental manipulation, the IV.</p>
<p>The basic statistical model partitions the observed DV into three parts that: the overall mean, which for reasons that will become clear later is called the <em>intercept</em>, the effect of the IV, and the part of the data that cannot be explained by the model, the <em>residuals</em>. When summing these three parts together, they result in the observed value. In mathematical form we can express this as</p>
<span class="math display" id="eq:statmodel">\[\begin{equation}
\text{DV} = \underbrace{\text{intercept}}_{\text{overall mean}} + \text{IV-effect} + \text{residual}.
\tag{5.1}
\end{equation}\]</span>
<p>(For those not used to reading mathematical expressions, the point at the end of the equation is simply a full stop that ends the sentence and has no mathematical meaning.) As someone without a mathematics background myself, I know that equations in a text are often more intimidating than immediately useful. Consequently, before moving on it makes sense to go through this equation in more detail. Furthermore, all statistical analyses discussed in this book are applications of Equation <a href="standard1.html#eq:statmodel">(5.1)</a>. This equation forms the foundation for the statistical analysis of experimental data and thus understanding it will unlock all analyses discussed in this book. Consequently, it makes sense to spend more time on it.</p>
<p>Let us consider the the variables in Equation <a href="standard1.html#eq:statmodel">(5.1)</a> in more detail. When doing so, we also consider how many different possible values each variable can take on.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Equation &lt;a href="standard1.html#eq:statmodel"&gt;(5.1)&lt;/a&gt; is displayed in simplified and not fully correct form. Mathematically correct would be that either each variable (i.e., &lt;span class="math inline"&gt;\(\text{DV}\)&lt;/span&gt;, &lt;span class="math inline"&gt;\(\text{intercept}\)&lt;/span&gt;, &lt;span class="math inline"&gt;\(\text{IV-effect}\)&lt;/span&gt;, and &lt;span class="math inline"&gt;\(\text{residual}\)&lt;/span&gt;) has an index, such as &lt;span class="math inline"&gt;\(i\)&lt;/span&gt;, that goes from 1 to &lt;span class="math inline"&gt;\(N\)&lt;/span&gt; (where &lt;span class="math inline"&gt;\(N\)&lt;/span&gt; is the total number of observations) or that each variables is a vector (i.e., holds multiple values) of length &lt;span class="math inline"&gt;\(N\)&lt;/span&gt;.&lt;/p&gt;'><sup>48</sup></a> The following Figure, a variant of Figure <a href="standard1.html#fig:laptop-dist">5.1</a>, shows the elements graphically and we explain them in the text just below.</p>
<div class="webex-solution">
<button>
Show Code
</button>
<div>
<p>
<em>Note:</em> The code below is only included for advanced readers or general interest. Understanding the code is not necessary for understanding the content of the chapter.
</p>
</div>
<div class="sourceCode" id="cb136"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234566</span><span class="op">)</span>  <span class="co">## needed to ensure jittered points are at same position</span>
<span class="va">p1_de</span> <span class="op">&lt;-</span> <span class="fu">ggplot_build</span><span class="op">(</span><span class="va">p1</span><span class="op">)</span>
<span class="co">#&gt; No summary function supplied, defaulting to `mean_se()`</span>

<span class="va">lap2</span> <span class="op">&lt;-</span> <span class="va">laptop_urry</span> <span class="op">%&gt;%</span> 
  <span class="fu">mutate</span><span class="op">(</span>xpoint <span class="op">=</span> <span class="va">p1_de</span><span class="op">$</span><span class="va">data</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>

<span class="va">lap3</span> <span class="op">&lt;-</span> <span class="va">laptop_urry</span> <span class="op">%&gt;%</span> 
  <span class="fu">group_by</span><span class="op">(</span><span class="va">condition</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">summarise</span><span class="op">(</span>overall <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">overall</span><span class="op">)</span><span class="op">)</span>

<span class="va">lap4</span> <span class="op">&lt;-</span> <span class="va">lap3</span> <span class="op">%&gt;%</span> 
  <span class="fu">summarise</span><span class="op">(</span>overall <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">overall</span><span class="op">)</span><span class="op">)</span>

<span class="va">lap5</span> <span class="op">&lt;-</span> <span class="va">p1_de</span><span class="op">$</span><span class="va">data</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op">%&gt;%</span> 
  <span class="fu">group_by</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">summarise</span><span class="op">(</span>xmin <span class="op">=</span> <span class="fu">first</span><span class="op">(</span><span class="va">xmin</span><span class="op">)</span>,
            xmax <span class="op">=</span> <span class="fu">first</span><span class="op">(</span><span class="va">xmax</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">bind_cols</span><span class="op">(</span><span class="va">lap3</span><span class="op">)</span>


<span class="va">lap6</span> <span class="op">&lt;-</span> <span class="va">p1_de</span><span class="op">$</span><span class="va">data</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span> <span class="op">%&gt;%</span> 
  <span class="fu">group_by</span><span class="op">(</span><span class="va">group</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">mutate</span><span class="op">(</span>overall <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">as_tibble</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">select</span><span class="op">(</span><span class="op">-</span><span class="va">size</span>, <span class="op">-</span> <span class="va">fill</span>, <span class="op">-</span><span class="va">alpha</span>, <span class="op">-</span> <span class="va">stroke</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234566</span><span class="op">)</span>
<span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">laptop_urry</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">condition</span>, y <span class="op">=</span> <span class="va">overall</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_violin</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_segment</span><span class="op">(</span>data <span class="op">=</span> <span class="va">lap6</span>, 
               mapping <span class="op">=</span> <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, xend <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">overall</span>, yend <span class="op">=</span> <span class="va">y</span><span class="op">)</span>,
               colour <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">ggbeeswarm</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ggbeeswarm/man/geom_quasirandom.html">geom_quasirandom</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_hline</span><span class="op">(</span>yintercept <span class="op">=</span> <span class="va">lap4</span><span class="op">$</span><span class="va">overall</span>, linetype <span class="op">=</span> <span class="fl">3</span>, colour <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_segment</span><span class="op">(</span>data <span class="op">=</span> <span class="va">lap5</span>, mapping <span class="op">=</span> <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">xmin</span>, xend <span class="op">=</span> <span class="va">xmax</span>,
                                          y <span class="op">=</span> <span class="va">overall</span>, yend <span class="op">=</span> <span class="va">overall</span><span class="op">)</span>,
               colour <span class="op">=</span> <span class="st">"red"</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">stat_summary</span><span class="op">(</span>colour <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">labs</span><span class="op">(</span>y <span class="op">=</span> <span class="st">"memory score"</span><span class="op">)</span>
<span class="co"># to show figure execute (without comment):</span>
<span class="co"># p2</span></code></pre></div>
</div>
<div class="figure">
<span style="display:block;" id="fig:laptop-model"></span>
<img src="02-standard_approach_files/figure-html/laptop-model-1.png" alt="Data from Urry et al. (2021) showing the overall mean (intercept, blue dotted line), the condition specific effects (difference between dashed red lines for the condition means and the blue line), and the residuals (grey lines from condition means to data points)." width="100%"><p class="caption">
Figure 5.2: Data from Urry et al. (2021) showing the overall mean (intercept, blue dotted line), the condition specific effects (difference between dashed red lines for the condition means and the blue line), and the residuals (grey lines from condition means to data points).
</p>
</div>
<ul>
<li><p><span class="math inline">\(\text{DV}\)</span>: The dependent variable, DV, are the observed values, one for each observation/participant. For the example data this are all the 142 black data points shown in Figure <a href="standard1.html#fig:laptop-model">5.2</a>. Thus, our statistical model tries to explain the individually observed values.</p></li>
<li><p><span class="math inline">\(\text{intercept}\)</span>: The intercept represents the overall mean. Consequently, we only have one intercept (i.e., the intercept is the same for each observation). In experimental designs we define this as the mean of all condition means. For the example data the intercept is (68.2 + 66.2) / 2 = 67.2 and is shown as a blue dotted line in Figure <a href="standard1.html#fig:laptop-model">5.2</a>.</p></li>
<li><p><span class="math inline">\(\text{IV-effect}\)</span>: The IV-effect represents the signal, the effect of our independent variable which we define as the difference between the condition means and the intercept (i.e., the deviation of the condition means from the intercept). Thus, we always have as many different IV-effects as we have conditions. For the example data with only two conditions, we only have two different IV-effects, both of which with the same magnitude and only differ in sign, 1.0 for the laptop condition and -1.0 for the longhand condition. If we add these values to the intercept, we get the condition means. As we will discuss further below, this is the most relevant part for answering the statistical question of interest. In Figure <a href="standard1.html#fig:laptop-model">5.2</a>, the red dashed line (and the red points) show the condition means, thus the condition effects are the differences between the blue line and the red lines.</p></li>
<li><p><span class="math inline">\(\text{residual}\)</span>: The residuals are the idiosyncratic aspects of the data that are left unexplained by the statistical model, the noise in the data. As the model only predicts the condition means (i.e., intercepts plus independent variable), these are the deviations of the individual observations from the condition means. Thus, as for the DV, we have as many residuals as we have values of the DV. In Figure <a href="standard1.html#fig:laptop-model">5.2</a>, the residuals are shown as grey lines from the condition means to each data point. This is all the information (or variability in the data) our model cannot explain.</p></li>
</ul>
<div id="model-predictions" class="section level3" number="5.4.1">
<h3>
<span class="header-section-number">5.4.1</span> Model Predictions<a class="anchor" aria-label="anchor" href="#model-predictions"><i class="fas fa-link"></i></a>
</h3>
<p>A simplification of Equation <a href="standard1.html#eq:statmodel">(5.1)</a> that makes it clearer what the statistical model predicts is obtained if we ignore the residuals for a moment. As a reminder, the residuals are the part of the data that remains unexplained. In other words, these represent the noise – all the idiosyncratic parts of the data independent of our manipulation (e.g., some participants have better memory than others independent of how they took notes). What remains from our statistical model if we ignore all idiosyncratic aspects are only the predictions based on our IV. In the case of experimental data, the IV is the experimental condition. Thus, what a statistical model actually predicts is the means of the experimental conditions. We can again formalise this as</p>
<span class="math display" id="eq:predmodel">\[\begin{equation}
\hat{\text{DV}} = \text{intercept} + \text{IV-effect}.
\tag{5.2}
\end{equation}\]</span>
<p>Here, the hat symbol (<span class="math inline">\(\hat{}\)</span>) means predicted value. Thus in contrast to the actual DV above, we only have the predicted DV in this equation.</p>
<p>When performing statistical analyses it sometimes help to remind oneself that all a standard statistical model predicts are the condition means. We generally do not make predictions about individual participants or consider other factors that are not part of the model. We only predict, and are interested in, the condition means.</p>
</div>
<div id="statistical-model-for-the-example-data" class="section level3" number="5.4.2">
<h3>
<span class="header-section-number">5.4.2</span> Statistical Model for the Example Data<a class="anchor" aria-label="anchor" href="#statistical-model-for-the-example-data"><i class="fas fa-link"></i></a>
</h3>
<p>Let us take a look at the first six participants and their values for all the variables in the basic statistical model to get a better understanding of Equation <a href="standard1.html#eq:statmodel">(5.1)</a>.</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="left">pid</th>
<th align="left">condition</th>
<th align="right">overall</th>
<th align="right">intercept</th>
<th align="right">iv_effect</th>
<th align="right">prediction</th>
<th align="right">residual</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">laptop</td>
<td align="right">65.8</td>
<td align="right">67.2</td>
<td align="right">1</td>
<td align="right">68.2</td>
<td align="right">-2.4</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">longhand</td>
<td align="right">75.8</td>
<td align="right">67.2</td>
<td align="right">-1</td>
<td align="right">66.2</td>
<td align="right">9.6</td>
</tr>
<tr class="odd">
<td align="left">4</td>
<td align="left">longhand</td>
<td align="right">50.0</td>
<td align="right">67.2</td>
<td align="right">-1</td>
<td align="right">66.2</td>
<td align="right">-16.2</td>
</tr>
<tr class="even">
<td align="left">5</td>
<td align="left">laptop</td>
<td align="right">89.0</td>
<td align="right">67.2</td>
<td align="right">1</td>
<td align="right">68.2</td>
<td align="right">20.8</td>
</tr>
<tr class="odd">
<td align="left">6</td>
<td align="left">longhand</td>
<td align="right">75.6</td>
<td align="right">67.2</td>
<td align="right">-1</td>
<td align="right">66.2</td>
<td align="right">9.4</td>
</tr>
<tr class="even">
<td align="left">8</td>
<td align="left">longhand</td>
<td align="right">83.3</td>
<td align="right">67.2</td>
<td align="right">-1</td>
<td align="right">66.2</td>
<td align="right">17.1</td>
</tr>
</tbody>
</table></div>
<p>The first three columns show the data. <code>pid</code> is the participant identifier (id) column. As it is often the case for real data, some ids are missing (here 3 and 7) for various reasons (e.g., potential participants were interested in the study and received an id, but then did not finish or start the experiment) so the first 6 rows already go up to <code>pid</code> = 8. <code>condition</code> is the factor (i.e., categorical variable) that tells us in which note taking condition a participant was. <code>overall</code> is their memory score on the scale from 0 to 100 which serves as the numeric DV in the statistical model (i.e., the left-hand side in Equation <a href="standard1.html#eq:statmodel">(5.1)</a>).</p>
<p>The four rightmost columns contain the values of the variables on the right-hand side of Equation <a href="standard1.html#eq:statmodel">(5.1)</a>, the <code>intercept</code>, the <code>iv_effect</code>, and the <code>residual</code>. In addition, the <code>prediction</code> column shows the left-hand side of Equation <a href="standard1.html#eq:predmodel">(5.2)</a>.</p>
<p>As described above, every observation (i.e., row) has an idiosyncratic DV and residual. We also see that all values share one intercept, and the IV-effect is condition specific. As a consequence, the <code>prediction</code> column (which is the sum of intercept and IV-effect) also has only two different values, one for each condition.</p>
<p>We can see in this data that the sum of the three values on the right-hand side of Equation <a href="standard1.html#eq:statmodel">(5.1)</a> equals the observed value of the DV. For example, consider <code>pid</code> = 4. If we enter the values into Equation <a href="standard1.html#eq:statmodel">(5.1)</a> we have</p>
<p><span class="math display">\[
50.0 = 67.2 + (-1) + (-16.2).
\]</span></p>
<p>From this example data we can also understand better what the residuals mean, they are the difference between the observed value and the predicted value, <span class="math inline">\(\text{residual} = \text{DV} - \hat{\text{DV}}\)</span>. Consider again <code>pid</code> = 4. Here we have</p>
<p><span class="math display">\[
-16.2 = 50- 66.2.
\]</span></p>
<p>We can also see how the residual captures the idiosyncratic aspects of our data that cannot be explained by the condition means. For example, some participants – such as <code>pid</code> = 5 and <code>pid</code> = 8 – have large positive residuals indicating that they have good memory independent of their note taking condition. Likewise, <code>pid</code> = 4 has a large negative residual indicating comparatively worse memory (again independent of the note taking condition).</p>
</div>
<div id="understanding-the-statistical-model" class="section level3" number="5.4.3">
<h3>
<span class="header-section-number">5.4.3</span> Understanding the Statistical Model<a class="anchor" aria-label="anchor" href="#understanding-the-statistical-model"><i class="fas fa-link"></i></a>
</h3>
<p>Now that we have described the parts of the statistical model we are almost ready to fit the model and interpret the output. Before doing so it makes sense to look at all the parts again individually and try to understand why we set up the statistical model in the way we do. Remember, our goal is to evaluate whether there is an effect of the experimental manipulation (i.e., a difference between the two note taking conditions) in the population from which the data is sampled. To do so, we set up a model that partitions the observed data into three parts:</p>
<ol style="list-style-type: decimal">
<li>The intercept representing the overall mean,</li>
<li>the condition specific effect (IV-effect) representing the difference of the condition means from the intercept, which can be understood as the signal in the data,</li>
<li>and the residuals representing the idiosyncratic part not explained by the model, which can be understood as the noise in the data.</li>
</ol>
<p>The reason for separating the data in this way is that it allows us to zoom in on what matters, the signal and the noise. To answer the question if there is a difference between the conditions in the population, we can now focus on the relevant parts of the model. The overall level of performance captured in the intercept can be ignored for this question. Consequently, the statistical test reported below is a statistical test of the condition effect that is based on the level of noise captured by the residuals. Thus, the reason for setting up the statistical model in this way is to make it easy to get an answer to the question that interests us: Is there an effect of the note taking manipulation/conditions on memory? To answer this question we need to consider the condition effect in light of the observed level of noise.</p>
</div>
</div>
<div id="estimating-the-statistical-model-in-r" class="section level2" number="5.5">
<h2>
<span class="header-section-number">5.5</span> Estimating the Statistical Model in R<a class="anchor" aria-label="anchor" href="#estimating-the-statistical-model-in-r"><i class="fas fa-link"></i></a>
</h2>
<div id="package-and-data-setup" class="section level3" number="5.5.1">
<h3>
<span class="header-section-number">5.5.1</span> Package and Data Setup<a class="anchor" aria-label="anchor" href="#package-and-data-setup"><i class="fas fa-link"></i></a>
</h3>
<p>For the statistical analyses reported in this book we generally use the <a href="https://cran.r-project.org/package=afex"><code>afex</code></a> package <span class="citation">(<a href="references.html#ref-singmannAfexAnalysisFactorial2021" role="doc-biblioref">Singmann et al. 2021</a>)</span> in combination with the <a href="https://cran.r-project.org/package=emmeans"><code>emmeans</code></a> package <span class="citation">(<a href="references.html#ref-lenth2021" role="doc-biblioref">Lenth 2021</a>)</span>. <code>afex</code> stands for “analysis of factorial experiments” and simplifies many of the things we want to do (full disclaimer: I am the main developer of <code>afex</code>). Most analyses can also be performed with different functions, but it is often easiest to use <code>afex</code> functions as they are developed particularly for cognitive and behavioural researchers working with experimental data. More specifically, <code>afex</code> functions provide the expected results for experimental data sets out-of-the-box without the need to change any settings (which is not true for the corresponding non-<code>afex</code> functions). <code>emmeans</code> stands for “estimated marginal means” and is the package we use once a statistical model is estimated to further investigate the results. <code>afex</code> and <code>emmeans</code> are fully integrated with each other which allows to test practically any hypotheses of interest with a combination of these two packages in a straight forward manner. We already introduce the interplay of these two packages here, and the next chapters will showcase the full power of this combination.</p>
<p>We also regular use functions from the <a href="https://cran.r-project.org/package=tidyverse"><code>tidyverse</code></a> package (e.g., for plotting). <code>tidyverse</code> is a collection of packages developed mainly by <code>RStudio</code> and their head data scientist Hadley Wickham. A short introduction to the <code>tidyverse</code> with pointers to further resources is given in Chapters <a href="tidyverse-intro.html#tidyverse-intro">3</a> and <a href="ggplot2-intro.html#ggplot2-intro">4</a>.</p>
<p>We begin the analysis by loading the three packages first (use <code><a href="https://rdrr.io/r/utils/install.packages.html">install.packages(c("afex", "emmeans", "tidyverse"))</a></code> in case they are not yet installed). We also change the default <code>ggplot2</code> theme using <code>theme_set()</code> to a nicer one.</p>
<div class="sourceCode" id="cb137"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="http://afex.singmann.science/">"afex"</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/rvlenth/emmeans">"emmeans"</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://tidyverse.tidyverse.org">"tidyverse"</a></span><span class="op">)</span>
<span class="fu">theme_set</span><span class="op">(</span><span class="fu">theme_bw</span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">15</span><span class="op">)</span> <span class="op">+</span> 
            <span class="fu">theme</span><span class="op">(</span>legend.position<span class="op">=</span><span class="st">"bottom"</span>, 
                  panel.grid.major.x <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>The next step would be loading in the data. This is made easy here as the data from <span class="citation"><a href="references.html#ref-urry2021" role="doc-biblioref">Urry et al.</a> (<a href="references.html#ref-urry2021" role="doc-biblioref">2021</a>)</span> is part of <code>afex</code>, under the name <code>laptop_urry</code>. So we can load it with the <code><a href="https://rdrr.io/r/utils/data.html">data()</a></code> function. We then also get an overview of the variables in this data set using <code><a href="https://rdrr.io/r/utils/str.html">str()</a></code>, which returns the structure of a <code>data.frame</code>.</p>
<div class="sourceCode" id="cb138"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"laptop_urry"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">laptop_urry</span><span class="op">)</span>
<span class="co">#&gt; 'data.frame':    142 obs. of  6 variables:</span>
<span class="co">#&gt;  $ pid       : Factor w/ 142 levels "1","2","4","5",..: 1 2 3 4 5 6 7 8 9 10 ...</span>
<span class="co">#&gt;  $ condition : Factor w/ 2 levels "laptop","longhand": 1 2 2 1 2 2 1 2 2 1 ...</span>
<span class="co">#&gt;  $ talk      : Factor w/ 5 levels "algorithms","ideas",..: 4 4 2 5 1 3 5 2 5 4 ...</span>
<span class="co">#&gt;  $ overall   : num  65.8 75.8 50 89 75.6 ...</span>
<span class="co">#&gt;  $ factual   : num  61.7 68.3 33.3 85.7 69.2 ...</span>
<span class="co">#&gt;  $ conceptual: num  70 83.3 66.7 92.3 82.1 ...</span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/utils/str.html">str()</a></code> function shows six variables, three of which we have already mentioned above:</p>
<ul>
<li><p><code>pid</code>: participant identifier, a <code>factor</code> with 142 levels, one for each participant.</p></li>
<li><p><code>condition</code>: <code>factor</code> identifying which note taking condition a participant belongs to, with two levels, <code>laptop</code> and <code>longhand</code>.</p></li>
<li><p><code>talk</code>: A <code>factor</code> identifying which TED talk a participant saw, with 5 level.</p></li>
<li><p><code>overall</code>: Numeric variable with participants’ overall memory performance on a scale from 0 (= no memory) to 100 (= perfect memory). This variable is called <code>overall</code> because it is the average of two separate memory performance scores given below.</p></li>
<li><p><code>factual</code>: Numeric variable with participants’ memory score for factual questions (ignored in this chapter).</p></li>
<li><p><code>conceptual</code>: Numeric variable with participants’ memory score for conceptual questions (analysed in Chapter <a href="case-study-laptop.html#case-study-laptop">6</a>).</p></li>
</ul>
</div>
<div id="estimating-the-statistical-model" class="section level3" number="5.5.2">
<h3>
<span class="header-section-number">5.5.2</span> Estimating the Statistical Model<a class="anchor" aria-label="anchor" href="#estimating-the-statistical-model"><i class="fas fa-link"></i></a>
</h3>
<p>For estimating a basic statistical model using <code>afex</code> we can use the <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> function. The next code snippet show how to do so for the example data, when saving the output in <code>R</code> object <code>res1</code> .</p>
<div class="sourceCode" id="cb139"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">res1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car</a></span><span class="op">(</span><span class="va">overall</span> <span class="op">~</span> <span class="va">condition</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/aov.html">Error</a></span><span class="op">(</span><span class="va">pid</span><span class="op">)</span>, <span class="va">laptop_urry</span><span class="op">)</span>
<span class="co">#&gt; Contrasts set to contr.sum for the following variables: condition</span></code></pre></div>
<p>The first argument to <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> is a <code>formula</code> specifying the statistical model, <code>overall ~ condition + Error(pid)</code>. The second argument identifies the <code>data.frame</code> containing the data (i.e., all the variables appearing in the <code>formula</code>), <code>laptop_urry</code>. We can also see that calling <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> produces a status message informing us that contrasts are set to <code>contr.sum</code> for the IVs in the model. This message is only shown for information purposes and can be safely ignored (we want <code>contr.sum</code> as contrasts for our variables, but as this is not the default <code>R</code> behaviour a message is shown).</p>
<p>A <code>formula</code> in <code>R</code> is defined by the presence of the tilde-operator <code><a href="https://rdrr.io/r/base/tilde.html">~</a></code> and the main way for specifying statistical models. It allows specifying statistical models in a similar way to the mathematical formulation, specifically the prediction equation of the statistical model, Equation <a href="standard1.html#eq:predmodel">(5.2)</a>. Therefore, a <code>formula</code> provides a comparatively intuitive approach for specifying a statistical model. On the left hand side of the <code><a href="https://rdrr.io/r/base/tilde.html">~</a></code> we have the dependent variable, <code>overall</code>. On the right hand side we have the variables we want to use to predict the dependent variable.</p>
<p>In the present case, the right-hand side consists of two parts concatenated by a <code><a href="https://rdrr.io/r/base/Arithmetic.html">+</a></code>, the independent variable <code>condition</code> and an <code><a href="https://rdrr.io/r/stats/aov.html">Error()</a></code> term with the participant identifier variable <code>pid</code>. Thus, there are two difference between the <code>formula</code> used here and the prediction Equation <a href="standard1.html#eq:predmodel">(5.2)</a>, the <code>formula</code> misses an explicit intercept and we have specified an <code><a href="https://rdrr.io/r/stats/aov.html">Error()</a></code> term that is missing in Equation <a href="standard1.html#eq:predmodel">(5.2)</a>. Let us address these two difference in turn. The intercept is not actually missing from this equation, but implicitly included. More specifically, an intercept is specified using a <code>1</code> in a <code>formula</code>. However, unless an intercept is explicitly suppressed – which can be done by including <code>0</code> in the formula (and which should only be done if there are very good statistical reason to do so; i.e., it makes very rarely sense) – it is always assumed to be part of the models. Consequently, including it explicitly produces equivalent results. The following code shows this by comparing the previous result without explicit intercept, <code>res1</code> with an <code>aov_car</code> call with explicit intercept using the <code><a href="https://rdrr.io/r/base/all.equal.html">all.equal()</a></code> function. This function can be used to compare arbitrary <code>R</code> objects and only returns <code>TRUE</code> if they are equal.</p>
<div class="sourceCode" id="cb140"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">res1b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car</a></span><span class="op">(</span><span class="va">overall</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">condition</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/aov.html">Error</a></span><span class="op">(</span><span class="va">pid</span><span class="op">)</span>, <span class="va">laptop_urry</span><span class="op">)</span>
<span class="co">#&gt; Contrasts set to contr.sum for the following variables: condition</span>
<span class="fu"><a href="https://rdrr.io/r/base/all.equal.html">all.equal</a></span><span class="op">(</span><span class="va">res1</span>, <span class="va">res1b</span><span class="op">)</span>
<span class="co">#&gt; [1] TRUE</span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/stats/aov.html">Error()</a></code> term is a mandatory part of the model <code>formula</code> when using <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> and is used to specify the participant identifier variable (i.e., <code>pid</code> in this case). Without it, <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> will produce an error.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;The fact that the &lt;code&gt;Error()&lt;/code&gt; is mandatory is one of the ways in which &lt;code&gt;afex&lt;/code&gt;’s &lt;code&gt;aov_car()&lt;/code&gt; differs from base &lt;code&gt;R&lt;/code&gt;’s &lt;code&gt;aov()&lt;/code&gt;. However, &lt;code&gt;aov()&lt;/code&gt; does not always produce the expected results, so needs to be used more carefully than &lt;code&gt;aov_car()&lt;/code&gt;.&lt;/p&gt;"><sup>49</sup></a></p>
<p>Before looking at the results, let us quickly explain why the function for specifying models is called <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code>. A regular statistical model that solely includes factors (i.e., categorical variables) as independent variables is also known as <em>analysis of variance</em>, which is usually shortened to ANOVA.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Describing in detail why statistical models with solely factors as IVs are called analysis of variance even though we are comparing condition means and not variances is beyond the scope of the present work. The short answer is that this has historical reasons. One can calculate the statistical tests in these models by hand by comparing different variance terms. For a full explanations, interested readers are encouraged to read the excellent explanation in &lt;span class="citation"&gt;&lt;a href="references.html#ref-howellStatisticalMethodsPsychology2013" role="doc-biblioref"&gt;Howell&lt;/a&gt; (&lt;a href="references.html#ref-howellStatisticalMethodsPsychology2013" role="doc-biblioref"&gt;2013&lt;/a&gt;)&lt;/span&gt; (any edition of the book should have it).&lt;/p&gt;'><sup>50</sup></a> There also exists a base <code>R</code> functions for <em>analysis of variance</em>, called <code><a href="https://rdrr.io/r/stats/aov.html">aov()</a></code>. However, <code><a href="https://rdrr.io/r/stats/aov.html">aov()</a></code> can produce unexpected or inappropriate results in specific cases. In contrast, <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> always produces the expected and appropriate results. It does so by combining base <code>R</code> functions with function from the <a href="https://cran.r-project.org/package=car"><code>car</code></a> package <span class="citation">(<a href="references.html#ref-foxCompanionAppliedRegression2019" role="doc-biblioref">Fox and Weisberg 2019</a>)</span> (where <code>car</code> stands for the book title, “Companion to Applied Regression” and not for a vehicle).<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;&lt;code&gt;aov_car()&lt;/code&gt; basically combines a call to base &lt;code&gt;R&lt;/code&gt;’s &lt;code&gt;lm()&lt;/code&gt; function, which is the function underlying &lt;code&gt;aov()&lt;/code&gt;, with a call to the &lt;code&gt;Anova()&lt;/code&gt; function from package &lt;code&gt;car&lt;/code&gt;. Doing this by hand requires using proper factor coding (e.g., &lt;code&gt;contr.sum&lt;/code&gt;). Furthermore, the &lt;code&gt;Anova()&lt;/code&gt; function has in some cases a syntax that can be described as cumbersome. In sum, &lt;code&gt;aov_car()&lt;/code&gt; is a lot easier and safer to use than using &lt;code&gt;lm()&lt;/code&gt; and &lt;code&gt;Anova()&lt;/code&gt; directly.&lt;/p&gt;"><sup>51</sup></a> So <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> stands for <code>aov</code> with some help from the <code>car</code> package.</p>
</div>
<div id="interpreting-the-results" class="section level3" number="5.5.3">
<h3>
<span class="header-section-number">5.5.3</span> Interpreting the Results<a class="anchor" aria-label="anchor" href="#interpreting-the-results"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s now take look at the results from our statistical model. For this, we simply call the object that contains the results <code>res1</code> (we would get the same output when calling <code><a href="https://rdrr.io/r/base/print.html">print(res1)</a></code> or <code><a href="https://rdrr.io/pkg/afex/man/nice.html">nice(res1)</a></code>).</p>
<div class="sourceCode" id="cb141"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">res1</span>
<span class="co">#&gt; Anova Table (Type 3 tests)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Response: overall</span>
<span class="co">#&gt;      Effect     df    MSE    F  ges p.value</span>
<span class="co">#&gt; 1 condition 1, 140 269.66 0.52 .004    .471</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  </span>
<span class="co">#&gt; 0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1</span></code></pre></div>
<p>The default <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> output is an “Anova Table” we will see throughout the book. We can also see that the results table contains “Type 3 tests,” but we will ignore this for now. The only other option, Type 2 tests, produces the same results for the example data. We will get back to the meaning of “type of test” in later chapters when it makes a difference and ignore this part until then.</p>
<p>The next line of the results table is only reference information. We see that the response variable, which we also know as DV, is <code>overall</code>, just as we intended.</p>
<p>We then get a table of effects, which in this case only has one row, the effect of <code>condition</code>. This row contains all the information for our null hypothesis significance test (NHST) for the condition effect. The most important column in this output is the last column, <code>p.value</code>, or <span class="math inline">\(p\)</span>-value. The <span class="math inline">\(p\)</span>-value in this column is the main results of NHST and allows us to judge the compatibility of the data with the null hypothesis. It is the probability of obtaining a difference as extreme as observed when assuming that the null hypothesis of no difference is true. We see that in this case the <span class="math inline">\(p\)</span>-value is not small, it is .471. Thus, the data are not incompatible with the null hypothesis and do not suggest that there is a memory difference between note taking with a laptop or in longhand format during lectures.</p>
<p>In general, researchers have adopted a significance level of .05. This means that if a <span class="math inline">\(p\)</span>-value is smaller than .05 we treat this as evidence that the data is incompatible with the null hypothesis. In this case we would say the result is “significant.” However, as in our case the result is not smaller than .05 the result is “not significant” (I would avoid saying “insignificant” if the <span class="math inline">\(p\)</span>-value is larger than .05, as “significant” is a technical term here). Thus, in the present case we do not reject the null hypothesis. Therefore, there is no evidence that either method of note taking is superior to the other in terms of memory performance.</p>
<p>There are two further important columns whose results generally need to be reported, <code>df</code>, which stands for “degrees of freedom” (or <em>df</em>), and <code>F</code>. Understanding these columns in detail is beyond the scope of the present chapter, so we will only introduce them briefly.</p>
<p>There are two degrees of freedom reported here, the first value, 1, is the numerator degree of freedom. It is always given by number of conditions (i.e., factor levels) minus 1. In the present case, we have two conditions, <code>laptop</code> and <code>longhand</code>, so the numerator <em>df</em> are 2 - 1 = 1. The second value is the denominator <em>df</em>, which are generally given by number of participants minus numerator <em>df</em> minus 1. Here we have 142 participants and therefore 142 - 1 - 1 = 140. In general, the larger the denominator <em>df</em> (i.e., the more participants we have) the better we can detect incompatibility with the null hypothesis (i.e., the easier it is to get small <span class="math inline">\(p\)</span>-values).</p>
<p>The <span class="math inline">\(F\)</span>-value is our measure of the signal versus noise ratio – it expresses the observed incompatibility of the data with the null hypothesis. The larger <span class="math inline">\(F\)</span>, the larger the signal relative to the noise. If <span class="math inline">\(F \leq 1\)</span>, the data are compatible with the null hypothesis. If <span class="math inline">\(F &gt; 1\)</span> the data are to some degree incompatible with the null hypothesis, with larger values indicating more incompatibility. The <span class="math inline">\(p\)</span>-value is calculated from <em>df</em> and <span class="math inline">\(F\)</span>-value. Consequently, the results are usually reported in the following way: <span class="math inline">\(F(1, 140) = 0.52\)</span>, <span class="math inline">\(p = .471\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Note that the default reporting style provides to some degree redundant information, because we can look up the &lt;span class="math inline"&gt;\(p\)&lt;/span&gt;-value if we have &lt;span class="math inline"&gt;\(F\)&lt;/span&gt;-value and both &lt;em&gt;df&lt;/em&gt; (e.g., &lt;code&gt;pf(0.52, 1, 140, lower.tail = FALSE)&lt;/code&gt; &lt;span class="math inline"&gt;\(\approx 0.47\)&lt;/span&gt;). The reason for providing this redundant information is that is allows the reader to perform a soundness check of the results. For example, if &lt;span class="math inline"&gt;\(F &amp;lt; 1\)&lt;/span&gt;, we know that the &lt;span class="math inline"&gt;\(p\)&lt;/span&gt;-value cannot be &lt;span class="math inline"&gt;\(&amp;lt; .05\)&lt;/span&gt;. This makes it easy to detect errors in results that could be example for introduced through typos (which also happen in scientific publications).&lt;/p&gt;'><sup>52</sup></a></p>
<p>The output contains two further columns that we will not discuss in detail for now, <code>ges</code> and <code>MSE</code>. <code>ges</code> stands for generalised eta-squared, using the mathematical notation and Greek letters, <span class="math inline">\(\eta^2_G\)</span>, and is a <em>standardised effect size</em> measure that tells us something about the absolute magnitude of the observed effect <span class="citation">(<a href="references.html#ref-olejnikGeneralizedEtaOmega2003" role="doc-biblioref">Olejnik and Algina 2003</a>; <a href="references.html#ref-bakemanRecommendedEffectSize2005" role="doc-biblioref">Bakeman 2005</a>)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="math inline"&gt;\(\eta^2_G\)&lt;/span&gt; is supposed to be a measure of the proportion of variance in the DV that can be accounted for by a specific factor or IV in the model. For example, in the present case the condition effect is supposed to explain 0.4% of the variance in performance. In general, we should avoid standardised effect sizes such as &lt;span class="math inline"&gt;\(\eta^2_G\)&lt;/span&gt; and instead report &lt;em&gt;simple effect sizes&lt;/em&gt;. A simple effect size is expressed in units of our measured DV. For example, throughout this chapter we have mentioned that the observed difference in memory performance between both note taking conditions is 2.0 on the scale from 0 to 100. Here, the difference of 2.0 is a simple effect size. We will have to say more about effect sizes later.&lt;/p&gt;'><sup>53</sup></a> Many journals in psychology require reporting this or similar measures, so it is included in the default output. <code>MSE</code> stands for “mean squared errors” and is a column that is mainly included for historical reasons.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Traditionally, ANOVA models could relatively easily be calculated by hand or by calculator based on different variance terms (hence the name, analysis of variance). One of this term is the mean squared error from which, in combination with the residual squared error, the &lt;span class="math inline"&gt;\(F\)&lt;/span&gt;-value can be calculated. In my undergrad studies I still learned to calculate ANOVA by hand, but this seems rather unnecessary nowadays. Interested reader can find a detailed explanation about the meaning of MSE for example in &lt;span class="citation"&gt;&lt;a href="references.html#ref-howellStatisticalMethodsPsychology2013" role="doc-biblioref"&gt;Howell&lt;/a&gt; (&lt;a href="references.html#ref-howellStatisticalMethodsPsychology2013" role="doc-biblioref"&gt;2013&lt;/a&gt;)&lt;/span&gt; or &lt;span class="citation"&gt;&lt;a href="references.html#ref-baguleySeriousStatsGuide2012" role="doc-biblioref"&gt;Baguley&lt;/a&gt; (&lt;a href="references.html#ref-baguleySeriousStatsGuide2012" role="doc-biblioref"&gt;2012&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;'><sup>54</sup></a> Consequently, we will ignore it.</p>
<p>One thing we note in the results table is that it does not contain any information about the intercept. However, as discussed above, the intercept is included in the model. The reason for omitting the intercept from the default output is that it is generally not of primary interest. In experimental research usually the main interest is in the effect of our independent variables, the effect of the experimental manipulation. The statistical model that separates the intercept (i.e., overall mean) from the condition effect allows to zoom in on the relevant part. In line with this, the default output of <code>aov_car</code> does the same. Later chapters will show how we can also get information about the intercept.</p>
<p>Estimating a statistical model with <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> provides us with the inferential statistical results, the null hypothesis tests for the IV-effects shown above. To get these, we just need to call the object containing the results at the <code>R</code> prompt (e.g., calling <code>res1</code> in the present case). However, we can use the results object also for others parts of the statistical analyses, for data visualisation and follow-up analyses.</p>
</div>
<div id="data-visualisation" class="section level3" number="5.5.4">
<h3>
<span class="header-section-number">5.5.4</span> Data Visualisation<a class="anchor" aria-label="anchor" href="#data-visualisation"><i class="fas fa-link"></i></a>
</h3>
<p>For data visualisation we can use the <code>afex</code> function <code><a href="https://rdrr.io/pkg/afex/man/afex_plot.html">afex_plot()</a></code> which is built on top of the <code>ggplot2</code> package. <code><a href="https://rdrr.io/pkg/afex/man/afex_plot.html">afex_plot()</a></code> requires an estimated model object (e.g., as returned from <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code>) and specifying which factors of the model we want to plot. In the present case, we only have one factor, <code>condition</code>, so we can only choose this one. Importantly, all factors passed to <code><a href="https://rdrr.io/pkg/afex/man/afex_plot.html">afex_plot()</a></code> need to be passed as character strings (i.e., enclosed with <code>"..."</code>).</p>
<div class="sourceCode" id="cb142"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/pkg/afex/man/afex_plot.html">afex_plot</a></span><span class="op">(</span><span class="va">res1</span>, <span class="st">"condition"</span><span class="op">)</span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:fig1"></span>
<img src="02-standard_approach_files/figure-html/fig1-1.png" alt="afex\_plot() figure for data from Urry et al. (2021)" width="100%"><p class="caption">
Figure 5.3: afex_plot() figure for data from Urry et al. (2021)
</p>
</div>
<p>This simple call to <code><a href="https://rdrr.io/pkg/afex/man/afex_plot.html">afex_plot()</a></code> produces already a rather good looking results figure combining the individual-level data points (in the background in grey) with the condition means (in black). Individual data points in the background that have the same or very similar values are displaced on the x-axis so they do not lie on top of each other. This is achieved through package <a href="https://cran.r-project.org/package=ggbeeswarm"><code>ggbeeswarm</code></a> (which needs to be installed once: <code><a href="https://rdrr.io/r/utils/install.packages.html">install.packages("ggbeeswarm")</a></code>). The plot also per default shows 95% confidence intervals of the means, which we will explain in detail in a later chapter.</p>
<p>As <code><a href="https://rdrr.io/pkg/afex/man/afex_plot.html">afex_plot()</a></code> returns a <code>ggplot2</code> plot object, we can manipulate the plot to make it nicer.</p>
<div class="sourceCode" id="cb143"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/afex/man/afex_plot.html">afex_plot</a></span><span class="op">(</span><span class="va">res1</span>, <span class="st">"condition"</span><span class="op">)</span>
<span class="va">p1</span> <span class="op">+</span> 
  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"note taking condition"</span>, y <span class="op">=</span> <span class="st">"memory performance (0 - 100)"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>group <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="02-standard_approach_files/figure-html/fig2-1.png" width="100%"></div>
<p>For example, in the code snippet above we first save the plot object as <code>p1</code> and then call a number of <code>ggplot2</code> function on this plot object to alter the plot appearance (as discussed before, graphical elements are added to a <code>ggplot2</code> plot using <code><a href="https://rdrr.io/r/base/Arithmetic.html">+</a></code>). Function <code>labs()</code> is used to change the axis labels, <code>coord_cartesian()</code> changes the extent of the y-axis (i.e., the plot now show the full possible range of memory performance score), and <code>geom_line(aes(group = 1)</code> adds a line connecting the two means. This figure could now be used in a results report or manuscript as is.</p>
</div>
<div id="follow-up-analysis" class="section level3" number="5.5.5">
<h3>
<span class="header-section-number">5.5.5</span> Follow-Up Analysis<a class="anchor" aria-label="anchor" href="#follow-up-analysis"><i class="fas fa-link"></i></a>
</h3>
<p>Follow-up analysis refers to an inspection of the predicted condition means and their relationships. In the case of a single independent variable with two levels (e.g., laptop versus longhand) their is not much to investigate in this regard. We can nevertheless show the general procedure. For follow-up analyses we generally begin with function <code><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans()</a></code> from package <code>emmeans</code> <span class="citation">(<a href="references.html#ref-lenth2021" role="doc-biblioref">Lenth 2021</a>)</span>. Function <code><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans()</a></code> then returns the estimated marginal means, which is a slightly complicated way of saying condition means, plus additional statistical information.</p>
<p>Similarly to <code><a href="https://rdrr.io/pkg/afex/man/afex_plot.html">afex_plot()</a></code>, <code><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans()</a></code> requires an estimated model object as well as the specification of a factor in the model for which we want to get the condition means:</p>
<div class="sourceCode" id="cb144"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">res1</span>, <span class="st">"condition"</span><span class="op">)</span>
<span class="co">#&gt;  condition emmean   SE  df lower.CL upper.CL</span>
<span class="co">#&gt;  laptop      68.2 1.99 140     64.3     72.1</span>
<span class="co">#&gt;  longhand    66.2 1.91 140     62.4     70.0</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Confidence level used: 0.95</span></code></pre></div>
<p>For now we only focus on the estimates means in column <code>emmean</code> and ignore the additional inferential statistical information in columns <code>SE</code> to <code>upper.CL</code>. We can see that the reported means match the means given in the text at the very beginning of the chapter, <a href="standard1.html#ex:urry">5.1</a>.</p>
<p>The power of <code>emmeans</code> is not only to provide the condition means, but it also allows us to perform calculation on the condition means. For example, in the case of a factor with two levels, we can easily calculate the difference between the condition means. This difference between the condition means is also a measure of the size of the effect. However, compared to the <code>ges</code> column in the default output, it is not standardised but a <em>simple effect size</em>, it is expressed in units of our dependent variable. As it is often easier to understand simple compared to standardised effect sizes, we will generally prefer this measure.</p>
<p>To calculate the effect of condition through <code>emmeans</code>, we first need to save the object returned by <code><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans()</a></code>. We can then call the <code><a href="https://rdrr.io/r/graphics/pairs.html">pairs()</a></code> function on this object. This gives us all pairwise comparisons of conditions means. In the present case, there is only one in the present case (we would get the same results by combining both calls into one: <code><a href="https://rdrr.io/r/graphics/pairs.html">pairs(emmeans(res1, "condition"))</a></code>):</p>
<div class="sourceCode" id="cb145"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">em1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">res1</span>, <span class="st">"condition"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">em1</span><span class="op">)</span>
<span class="co">#&gt;  contrast          estimate   SE  df t.ratio p.value</span>
<span class="co">#&gt;  laptop - longhand     1.99 2.76 140   0.722  0.4715</span></code></pre></div>
<p>The output shows a mean difference of 1.99 which slightly differs from the 2.0 reported above, which is slightly concerning. However, the results reported above are rounded to one decimal only. If we do so for the present results, we also get an estimated difference of 2.0 (we will not explain this code in detail here):</p>
<div class="sourceCode" id="cb146"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">em1</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://rdrr.io/r/base/format.html">format</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">1</span>, nsmall <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="co">#&gt;            contrast estimate  SE    df t.ratio p.value</span>
<span class="co">#&gt; 1 laptop - longhand      2.0 2.8 140.0     0.7     0.5</span></code></pre></div>
</div>
</div>
<div id="summary-4" class="section level2" number="5.6">
<h2>
<span class="header-section-number">5.6</span> Summary<a class="anchor" aria-label="anchor" href="#summary-4"><i class="fas fa-link"></i></a>
</h2>
<p>The goal of this chapter was to introduce the standard statistical approach for analysing experimental data with one independent variable with two levels – such as an experiment with two conditions. Practically every time when we run such an experiment, we observe that there is some mean difference in the dependent variable between the two conditions. For our example data by <span class="citation"><a href="references.html#ref-urry2021" role="doc-biblioref">Urry et al.</a> (<a href="references.html#ref-urry2021" role="doc-biblioref">2021</a>)</span>, there was a memory difference of 2.0 points between the two note taking conditions (laptop versus longhand) on the response scale from 0 to 100.</p>
<p>The important statistical question we then have is whether there is any evidence suggesting that the observed difference in our sample generalises to the population. The sample are the participants in our experiment and the population refers to all possible participants that could have been sampled. For <span class="citation"><a href="references.html#ref-urry2021" role="doc-biblioref">Urry et al.</a> (<a href="references.html#ref-urry2021" role="doc-biblioref">2021</a>)</span> this population could be loosely described as students taking notes or maybe more precisely undergraduate students at research intensive (R1) US universities. The question we would like to get a statistical answer to is: Should we believe that there generally is a memory difference between note taking with a laptop versus longhand? In other words, is there a genuine signal or is the observed difference just noise? To answer this question we need <em>inferential statistics</em>.</p>
<p>The inferential statistical approach we are using is called <em>null hypothesis significance testing</em> or NHST. However, NHST does not directly address the question whether there is evidence for a difference in the population. Instead, NHST tests the compatibility of the data with the <em>null hypothesis</em> – the assumption that there is no difference between the condition in the population. The most important result from NHST is the <span class="math inline">\(p\)</span>-value. The <span class="math inline">\(p\)</span>-value is a measure of the compatibility of the data with the null hypothesis; it is the probability of obtaining a results as extreme as observed assuming the null hypothesis is true. If the <span class="math inline">\(p\)</span>-value is smaller than .05 we reject the null hypothesis that there is no difference. In this case we decide that there is evidence for a difference (although this does not follow with logical necessity).</p>
<p>To apply NHST to the data we set up a <em>statistical model</em> that partitions the observed data into three parts (Equation <a href="standard1.html#eq:statmodel">(5.1)</a>): the intercept representing the overall mean, the the effect of the independent variable (i.e., the difference of the condition means from the intercept), and the residuals representing the idiosyncratic aspects not explained by the other parts of the model. The effect of the independent variable is our estimate of the signal and the residuals are our estimate of the noise in the data. This partitioning allows us to zoom in on the part of the data that we are interested in, the effect of our independent variable, the experimental manipulation.</p>
<p>To estimate a statistical model to the data we used function <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> from the <code>afex</code> package. <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> allows us to specify the statistical model using a formula of the form <code>dv ~ iv + Error(pid)</code> (where <code>pid</code> refers to the variable in the data with the participant identifier) mimicking the mathematical specification of the statistical model. The default output returns an ANOVA table which provides a null hypothesis significance test for our <code>iv</code>, the independent variable. The returned table is called an ANOVA table because statistical models that only contain factors are called analysis of variance or ANOVA. In the present case, the statistical model only has a single factor, note taking condition, with two levels, laptop versus longhand. In the returned ANOVA table, we do not only have the <span class="math inline">\(p\)</span>-value for our experimental factor, but additional inferential statistical information such as the degrees of freedom, <em>df</em>, and the <span class="math inline">\(F\)</span>-value.</p>
<p>We can also use the object returned from <code><a href="https://rdrr.io/pkg/afex/man/aov_car.html">aov_car()</a></code> for plotting using function <code><a href="https://rdrr.io/pkg/afex/man/afex_plot.html">afex_plot()</a></code>. This function produces a plot combining the individual-level data points with the condition means. This provides a comprehensive display of the data of the experiment. As the function returns a <code>ggplot2</code> object, this plot can be be easily modified to create a figure that can be used in a results report.</p>
<p>We can also use the object returned from <code>aov_car</code> for follow-up analyses using <code>emmeans</code>. With <code>emmeans</code> we can easily obtain the condition means (or estimated marginal means) on the dependent variable. Based on these condition means we can calculate the observed effect size (i.e., the mean difference).</p>
<p>Applying the statistical model to the data from <span class="citation"><a href="references.html#ref-urry2021" role="doc-biblioref">Urry et al.</a> (<a href="references.html#ref-urry2021" role="doc-biblioref">2021</a>)</span> showed a non significant difference, <span class="math inline">\(F(1, 140) = 0.52\)</span>, <span class="math inline">\(p = .471\)</span>. This suggests that there is no difference in memory performance after watching a talk and taking notes with either a laptop or in longhand format.</p>

</div>
</div>

<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  if (t = document.getElementById("webex-total_correct")) {
    t.innerHTML =
      document.getElementsByClassName("webex-correct").length + " of " +
      document.getElementsByClassName("webex-solveme").length + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }
  
  if (my_answer !== "" & real_answers.includes(my_answer)) {
    cl.add("webex-correct");
  } else {
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);  
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }  
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }  
  }
  
  update_total_correct();
}

window.onload = function() {
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }
  
  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off"); 
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";
    
    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;
    
    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;
  }
  
  update_total_correct();
}

</script><div class="chapter-nav">
<div class="prev"><a href="ggplot-exercises.html">ggplot2: Example, Quiz, and Exercises</a></div>
<div class="next"><a href="case-study-laptop.html"><span class="header-section-number">6</span> Case Study 1: More Results from Note Taking Studies</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#standard1"><span class="header-section-number">5</span> The Standard Approach for One Independent Variable</a></li>
<li><a class="nav-link" href="#ex:urry"><span class="header-section-number">5.1</span> Example Data: Note Taking Experiment</a></li>
<li><a class="nav-link" href="#generalising-from-sample-to-population"><span class="header-section-number">5.2</span> Generalising From Sample to Population</a></li>
<li><a class="nav-link" href="#nhst-logic"><span class="header-section-number">5.3</span> The Logic of Inferential Statistics</a></li>
<li>
<a class="nav-link" href="#basic-stats-model"><span class="header-section-number">5.4</span> The Basic Statistical Model</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#model-predictions"><span class="header-section-number">5.4.1</span> Model Predictions</a></li>
<li><a class="nav-link" href="#statistical-model-for-the-example-data"><span class="header-section-number">5.4.2</span> Statistical Model for the Example Data</a></li>
<li><a class="nav-link" href="#understanding-the-statistical-model"><span class="header-section-number">5.4.3</span> Understanding the Statistical Model</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#estimating-the-statistical-model-in-r"><span class="header-section-number">5.5</span> Estimating the Statistical Model in R</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#package-and-data-setup"><span class="header-section-number">5.5.1</span> Package and Data Setup</a></li>
<li><a class="nav-link" href="#estimating-the-statistical-model"><span class="header-section-number">5.5.2</span> Estimating the Statistical Model</a></li>
<li><a class="nav-link" href="#interpreting-the-results"><span class="header-section-number">5.5.3</span> Interpreting the Results</a></li>
<li><a class="nav-link" href="#data-visualisation"><span class="header-section-number">5.5.4</span> Data Visualisation</a></li>
<li><a class="nav-link" href="#follow-up-analysis"><span class="header-section-number">5.5.5</span> Follow-Up Analysis</a></li>
</ul>
</li>
<li><a class="nav-link" href="#summary-4"><span class="header-section-number">5.6</span> Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/singmann/stats_for_experiments/blob/main/02-standard_approach.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/singmann/stats_for_experiments/edit/main/02-standard_approach.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Introduction to Statistics for Experimental Psychology with <code>R</code></strong>" was written by Henrik Singmann. It was last built on 2021-11-03.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
