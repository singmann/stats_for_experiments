# Case Study 1: More Results from Note Taking Studies

In this chapter we will apply what we have learned in the previous chapter - how to analyse experimental data with one experimental manipulation and two conditions. For this, we will again take a look at the data from @urry2021. Additionally, we will analyse the data of the experiment by @muellerPenMightierKeyboard2014. This experiment was the first published experiment investigating the question of note taking with a laptop or in longhand format and was the basis on which @urry2021 planned their study. For the study of @muellerPenMightierKeyboard2014 we will perform a full analysis starting with reading in the data. So in addition to performing the statistical hypothesis test, we will calculate some descriptive statistics.

We start the analysis in this chapter in the same way as in the previous chapter, by loading the three packages we generally use, `afex`, `emmeans`, and `tidyverse`, and set a nicer `ggplot2` theme. Before doing so it is probably a good idea to restart `R` (unless, of course, you are just starting `R`). In `RStudio` this can be conveniently done through the menu by clicking on `Session` and then `Restart R`. In other `R` environments you might need to restart the program. The benefit of restarting `R` is that it should create a blank `R` session in which no packages are loaded and no objects exist in the workspace. Only such a blank sessions ensures that, once we have obtained a set of results, we can recreate them later using the same code. That is, a blank `R` session avoids any potential problems due to analyses performed in a previous session that are still lingering. Restarting `R` should generally be done when starting a new analysis or after one is completely done with an analysis. In the latter case, it makes sense to restart `R` and the rerun all code one has saved in ones script to ensure that all results replicate based on only the code in the script (and do not require some additional code not saved).

```{r}
library("afex")
library("emmeans")
library("tidyverse")
theme_set(theme_bw(base_size = 15) + 
            theme(legend.position="bottom", 
                  panel.grid.major.x = element_blank()))
```

## Conceptual Memory Data from Urry et al. (2021)

As a quick reminder, @urry2021 showed their participants short lectures (TED talks) on video during which participants were allowed to take notes. One group of participants, the `laptop` condition, could take notes on a laptop, whereas the participants in the `longhand` condition could take notes with pen and paper. After the lecture participants were quizzed on two aspects of the content of the lecture, factual questions and conceptual questions. In the previous chapter we have analysed the overall memory score which was the average of the performance for the factual questions and the conceptual questions. Here, we are only concerned with the memory performance for conceptual questions. We begin our analysis by loading in the data (which is part of `afex` can be loaded with `data()`) and getting an overview of the variables using `str()`:

```{r}
data("laptop_urry")
str(laptop_urry)
```

As before, we have the participants identifier variable in `pid` and the note taking condition in variable `condition`. We can also guess that the conceptual memory scores are in the aptly name variable `conceptual` (if we were unsure about this, we could also check the documentation of the data at `?laptop_urry`).

Usually, once the data is sufficiently prepared (i.e., we have performed some sanity checks and identified DV and IV), the first step in an analysis should be plotting the data. This could be done using `ggplot2` directly. However, in cases such as the present one where it is very clear which statistical model we are going to estimate it is often a bit less effort to plot the data with `afex_plot()`. Thus, we start by estimating the statistical model for the conceptual memory performance of the data from @urry2021 and save the estimated model object as `mc_urry`. For this, we again use `aov_car()` on the `laptopt_urry` data and specify the model using the formula interface. The DV we are considering here is `conceptual`, our IV is `condition`, and the participant identifier is `pid`. Consequently, the formula is `conceptual ~ condition + Error(pid)`. Then, before looking at the inferential statistical results, we use this model object to plot the data using `afex_plot`.

```{r urry-conceptual,  fig.cap='Conceptual memory scores from Urry et al. (2021) across note taking conditions'}
mc_urry <- aov_car(conceptual ~ condition + Error(pid), laptop_urry)
afex_plot(mc_urry, "condition")
```

The goal behind beginning with plotting the data is that it allows to see whether the data "looks alright". That is, we check whether there are any features that stand out such as clear outliers or an unusual pattern in the data. If this were the case, we would try to figure out if we can find a reason for this issue or how we deal with it. But, as the data looks alright, we continue and consider the results of the significance test:

```{r}
mc_urry
```

The ANOVA table reveals that the significance test for the effect of condition is not significant with $p = .319$. Thus, in line with the finding that there is no evidence for a difference in overall memory performance, there also is no evidence for a difference in memory for conceptual information.

We can also again use `emmeans` to see the condition means (or estimated marginal means). In line with Figure \@ref(fig:urry-conceptual) (as `afex_plot` internally also uses `emmeans` it shows exactly the same means in graphical form), the memory score in the laptop condition is descriptively around 3.5 points higher than the score in the longhand condition.

```{r}
emmeans(mc_urry, "condition")
```

Before moving to the next data set, let us consider how we could report this analysis in a research report. We could for example write:

> As shown in Figure \@ref(fig:urry-conceptual), participants' conceptual memory scores (on a scale from 0 to 100) are descriptively slightly larger in the laptop condition compared to the longhand condition. We analysed these scores with an ANOVA with one factor, note taking condition, with two levels (laptop vs. longhand). The effect of note taking condition was not significant, $F(1, 140) = 1.00$, $p = .319$. This indicates that the data does not provide evidence for a difference in memory for conceptual information based on how notes are taken during lectures.

## Why are Experiments Replicated?

The study by @urry2021 was not the first study investigating the effect of note taking during lectures on memory. In contrast, their study was a *replication* of Study 1 by @muellerPenMightierKeyboard2014. A replication is the act of rerunning an existing study to see if one can obtain (or replicate) the results of the previous study.

As we have discussed before, inferences from NHST are never conclusive as they are probabilistic and require multiple inferential steps. Replications are one of the most important tools in science for overcoming at least the probabilistic uncertainties associated with the inferences we draw from experimental data. For example consider that several independent but otherwise as similar as possible experiments -- that is, replications of the same experiment -- all obtain a significant result (i.e., indicate that the data are incompatible with the null hypothesis). Such a pattern would dramatically increase our confidence that the null hypothesis is likely false.

In addition to the gain in confidence for specific results, there are good practical reasons for replicating an existing experiment. For example, when beginning to work on a new topic it is generally a good idea to replicate the experiment on which one wants to build on. If one already has problems replicating what exists that shows that the topic is maybe not as simple as portrayed in the literature.

Another excellent reason for performing a replication is if one simply does not believe an existing result. Remember, one of the key components of the scientific method is *scepticism* (at least [according to Wikipedia](https://en.wikipedia.org/wiki/Scientific_method)). And if a results is difficult to believe, the reasonable sceptical position to take is to require more evidence. A replication is one way (if not the best way) to produce such evidence. Not believing existing experiments also does not imply that one questions the integrity of the researchers who did the experiment. There are many completely harmless reasons why a study might not replicate. For example, researchers might have just obtained a significant results by chance (which happens in 5% of cases, as discussed in the next chapters).

Sadly, replicating existing experiments and publishing the results, is still not the norm in psychology and related disciplines. Quite to the contrary, the situation is so dire that many fields are currently considered to be in a "[replication crisis](https://en.wikipedia.org/wiki/Replication_crisis)". For example, a large scale effort to replicate 100 studies in psychology [@opensciencecollaborationEstimatingReproducibilityPsychological2015] showed that less than 50% could be replicated successfully. Similarly sobering results have since been observed across the social sciences [@camererEvaluatingReplicabilitySocial2018; @kleinManyLabsInvestigating2018; @camererEvaluatingReplicabilityLaboratory2016]. Much has been written about this problem and this is not the right place to rehash all arguments. The best summary of the situation is the book by Chris Chambers [@chambersSevenDeadlySins2017]. The important thing is to realise that science is a cumulative endeavour. Every new experiment builds on existing research. If the existing research has never been replicated, our confidence in this research has to be somewhat low. This questions the foundations of any new work that builds up on this non-replicated research. To move forward every researcher needs to try to do better and rebuild our science on solid (i.e., replicable) grounds.

## Conceptual Memory Data from Mueller and Oppenheimer (2014)

```{r}
library("afex")
library("emmeans")
library("tidyverse")
theme_set(theme_bw(base_size = 15) + 
            theme(legend.position="bottom", 
                  panel.grid.major.x = element_blank()))
```

```{r, message=FALSE}
mo2014 <- read_csv("data/Study 1 abbreviated data.csv")
glimpse(mo2014)
```

```{r}
mo2014 <- mo2014 %>% 
  mutate(
    pid = factor(participant),
    condition = factor(LapLong, 
                      levels = c(0, 1),
                      labels = c("laptop", "longhand")),
    performance = (factualindex/perfectfactindexscore + 
                     conceptualindex/perfectconceptindexscore)/2 * 100
  ) %>% 
  select(pid, condition, performance)
```

```{r}
ggplot(mo2014, aes(x = condition, y = performance)) +
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +
  ggbeeswarm::geom_quasirandom() +
  stat_summary(colour = "red") +
  coord_cartesian(ylim = c(0, 100))
```

```{r}
res2 <- aov_car(performance ~ condition + Error(pid), mo2014)
```
