- Therapy example: 
  - placebo versus no placebo
  - maybe talk about a job who wants to improve wellbeing. show that there are 99 different questionnaires for well being.
  - Hawthorne/placebo effect
  - control group
  - what type of intervention
  
- Loss aversion:
  - 
  
- gap 1:
  - measurement - schmeasurement paper
  - 99 ways of measuring well-being
  - 
  

- gap 2:

####

The first example about therapies seems underdeveloped, at least in comparison with the loss aversion. It seems separate from the four stages that you describe but you could link it much more. For example, you could talk about placebo effect.

Do people really say that reflection effect is evidence of loss aversion? Endowment effect is a nice example of something that has been challenged as a measure of loss aversion in aggregate, maybe even simpler to understand that risky gambles.
- mixed gambles vs. utility functions.

A lot of what you are saying in the epistemiology 1 is related to measurement schmesurement and the construct validity crisis. Here you could use examples of how many measures exist for popular concepts like self-esteem or wellbeing. Even if you had a perfect correlation between them, there is no guarantee that they measure what is on the label.

A very good example (to add to your list) is the latest debate about system 1 and 2. The most recent paper by De Neyne basically says that we should just stop talking about it since we clearly have no method to test it.

You should definitely look at the McGraw paper about measuring loss aversion using subjective scales.  The results of this paper seem to match well on your example I think.

What we should and shouldn't do feels like a list of examples...

Nice example of noise confused with signal. <- intelligence and risk aversion.

###

- framing effects: spillover of intention
  + 
  + 
  
#### last paragraph removed

As we have discussed, a statistical analysis never gives us perfect confidence that a particular result supports an empirical hypothesis. The only way to get some confidence that we did not get unlucky with our sample of participants is that the study is repeated, either by us but ideally by others â€“ a so called replication. If a completely independent set of researchers finds the same pattern of results, this provides us with rather strong evidence that the study design indeed gives rise to this data pattern. For example, @walasekContextdependentSensitivityLosses2019 replicated and extended the results of @walasekHowMakeLoss2015. study, the pattern is not yet as clear. Whereas I am not aware of any published exact (or direct) replication of their study, the original authors have attempted to extend their findings somewhat [@walasekContextdependentSensitivityLosses2019] and found similar but less pronounced differences between condition. However, using a different study design @schneiderEffectsSurroundingPositive2016 also showed that the acceptance rated of symmetric lotteries are strongly affected by which other lotteries are presented.

Conclusion

In the end, we have to accept and embrace the uncertainty that comes from working at the forefront of knowledge. Answering big and important research question is a difficult endeavour that cannot be done with a single study or research project. If we get lucky, one single study can move us one step forward by providing really strong evidence for one thing.





