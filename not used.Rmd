## `RStudio` Setup

Our main access through `R` is through the `RStudio` IDE.

Let me end this section by discussing the ethical dimension of the question of causal inference from observational data. Clearly, some of the most politically charged societal questions that can be addressed empirically can generally only be done so using observational data. For example, an important question is whether

Example I: Testing a New Therapy

To get a better understanding of the research process and the problems that can arise in it, let us consider a first example research question and how it can be investigated empirically. In many clinical domains, a frequent research question is whether a new therapeutical intervention works better than an existing one. The basic study design for this type of research question is quite clear, a randomized controlled trial. We want to compare the new treatment with a control treatment in an experimental setting -- eligible participants are randomly assigned to receive either the new or the existing treatment. Whereas the general design of this study is fixed, important questions in the operationalisation step are how to measure the outcome intervention and how to implement the control treatment.

For example, if we are testing a new therapy against a mental health disorder, are we interested if the new treatment reduces symptoms as measured by one of the many available questionnaires (and then which questionnaire), reduces the number of sick days, or the number of recurring episodes? Depending on the differences between the new and old treatment it is possible that one treatment does better on one of these measures whereas the other is better for another measure. When performing the research we need to consider these different possibilities before we can collect any data. And if we collect multiple measures, we should determine what our primary outcome is and how we deal with the additional outcomes.

A further problem when comparing therapeutical interventions is how exactly to set up the control condition. If every therapist involved in the study is a proponent of the new treatment -- which commonly happens as tests of new treatments are often done by those developing the new treatment -- they are unlikely to invest the same amount of effort in the control treatment than in the new treatment. This difference in effort, also known as allegiance effects, can affect the results independent of whether or not the new therapy is actually more effective.

Consider a trial in which we have decided on one outcome measure, but therapists are more invested in the new treatment than in the old treatment. After we have collected the data, we run the statistical analysis which provides evidence that the new treatment performs better than the control treatment on the selected outcome measure. What would this mean for the research question? The researchers performing such a study would probably conclude that the new treatment is better than the old treatment. However, given the difference in allegiance to the two treatments, such a conclusion seems premature. It is also plausible that the therapists, because of their stronger investment with the new treatment, invested more effort into the patients treated with the new treatment. This provides an alternative explanation for the results: This difference in effort could be responsible for the difference in the outcome instead of the difference in the two treatments. To provide compelling evidence that the new treatment is indeed better than the old treatment, the researchers would need to test their new treatment in a setting in which this alternative explanation would not work. For example, by showing that the new treatment is also better than the old treatment for a therapist with an allegiance to the old treatment.
