For example, in a recent paper on which I was a co-author [@baumannLinearThresholdModel2020], we developed a new task, the "ticket shopping task", to investigate sequential decision making problems (in this section, the details of the tasks are not really relevant so we will only mention the names, but do not describe tasks in detail). Whereas I feel we could make a good case that we could figure out to some degree what people do in this task, this does not mean that this is what people generally do in sequential decision making problems.

Likewise, whereas there might be both a model-free and model-based reinforcement learning system in the brain, the popular "two-step task" [@dawModelBasedInfluencesHumans2011] is unlikely to reveal all its mechanism or even prove its existence.[^role_of_stats-11] In fact, there is good evidence t participants in this task show many behaviours that are unrelated to the theoretical question of interest [e.g., @akamSimplePlansSophisticated2015].

[^role_of_stats-11]: I am not suggesting the original authors [@dawModelBasedInfluencesHumans2011] necessarily made these claims. This is just an example of where a particular task is portrayed in the literature as representing the underlying theoretical constructs (i.e., model-based and model-free reinforcement learning). As we have discussed, this is not a logically justifiable position. A particular task cannot represent a construct unless all auxiliary conditions are carefully spelled out and justified.

Another example comes from the domain of moral reasoning. Here, a prominent procedure is the use of the "trolley problem" and similar vignettes [@greeneFMRIInvestigationEmotional2001]. Whereas these vignettes have revealed interesting results, it seems questionable to assume that participants' responses represent the extent of their moral reasoning or that they are particularly predictive of participants real-world behaviour.[^role_of_stats-12] Similar arguments can be made for many other experimental domains but also whenever particular questionnaires are used.

[^role_of_stats-12]: Again, I do not want to accuse the authors cited here [@greeneFMRIInvestigationEmotional2001] of making such claims. However, the literature seems to treat "moral reasoning" and "responses to trolley-type problems" as near synonyms which seems problematic as it clearly these problems are clearly only one possible operationalisation of moral reasoning.

It makes sense to look a bit critical at the argument we have made here



## `RStudio` Setup

Our main access through `R` is through the `RStudio` IDE.

Let me end this section by discussing the ethical dimension of the question of causal inference from observational data. Clearly, some of the most politically charged societal questions that can be addressed empirically can generally only be done so using observational data. For example, an important question is whether

Example I: Testing a New Therapy

To get a better understanding of the research process and the problems that can arise in it, let us consider a first example research question and how it can be investigated empirically. In many clinical domains, a frequent research question is whether a new therapeutical intervention works better than an existing one. The basic study design for this type of research question is quite clear, a randomized controlled trial. We want to compare the new treatment with a control treatment in an experimental setting -- eligible participants are randomly assigned to receive either the new or the existing treatment. Whereas the general design of this study is fixed, important questions in the operationalisation step are how to measure the outcome intervention and how to implement the control treatment.

For example, if we are testing a new therapy against a mental health disorder, are we interested if the new treatment reduces symptoms as measured by one of the many available questionnaires (and then which questionnaire), reduces the number of sick days, or the number of recurring episodes? Depending on the differences between the new and old treatment it is possible that one treatment does better on one of these measures whereas the other is better for another measure. When performing the research we need to consider these different possibilities before we can collect any data. And if we collect multiple measures, we should determine what our primary outcome is and how we deal with the additional outcomes.

A further problem when comparing therapeutical interventions is how exactly to set up the control condition. If every therapist involved in the study is a proponent of the new treatment -- which commonly happens as tests of new treatments are often done by those developing the new treatment -- they are unlikely to invest the same amount of effort in the control treatment than in the new treatment. This difference in effort, also known as allegiance effects, can affect the results independent of whether or not the new therapy is actually more effective.

Consider a trial in which we have decided on one outcome measure, but therapists are more invested in the new treatment than in the old treatment. After we have collected the data, we run the statistical analysis which provides evidence that the new treatment performs better than the control treatment on the selected outcome measure. What would this mean for the research question? The researchers performing such a study would probably conclude that the new treatment is better than the old treatment. However, given the difference in allegiance to the two treatments, such a conclusion seems premature. It is also plausible that the therapists, because of their stronger investment with the new treatment, invested more effort into the patients treated with the new treatment. This provides an alternative explanation for the results: This difference in effort could be responsible for the difference in the outcome instead of the difference in the two treatments. To provide compelling evidence that the new treatment is indeed better than the old treatment, the researchers would need to test their new treatment in a setting in which this alternative explanation would not work. For example, by showing that the new treatment is also better than the old treatment for a therapist with an allegiance to the old treatment.
