# `tidyverse`: Example, Quiz, and Exercises {#tidyverse-exercises .unnumbered}

To get into the habit of doing it regularly when starting a new task or analysis, now is probably a good time to restart your `R` session. As a reminder, do so through the `RStudio` menu with `Session` - `Restart R`. After this, we need to load the `tidyverse` again:

```{r, results='hide', message=FALSE}
library("tidyverse")
```

## Extended `tidyverse` Example: Walasek & Stewart (2015) Exp. 1a & 1b {#extended-walasek-example}

### Reading Both Data Sets

As an extended `tidyverse` example, let us look once again at the data of @walasekHowMakeLoss2015. As described in Section \@ref(files), there are two similar data sets, Experiments 1a and 1b, that we can consider together (and have done so in Section \@ref(alternative-explanation-loss-aversion-or-loss-seeking)). To follow the extended examples, download them both into folder `data` that is in your current working directory: [Experiment 1a](https://github.com/singmann/stats_for_experiments/raw/master/data/ws2015_exp1a.csv) and [Experiment 1b](https://github.com/singmann/stats_for_experiments/raw/master/data/ws2015_exp1b.csv). Then, we can load them both as separate objects using `read_csv()`.

```{r}
ws1a <- read_csv("data/ws2015_exp1a.csv")
ws1b <- read_csv("data/ws2015_exp1b.csv")
```

We use new names for the resulting data objects (`ws1a` and `ws1b`) to help us remember that this is the data from @walasekHowMakeLoss2015, Experiments 1a and 1b. It's generally a good idea to use descriptive object names as this makes code easier to read later on. Especially when the code is long, one could even use more descriptive names such as `walasek_stewart_2015_1a` and `walasek_stewart_2015_1b`. However, as this example stays relatively short, the first letter of the last names and no year will suffice.

Note that as in the previous chapter, if you have problems downloading these two files or setting up the correct working directory, you can load them directly from the internet as well. However, this is not recommended and only shown here to make sure you can follow all steps in this example.

```{r, eval=FALSE}
ws1a <- read_csv("https://github.com/singmann/stats_for_experiments/raw/master/data/ws2015_exp1a.csv")
ws1b <- read_csv("https://github.com/singmann/stats_for_experiments/raw/master/data/ws2015_exp1a.csv")
```

We now have two data sets that have the same structure (i.e., with the same columns and data types) as we can see by just printing them both:

```{r}
ws1a
ws1b
```

What this output shows is that not only do the two data sets have the same columns in the same order, but they also appear to have the same condition names. To check, let's print the sorted unique values for each `condition` column:

```{r}
ws1a$condition %>% 
  unique() %>% 
  sort()
ws1b$condition %>% 
  unique() %>% 
  sort()
```

This confirms that indeed, the condition names are the same in both data sets.

### Combining Both Data Sets

To analyse these two data sets together, as we have done in Section \@ref(alternative-explanation-loss-aversion-or-loss-seeking), we now have to combine these two `tibble`s into one. Specifically, we need to add the *rows* of one of the data sets to the other data sets (in contrast to adding additional *columns* to one of the data sets). The `tidyverse` function to combine multiple `tibble`s by rows is `bind_rows()`. So the code for combining the two data sets is simply `bind_rows(ws1a, ws1b)`. This will only work in a case like this in which not only do we have the same columns, but they are also in the same order .

However, before combining the data, we have to consider one further complication. We can see that in both data sets the participant identifier column, `subno`, appears to consist of whole numbers. This means that the same number may be used for different participants in the two  experiments. If we do not account for this possibility before combining the data, we may end up with a data set in which data from different participants are treated as coming from the same participant -- a clear error. For example, the output above shows that there is a participant with `subno` 8 in Experiment 1a. If there is also a participant with `subno` 8 in Experiment 1b, the data from these two different participants (no participant participated in both studies) would be treated as being from the same participant -- a clear error. To see whether this is indeed a potential problem, we print all individual `subno` values for both experiments.

```{r}
ws1a$subno %>% 
  unique() %>% 
  sort()
ws1b$subno %>% 
  unique() %>% 
  sort()
```

The output confirms our suspicion. `subno` values are not unique across experiments, so we  need to make them so before combining the data. One straightforward way to do this is by adding a string to the start of each `subno`, either `e1a_` or `e1b_`, that indicates which data set each participant belongs to. For this we use the `paste0()` function which pastes strings together into one (`paste0()` does so without adding any extra separation character to the combined strings).

In the same call, we will also convert the `subno` variable to a factor (as it is a categorical variable). We can then combine both data sets into one called `ws1` using the `bind_rows()` call discussed above. We then get an overview of the combined data using the `glimpse()` function which is the `tidyverse` equivalent of `str()` (`glimpse()` often produces less verbose output for tibbles than `str()`-- try it out yourself to see).

```{r}
ws1a <- ws1a %>%
  mutate(subno = factor(paste0("e1a_", subno)))
ws1b <- ws1b %>%
  mutate(subno = factor(paste0("e1b_", subno)))
ws1 <- bind_rows(ws1a, ws1b)
glimpse(ws1)
```

The output shows that the `subno` for the first participant in Experiment 1 is now `e1a_8`, not `8`. In other words, `subno`'s are now unique within each experiment and so we can combine the data without making the larger data set misleading.

To verify this logic, we can count the number of unique values of `subno` for each data set using the `length()` function on the `unique()` elements of the `subno` vectors. `length()` is a function that returns the number of elements in a vector, so can be directly used in calculations. The calculation here shows that, indeed, the combined data has the same number of participants, 781, as Experiments 1a and 1b together.

```{r}
length(unique(ws1a$subno)) + length(unique(ws1b$subno))
length(unique(ws1$subno))
```

Before continuing with the analysis of the combined data, it makes sense to take a step back and consider briefly why we discussed the question of how to combine these two data sets rather extensively. One the one hand, the code above uses a few new functions that we have not yet introduced such as `bind_rows()` and `length()`. As before, we want to introduce new functions by explicitly discussing their functionality.

On the other hand, the discussion above shows us one way of handling and checking the assumptions in our code. The issue here is that when combining two data sets using `bind_rows()`, the code assumes that the participant identifiers are unique. This is not necessarily an obvious assumption we have when writing the code, but it is a consequence of the fact that we simply concatenate both data sets. Because this is not an assumption that is obvious, we may overlook it, possibly leading to problems later on in our code. Specifically, treating data from different participants as coming from the same participant, just because they coincidentally share the same `subno`,  is probably *not* appropriate in our statistical analysis. By checking whether the number of participants in the combined data set is equal to the sum of the number of participants in the separate data sets, we ensure that combining the two data sets was done appropriately.

Another reason why we are discussing this issue in detail is that in a paper on which I am a co-author, @skovgaard-olsenRelevanceEffectConditionals2016, I overlooked this exact problem. The experiment reported in the paper consisted of three conditions that needed to be combined for the analysis. The problem was that the participant identifiers were only unique within conditions and not across conditions and I combined the data sets without considering this fact. Consequently, the statistical analysis incorrectly treated observations from different participants as belonging to the same participant. In fact, all statistical results reported in @skovgaard-olsenRelevanceEffectConditionals2016 are affected as I only recognised the error after publication of the article. Luckily for my co-authors and me, once I realised what had happened and re-analysed the data after correctly combining it, that initial error had had no substantive effects on the results. Some details changed (the exact value of some numbers), but not the qualitative pattern of results. Consequently, we could fix this error by publishing a straightforward correction [@skovgaard-olsenCorrigendumRelevanceEffect2018]. The larger point here is that such errors can and will happen. The best way to avoid them is by regularly checking explicitly whether the assumptions we make about our data and our code hold. 

### Preparing the Data Set and Descriptive Analysis

Now that we have combined the two data sets into one `tibble`, we can further prepare it for analysis. For this, we turn all categorical variables into factors, as shown before.

```{r}
ws1 <- ws1 %>% 
  mutate(
    subno = factor(subno),
    response = factor(response, levels = c("reject", "accept")),
    condition = factor(
      condition, 
      levels = c(40.2, 20.2, 40.4, 20.4), 
      labels = c("-$20/+$40", "-$20/+$20", "-$40/+$40", "-$40/+$20")
    )
  )
ws1
```

Next, we calculate the number of participants per condition and check if every participant has 64 trials. This is one way to check our assumptions about the data and ensure data integrity (we use the same code as described in Section \@ref(counting)).

```{r}
ws1 %>% 
  group_by(condition, subno) %>% 
  summarise(n = n()) %>% 
  group_by(condition) %>% 
  summarise(
    n_participants = n(),
    all_64 = all(n == 64)
    )
```

Finally, it is time to perform a descriptive analysis of the data. The main result we have reported for this data was the mean acceptance rates for the symmetric lotteries that appear in all conditions. The code for this is the same as given in Section \@ref(group-by), but now we use the combined data. This code reproduces the results reported in Section \@ref(alternative-explanation-loss-aversion-or-loss-seeking).

```{r}
ws1 %>%
  filter(loss == gain, loss %in% c(12, 16, 20)) %>% 
  group_by(condition) %>% 
  summarise(mean_acc = mean(resp)) %>% 
  ungroup()
```

## Quiz 

Note: The pull-down menu for selecting an answer turns green after selecting the correct answer. 

::: {.exercise}
What does `NA` stand for in `R`? 

1. "not available", i.e., missing data
2. "no answer", i.e, `R` couldn't find an answer to your command
3. "nothing applicable", i.e., there are no values/variables that match your request

Answer: `r webex::mcq(c(answer = "1", "2", "3"))`
:::

::: {.exercise}
Which of the following is NOT true for an `R` package? 

1. Is a collection of functions that extend `R`.
2. Needs to be installed from CRAN every time you use it .
3. Needs to be loaded every time you use it.

Answer: `r webex::mcq(c("1", answer = "2", "3"))`
:::

::: {.exercise}
What are "bugs" in programming languages? 

1. variables that are not of interest for a specific analysis
2. the same code is used multiple times for different datasets
3. error in the code that leads to unexpected/wrong results

Answer: `r webex::mcq(c("1", "2", answer = "3"))`
:::

::: {.exercise}
What is a `tibble`?

1. a variant of a `data.frame`
2. the `tiydverse` version of a vector 
3. the result you get from data wrangling

Answer: `r webex::mcq(c(answer = "1", "2", "3"))`
:::

::: {.exercise}
This operator `%>%` means we are using...

1. base R
2. a pipe
3. a data.frame

Answer: `r webex::mcq(c("1", answer = "2", "3"))`
:::

::: {.exercise}
The `dplyr` package is NOT useful for:

1. picking variables based on their names
2. adding new variables
3. summarizing multiple values
4. changing the ordering of the rows
5. reading file in as csv

Answer: `r webex::mcq(c("1", "2", "3", "4", answer = "5"))`
:::

::: {.exercise}
Using the `dplyr` package, which function is used for adding/changing variables in the current data?

1. `mutate()`
2. `summarise()`
3. `filter()`
4. `select()`

Answer: `r webex::mcq(c(answer = "1", "2", "3", "4"))`
:::

::: {.exercise}
Using the `dplyr` package, which function is used for selecting subsets of rows?

1. `mutate()`
2. `summarise()`
3. `filter()`
4. `select()`

Answer: `r webex::mcq(c("1", "2", answer = "3", "4"))`
:::

::: {.exercise}
Using the `dplyr` package, which function is used for selecting subsets of columns?

1. `mutate()`
2. `summarise()`
3. ``filter()`
4. `select()`

Answer: `r webex::mcq(c("1", "2", "3", answer = "4"))`
:::

::: {.exercise}
When using the pipe operator `%>%`, `R` executes operations in which order?

1. From innermost to outermost function
2. That depends on which other packages are loaded.
3. From left to right.

Answer: `r webex::mcq(c("1", "2", answer = "3"))`
:::

## Practical Helpers: Cheatsheets

Trying to remember and applying all the `tidyverse` tools yourself can be a bit overwhelming at the beginning. There are quite a few functions and one has to remember for each what it does and what its syntax is. Furthermore, so far we have introduced the most important functions, but there are more in `dplyr` and other `tidyverse` packages that we do not have the space to introduce (for more see ["`R` for data science"](https://r4ds.had.co.nz/)).

One way for you to keep an overview of which functions do what is with the help of **cheat sheets** (*or* cheatsheets). Cheat sheets are short (usually 1 or 2 pages) documents that provide an overview of a package or tool and are a common resource for many programming languages. Their benefit compared to other learning resources such as books or the documentation is that they provide a concise overview and can point you quickly to the right tool. 

In the case of `R`, once you know which function to use (e.g., thanks to the cheat sheet) it might then make sense to follow up by looking at the documentation. The documentation can be obtained for each function by entering `?functionname` (e.g., `?summarise`) at the `R` prompt. This provides  not only an explanation of what the function does plus all of its arguments, but will also usually have helpful examples.

For the `tiydverse` packages, `RStudio` provides an almost complete list of [cheat sheets](https://www.rstudio.com/resources/cheatsheets/). The most relevant for us at the moment is the [`dplyr` cheat sheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf). Furthermore, there are also cheat sheets for [the `RStudio` IDE iteself](https://github.com/rstudio/cheatsheets/raw/master/rstudio-ide.pdf), [reading in data](https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf), and even [base `R`](http://github.com/rstudio/cheatsheets/raw/master/base-r.pdf). Before diving into the examples below, it might make sense to download (or even print) the cheat sheets and have them by your side while trying to solve the problems.

## `tiydverse` Exercise: Earworms and Sleep {#earworms-task1}

For this exercise we will work with a data set from @scullinBedtimeMusicInvoluntary2021 investigating a research question about the relationship between listening to music and sleep: "Many people listen to music for hours every day, often near bedtime. We investigated whether music listening affects sleep, focusing on a rarely explored mechanism: involuntary musical imagery (earworms)." I'm sure most of you will have had the experience of an earworm -- hearing some particular piece of music in your head, and not being able to 'stop it playing'. If this seems alien to you, [Wikipedia provides a longer introduction](https://en.wikipedia.org/wiki/Earworm).

Here, we are looking at the data from @scullinBedtimeMusicInvoluntary2021's Study 2, which was a sleep-lab experiment. Participants came to the sleep-lab and stayed for one night in a controlled environment in which a number of objective sleep parameters could be measured via [polysomnography](https://en.wikipedia.org/wiki/Polysomnography). Throughout the night several physiological parameters such as electroencephalography (EEG) and breathing were recorded continuously. Participants were assigned to one of two conditions determining the music they heard just before going to bed: either a condition in which original versions of three pop songs, which included the lyrics, or an instrumental version of the same three pop-songs (without the lyrics). The three songs (["Don't Stop Believin'" by Journey](https://youtu.be/1k8craCGpgs), ["Call Me Maybe" by Carly Rae Jepsen](https://youtu.be/fWNaR-rxAic), and ["Shake It Off" by Taylor Swift](https://youtu.be/nfWlot6h_JM)) were chosen because previous research had shown that they induce earworms. After participants woke up in the morning, they were asked whether they experienced any earworms at different points in the night or in the morning.

The researchers were interested in two research questions: 

(1) Does listening to the original version of a pop song (with lyrics) or an instrumental version of it affect whether or not participants develop earworms? This research question was based on previous results and the authors expected the instrumental version to induce more earworms than the lyrical versions. 

(2) Does the sleep quality differ between participants in the lyrical music condition and the instrumental music condition (in which participants are expected to have more earworms)?

Before looking at the data, take a guess yourself. Do you believe you sleep better after listening to music that makes it likely that you develop an earworm?

A version of the original data file made available by @scullinBedtimeMusicInvoluntary2021 can be downloaded from [here](https://github.com/singmann/stats_for_experiments/raw/master/data/earworm_study.csv). I recommend you download it to the `data` folder in the working directory and then you can read in the data via the following code. It makes sense to restart `R` before doing that, so we also reload the `tidyverse`.

```{r}
library("tidyverse")
earworm <- read_csv("data/earworm_study.csv")
```

Alternatively, you can also download directly from the internet for this exercise, but I really recommend getting comfortable with files, folders, and the `R` working directory. The code for downloading from the internet is:

```{r, eval=FALSE}
earworm <- read_csv("https://github.com/singmann/stats_for_experiments/raw/master/data/earworm_study.csv")
```

Let's take a first look at the data:

```{r}
glimpse(earworm)
```

In addition to the variables relevant to our research questions, the data contains a number of control variables (the original data file included even more). We can see a total of 19 variables:

- `id`: Participant identifier
- `group`: experimental condition with two values: "Lyrics" versus "Instrumental"
- `relaxed`: question asking participants how relaxed they felt on a scale from 0 (= not relaxed) to 100 (= very relaxed) after listening to the music.
- `sleepy`: question asking participants how sleepy they felt on a scale from 0 (= not sleepy) to 100 (= very sleepy) after listening to the music.
The next 5 variables concerned whether or not the participants reported having an earworm at different times:
- `earworm_falling_asleep`: Had earworm when trying to fall asleep last night? 0 = No; 1 = Yes
- `earworm_night`: Had earworm when woke up during the night? 0 = No; 1 = Yes
- `earworm_falling_asleep`: Had earworm when woke up during the night? 0 = No; 1 = Yes
- `earworm_morning`: Had earworm when woke up this morning? 0 = No; 1 = Yes
- `earworm_control`: Had earworm at the control time point (i.e., after getting ready to leave the lab)? 0 = No; 1 = Yes
- `sleep_efficiency`: sleep efficiency percentage score obtained from the polysomnography (0 = very low sleep efficiency and 100 = very high sleep efficiency)
- `sleep_time`: total sleep time in minutes

The remaining variables are demographic ones whose meaning should be evident, except, perhaps, for `classrank`. This uses US nomenclature for what year of 4 the student participant is in  (i.e., freshman = year 1, sophomore = year 2, junior = year 3, and senior = year 4) plus some additional values.

::: {.exercise}
For research questions 1 and 2 described above, which variables are the independent and which are the dependent variables? 

`r hide("Hint")`
The answer to this question does not require coding. Instead you should come to a solution by just thinking about the description of the experiment and the variables. 

Also, remember that in an experiment we test the effect of the independent variable on the dependent variable. 
`r unhide()`

`r hide("Solution")`

The independent variable for both research questions is the experimental condition, variable `group`.

For research question 1, we have three dependent variables, all beginning with `earworm_`: `earworm_falling_asleep`, `earworm_night`, and `earworm_morning`. Only `earworm_control` is not a dependent variable for this research question, but a control variable (i.e., we should not see an effect of `group` on this dependent variable). [Note that the categorisation of `earworm_control` as a control variable was a decision of the original authors. I would think that in principle there could still be an effect of the manipulation on this variable as it was collected after the experimental manipulation. However, as they declared it like that, we go with their categorisation here.]

For research question 2, we have one main dependent variable,  `sleep_efficiency` as a measure of sleep quality. We could also consider the time a participant sleeps, `sleep_time`, as a secondary measure of sleep quality. 

`r unhide()`
:::

::: {.exercise}
How can you categorise the other variables, such as `relaxed`, `age`, etc., that are neither independent nor dependent variables? What results pattern would we expect for these variables?

`r hide("Solution")`
The other variables can all be understood as control variables. The two explicitly psychological measures, `relaxed` and `sleepy`, are taken right after the experimental manipulation (i.e., listening to either lyrical or instrumental music). We hope that the type of music does not affect this measure. The other control variables, `age` and following, are all demographic variables. We can use them to check whether the randomisation led to unbalanced conditions. And as we have discussed before, the participant identifier, `id`, is also a control variable.
`r unhide()`
:::

::: {.exercise}
Before starting with the analysis, we should prepare the data and transform all important categorical variables into `factor`s to avoid any problems. Your task: Transform `id` and `group` into a `factor`. For `group` make sure that the original version with lyrics is factor level 1.

`r hide("Hint")`
Sounds like a job for `mutate()` and `factor()`.
`r unhide()`

`r hide("Solution")`
```{r}
earworm <- earworm %>% 
  mutate(
    id = factor(id),
    group = factor(group, levels = c("Lyrics", "Instrumental"))
  )
```

`r unhide()`

:::

::: {.exercise}
As a first step in our analysis, we need to get an overview of the data. For this, we first need to learn something about the structure of the data. This requires two steps:

- How many rows does the data from each participant occupy?
- How many participants are in each condition?

`r hide("Hint")`
Sounds like a job for `summarise()`
`r unhide()`

`r hide("Solution")`
```{r}
earworm %>% 
  group_by(id) %>% 
  summarise(n = n()) 
```

Looks like every `id` has one row. However, let us make sure this is indeed the case.

```{r}
earworm %>% 
  group_by(id) %>% 
  summarise(n = n()) %>% 
  summarise(all_1 = all(n == 1))
```

Yes, everyone has only one row. As discussed before, if there is only one observation per participant there is no distinction between wide and long format, so we can use the data in this format.

Because there is only one observation per participant, we can directly count the number of participants per condition by counting the number of rows per condition.

```{r}
earworm %>% 
  group_by(group) %>% 
  summarise(n = n()) 
```

There are 25 participants in the lyrics condition and 23 in the instrumental condition.
`r unhide()`

:::

::: {.exercise}
Before looking at the results, it's a good idea to get an overview of the demographics of the data. In the first step, let us provide a basic overview of participants ignoring the condition they are put in:

- Provide some summaries of the age of participants (min, max, mean, sd).
- What is the gender distribution?
- What is the ethnicity distribution of participants?

When calculating the distribution of a categorical variable, not only calculate the frequencies, but also the proportions (i.e., relative frequencies). 

`r hide("Hint")`
For getting a summary on `age`, `summarise()` seems like a good idea. 

For the other questions, we could also use `summarise()` conditional on the categorical variables or alternatively `count()`. We can then calculate the proportions from the frequencies using the formula proportion = frequency / total sum.
`r unhide()`

`r hide("Solution")`

For the age distribution we have to look at the `age` variable:
```{r}
earworm %>% 
  summarise(mean = mean(age),
            min = min(age),
            max = max(age),
            sd = sd(age))
```

Looks like the participants were all in the student age range.

To get the absolute frequencies for a categorical variable we can just do:

```{r}
earworm %>% 
  group_by(gender) %>% 
  summarise(n = n())
```

We can then add the proportions to the resulting `tibble` using `mutate()`:

```{r}
earworm %>% 
  group_by(gender) %>% 
  summarise(n = n()) %>% 
  mutate(prop = n / sum(n))
```

Around 71% of participants were women and the rest were men.

For the ethnicity item we can use the same logic/code:
```{r}
earworm %>% 
  group_by(raceethnicity) %>% 
  summarise(n = n()) %>% 
  mutate(prop = n / sum(n))
```

Around 60% are Caucasian, 19% Hispanic, and the rest Asian (12%) or African American (8%). 

`r unhide()`

:::

::: {.exercise}
Let us now calculate the conditional demographic distributions; that is, the demographic distribution conditional on the experimental condition `group`. The reason for doing so is to check if the randomisation created balanced or unbalanced groups on the control variables we have collected.

`r hide("Hint")`
We can re-use the code from the previous exercise, but need to add `group_by()` to it.
`r unhide()`

`r hide("Solution")`
For the age distribution we can essentially copy the code from above and just need to add `group_by(group)`:
```{r}
earworm %>% 
  group_by(group) %>% 
  summarise(mean = mean(age),
            min = min(age),
            max = max(age),
            sd = sd(age))
```

Participants in the instrumental condition are on average around 1 year older than participants in the lyrics condition, which seems not too small given that the SD is not much larger. However, this difference could be mostly due to a larger maximum value, which would also explain the difference in SDs. To check this, we can split the data into two `tibble`s, one for each condition, and take a look at the sorted ages.

```{r}
earworm_lyrics <- earworm %>% 
  filter(group == "Lyrics")
earworm_instrumental <- earworm %>% 
  filter(group == "Instrumental")
earworm_lyrics$age %>% 
  sort()
earworm_instrumental$age %>% 
  sort()
```

This suggests that it is not only one particularly old participant in the instrumental condition, but several (i.e., the four oldest participants are all in the instrumental condition). So there might be some age imbalance between the two conditions.

To calculate the conditional gender distributions, we first calculate the number of participants by `group` and `gender` combination. Then, we need to group again by the experimental condition `group` to calculate the relative frequencies within each condition. That is, we can also use `mutate()` conditional on the grouping factor created by `group_by()` (i.e., the `sum(n)` part of the `mutate()` call is executed separately for each experimental condition after the `group_by()` part). 

```{r}
earworm %>% 
  group_by(group, gender) %>% 
  summarise(n = n()) %>%
  group_by(group) %>%   
  mutate(prop = n / sum(n))
```

The output shows that the gender ratio is not balanced between groups. Whereas we see a roughly 50-50 gender ratio in the instrumental condition, in the lyrical condition it is closer to 80-20.

Finally, let's use the same logic for the ethnicity question. Note that the resulting table is again too long to be shown fully, so we pipe it to `print(n = Inf)` as done before.

```{r}
earworm %>% 
  group_by(group, raceethnicity) %>% 
  summarise(n = n()) %>%
  group_by(group) %>%   
  mutate(prop = n / sum(n)) %>% 
  print(n = Inf)
```

This does not show any major differences between the two conditions. Only the proportion of Asian participants is somewhat imbalanced.

Overall, the results show that the two groups are not perfectly balanced, even though the groups were randomly created. This can happen in experiments, and in fact would be expected, especially if the group sizes are small as here (i.e., a maximum of 25 participants per condition). The larger the groups, the more likely it will be that they are balanced. 

If the groups are unbalanced, is this a problem? Not necessarily. If you remember, the problem randomisation attempts to address are confounders -- third variables that can affect the dependent variable. Imbalance in experiments thus is problematic if we have imbalance in variables that are known to also affect the dependent variable. The question is if age and gender are such variables. I am not much of a sleep researcher, but would assume that the effect of gender on sleep efficiency is not extremely large. However, age surely has an effect on sleep, but I doubt whether that would be true in the age range of the participants here. If the age range were larger (e.g., one group had participants in their 40s or older and the other did not), I would be more concerned. The differences here seem rather unimportant overall. Nevertheless, in their main analysis @scullinBedtimeMusicInvoluntary2021 do adjust for the difference in gender, a statistical technique we will get back to later. 

`r unhide()`

:::

::: {.exercise}
In addition to the demographic variables, we should also get an overview of the two control variables measuring participants' responses about their own state after listening to the music, variables `relaxed` and `sleepy`. Check whether they look similar across condition by calculating their mean and SD.

`r hide("Hint")`
A job for the `group_by()` `summarise()` combination that is one of the most frequent combination we use from the `tidyverse`.
`r unhide()`

`r hide("Solution")`
```{r}
earworm %>% 
  group_by(group) %>% 
  summarise(m_relaxed = mean(relaxed),
            sd_relaxed = sd(relaxed),
            m_sleepy = mean(sleepy),
            sd_sleep = sd(sleepy))
```

The differences in the relaxed and sleepiness question after listening to the music seem minor given the variability (i.e., SD) in the data.

`r unhide()`

:::

::: {.exercise}
Having now carefully checked and explored the data, it's time to take a look at research question 1: Does listening to the  original version of a pop song (with lyrics) or an instrumental version of it affect whether or not participants develop earworms?

Let us look at this research question in multiple steps:

1. Calculate whether experimental condition (`group`) affects any of the three `earworm` dependent variables as well as the `earworm` control variable. For doing so, calculate the conditional means as well as the standard deviations. 
2. Calculate two new dependent variables from the three dependent variables (i.e., `earworm_...` variables with the exception of `earworm_control`): any earworm at all (which should be 0 if participant did not report any earworm and 1 otherwise) and proportion of earworms (which should be the sum of the three earworm dependent variables divided by 3). Then calculate whether `group` affects these two new dependent variables.

Does the analysis support the prediction that instrumental music leads to more earworms than lyrical music?

`r hide("Hint")`
You already know the drill: Calculating conditional means and standard deviations is done through `group_by()` and `summarise()`. To calculate new variables (analysis 2), you need to use `mutate()`.
`r unhide()`

`r hide("Solution")`

**Analysis 1: Separate analysis for each dependent variable:**

```{r}
earworm %>% 
  group_by(group) %>% 
  summarise(m_fall = mean(earworm_falling_asleep),
            sd_fall = sd(earworm_falling_asleep),
            m_night = mean(earworm_night),
            sd_night = sd(earworm_night),
            m_morning = mean(earworm_morning),
            sd_morning = sd(earworm_morning),
            m_cont = mean(earworm_control),
            sd_cont = sd(earworm_control)
  )
```
Whereas this is the correct code, it does not show all variables of the returned data. One easy way to ensure all variables are shown is to convert the `tibble` back to a `data.frame`.

```{r}
earworm %>% 
  group_by(group) %>% 
  summarise(m_fall = mean(earworm_falling_asleep),
            sd_fall = sd(earworm_falling_asleep),
            m_night = mean(earworm_night),
            sd_night = sd(earworm_night),
            m_morning = mean(earworm_morning),
            sd_morning = sd(earworm_morning),
            m_cont = mean(earworm_control),
            sd_cont = sd(earworm_control)
  )  %>% 
  as.data.frame()
```

We can see that for two of the three dependent variables, for earworms when falling asleep and in the morning, the proportion of earworms is noticeably larger in the instrumental than in the lyrical condition. For the proportion of earworms during the night and at the control time, we see a much smaller difference or even a small difference in the opposite direction.

**Analysis 2: Analysis for new dependent variables.**

*Step 1: Calculate new variables*

```{r}
earworm <- earworm %>% 
  mutate(
    prop_earworm = (earworm_falling_asleep + earworm_night + 
                      earworm_morning) / 3
  ) %>% 
  mutate(any_earworm = if_else(prop_earworm == 0, 0, 1)) 

earworm %>% 
  select(id, prop_earworm, any_earworm, starts_with("earworm"))  %>% 
  as.data.frame() %>% 
  head()

```

We first calculate the new variables using `mutate()`. To do so, we realise that the `any_earworm` variable is a function of the `prop_earworm` (= proportion of earworm) variable, so we calculate the latter first.  To calculate the proportion variable we just add each of the three variables up and then divide by 3, being mindful that we need to put parentheses around the `+` operations. 

We can then calculate the `any_earworm` variable from the `prop_variable`. Note that we do so in a new `mutate()` call. The reason is that we need to refer to the `prop_variable` variable and it can lead to problems using variables that are created in the same `mutate()` call. It might work, but is not guaranteed, so better to avoid it.

To calculate the `any_earworm` variable, we need to check when the `prop_earworm` variable is 0 and then assign 0 to the `any` variable and 1 otherwise. We use the `if_else()` function for this which allows us to apply an if-else logic, as we have here, to a vector (i.e., if called with a vector, `if_else()` also returns a vector). Here, the if-part checks if `prop_earworm == 0`; if it is, we return `0`, and `1` otherwise.

We then save the new variable back in the `earworm` data so we can use it again. 

Because this is a non-trivial calculation, we end by printing the first few rows of the results to see if the calculated variables show what they should. We do this to make sure we did not make any errors. As printing the `tibble` per default would now show all variables we want ot see, we first select the relevant variables, convert the `tibble` to a `data.frame`, and then  use `head()` to get the first few rows. This shows it seems to work. However, as we do not see enough rows with 1s, we repeat the code but print the last few rows using `tail()`. This output is more telling that our logic worked.

```{r}
earworm %>% 
  select(id, prop_earworm, any_earworm, starts_with("earworm"))  %>% 
  as.data.frame() %>% 
  tail()

```

*Step 2: Calculate conditional means and SDs*

```{r}
earworm %>% 
  group_by(group) %>% 
  summarise(m_any = mean(any_earworm),
            sd_any = sd(any_earworm),
            m_prop = mean(prop_earworm),
            sd_prop = sd(prop_earworm)
  )
```

This shows that for both new dependent variables, we see a difference in the expected direction.

**Overall answer:** The analysis overall appears to support the prediction that listening to instrumental compared to lyrical music leads to more earworms. However, we still need, at some point, to do a proper statistical analysis to get a better understanding.

`r unhide()`

:::

::: {.exercise}
Let's now take a look at research question 2: Does sleep quality differ between participants in the lyrical and the instrumental music condition (in which participants are expected to have more earworms)?

Check the effect of the independent variable on the main measure of sleep quality, `sleep_efficiency`, and also on the length of sleep, `sleep_time`. Don't forget to calculate both means and SD to judge the size of the difference given the level of noise. 

In addition to just calculating the conditional means, also calculate the exact difference in sleep efficiency and sleeping time between both conditions.

Does the data overall support the prediction?

`r hide("Hint")`
Conditional means is the job of the `group_by()` and `summarise()` combination.
`r unhide()`

`r hide("Solution")`
The analysis can be straightforwardly adapted from the previous code. However, because we also want to calculate the difference exactly, we save the result in a new object, and then print it.

```{r}
summary_sleep <- earworm %>% 
  group_by(group) %>% 
  summarise(m_efficiency = mean(sleep_efficiency),
            sd_efficiency = sd(sleep_efficiency),
            m_time = mean(sleep_time),
            sd_time = sd(sleep_time)
  )
summary_sleep
```

This shows that there is a small difference in sleep efficiency as well as time slept, in the predicted direction (i.e., a higher sleep quality for lyrical compared to instrumental music). However, the SD for sleep efficiency is much smaller than for time slept, which is perhaps not surprising given the very different magnitudes of the two variables (differing by about a factor of 5).

Let us now calculate the observed difference to understand the pattern better. With the `tidyverse` this can be done as:

```{r}
summary_sleep %>% 
  summarise(diff_efficiency = m_efficiency[1] - m_efficiency[2],
            diff_time = m_time[1] - m_time[2])
```

This shows that we can use normal vector indexing (i.e., `[1]` or `[2]`) for a vector inside `summarise()`. 

The same results could also be obtained with base `R` as:

```{r}
summary_sleep$m_efficiency[1] - summary_sleep$m_efficiency[2]

summary_sleep$m_time[1] - summary_sleep$m_time[2]
```

Overall, the results show that there is a difference in sleep quality that is around 50% of the observed SD in both measures. As for research question 1, a statistical analysis is necessary to better understand the pattern. 

However, we can already say that the differences are not large in absolute terms. For example, the difference in time slept is around 10 minutes with an average sleep time that corresponds to more than 8 hours:

```{r}
500 / 60  ## sleep time in minutes / 60 gives time in hours
```

`r unhide()`

:::

::: {.exercise}
The analysis so far supports the prediction for both research questions: Participants that listen to instrumental compared to lyrical songs report more earworms and sleep worse. However, this analysis does not address the question of whether participants that report earworms sleep worse than participants that do not report earworms. 

As the last bit of the analysis, let's take a look at this question: Do participants that report having an earworm sleep better than participants that do not do so, ignoring the experimental condition. For this:

1. Create a new `factor`, `has_earworm`, that is `yes`, whenever participants report at least once that they had an earworm for one of the three `earworm` dependent variables (i.e., within the experimental time frame, ignoring the control time).
2. Calculate the conditional N (number of participants) as well as conditional means and SD of the two sleep variables, `sleep_efficiency` and `sleep_time`, as a function of `has_earworm`.

What can we learn from this analysis?

`r hide("Solution")`
To create the new factor, `has_earworm`, we can transform `any_earworm` into a factor: 

```{r}
earworm <- earworm %>% 
  mutate(has_earworm = factor(
    any_earworm,
    levels = c(1, 0),
    labels = c("yes", "no")
  ))
```

Then, we can use the previous code to calculate the conditional means and SDs.

```{r}
summary_earworms <- earworm %>% 
  group_by(has_earworm) %>% 
  summarise(n = n(),
            m_efficiency = mean(sleep_efficiency),
            sd_efficiency = sd(sleep_efficiency),
            m_time = mean(sleep_time),
            sd_time = sd(sleep_time)
  )
summary_earworms %>% 
  mutate(prop = n / sum(n))

## want to see all variables:
summary_earworms %>% 
  mutate(prop = n / sum(n)) %>% 
  as.data.frame()
```

The analysis shows that around 40% report an earworm during the experimental time frame. And there is also an interesting pattern: Participants that report having an earworm have lower sleep efficiency scores but sleep slightly longer, compared to participants that do not report an earworm.

We can also again calculate the difference. Note that we need to change the order here to get the same interpretation as above (i.e., positive means in line with the prediction).

```{r}
summary_earworms %>% 
  summarise(diff_efficiency = m_efficiency[2] - m_efficiency[1],
            diff_time = m_time[2] - m_time[1])
```

What we can learn from the analysis is that it looks as if having an earworm leads to reduced sleep efficiency. The pattern for sleep length is more difficult to interpret (but also a lot smaller compared to the variability in the data as measured by the SD). 

However, in this analysis we lose the benefit of randomisation. We do not really know if it is the earworm or something related to the earworm that drives the effect. Nevertheless, because we do not really have another way of introducing an earworm other than playing different types of music, it is still an important result.

`r unhide()`

:::



